{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pyautogui\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import constants.constants as const\n",
    "import constants.file_handler_constants as fh\n",
    "from constants.restaurant_constants import *\n",
    "\n",
    "from packages.restaurant.Restaurant import *\n",
    "from packages.file_handler_package.file_handler import *\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv, dotenv_values \n",
    "\n",
    "from selenium.webdriver import Remote, ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.actions.wheel_input import ScrollOrigin\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "from selenium.webdriver.edge.options import Options\n",
    "\n",
    "\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from packages.restaurant.mulProcess_restaurant_scraping_proxy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_restaurant_df(restaurant: Restaurant) -> pd.DataFrame:\n",
    "    restaurant_dict = {\n",
    "        'name': [restaurant.get_name()],\n",
    "        'sub_name': [restaurant.get_sub_name()],\n",
    "        'wongnai_url' : [restaurant.get_wongnai_url()],\n",
    "        'restaurantType' : [restaurant.get_restaurantType()],\n",
    "        'facility' : [restaurant.get_facility()],\n",
    "        'description' : [restaurant.get_description()],\n",
    "        'imgPath': [restaurant.get_imgPath()],\n",
    "        'phone' : [restaurant.get_phone()],\n",
    "        'website' : [restaurant.get_website()],\n",
    "        'openingHour' : [restaurant.get_openingHour()],\n",
    "        'priceRange' : [restaurant.get_priceRange()],\n",
    "        'latitude' : [restaurant.get_latitude()],\n",
    "        'longitude' : [restaurant.get_longitude()],\n",
    "        # location\n",
    "        'address' : [restaurant.get_location().get_address()],\n",
    "        'province' : [restaurant.get_location().get_province()],\n",
    "        'district' : [restaurant.get_location().get_district()],\n",
    "        'subDistrict' : [restaurant.get_location().get_subDistrict()],\n",
    "        'province_code' : [restaurant.get_location().get_province_code()],\n",
    "        'district_code' : [restaurant.get_location().get_district_code()],\n",
    "        'sub_district_code' : [restaurant.get_location().get_sub_district_code()],\n",
    "\n",
    "        # rating\n",
    "        'score' : [restaurant.get_rating().get_score()],\n",
    "        'ratingCount' : [restaurant.get_rating().get_ratingCount()],\n",
    "    }\n",
    "    \n",
    "    restaurant_df = pd.DataFrame(restaurant_dict)\n",
    "    \n",
    "    return restaurant_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_openinghours(openingHours: dict) -> dict:\n",
    "    temp_openingHours = openingHours.copy()\n",
    "\n",
    "    if(len(temp_openingHours) == 0):\n",
    "        return temp_openingHours.copy()\n",
    "    \n",
    "    # cut substring represent special holiday\n",
    "    # for example:\n",
    "    # {'วันจันทร์(วันเฉลิมพระชนมพรรษา พระบาทสมเด็จพระปรเมนทรรามาธิบดีศรีสินทรมหาวชิราลงกรณ พระวชิรเกล้าเจ้าอยู่หัว (วันหยุดชดเชย))': '9:00–17:00'}\n",
    "    # change its key to -> {'วันจันทร์': '9:00–17:00'}\n",
    "    for key, val in temp_openingHours.copy().items():\n",
    "        start_Idx_special_holiday = key.find('(')\n",
    "        if(start_Idx_special_holiday != -1):\n",
    "            # changing keys of dictionary\n",
    "            new_key = key[:start_Idx_special_holiday]\n",
    "            temp_openingHours[new_key] = temp_openingHours.pop(key)\n",
    "\n",
    "    days_of_week = ['อาทิตย์', 'จันทร์', 'อังคาร', 'พุธ', 'พฤหัสบดี', 'ศุกร์', 'เสาร์']\n",
    "    # in case of temp_openingHours = {\"ทุกวัน\": '10:30 - 21:00'}\n",
    "    # convert it to dictionary with all days of week as a keys(same value)\n",
    "    if(len(temp_openingHours) == 1 and list(temp_openingHours.keys())[0] == 'ทุกวัน'):\n",
    "        temp_time = list(temp_openingHours.values())[0]\n",
    "        del temp_openingHours['ทุกวัน']\n",
    "        for cur_day_of_week in days_of_week:\n",
    "            temp_openingHours[cur_day_of_week] = temp_time\n",
    "\n",
    "    else:\n",
    "        # if there is range between day of week --> convert it to two individual key with same value\n",
    "        # for example: {'จันทร์ - พุธ': '10:00 - 20:30', 'อาทิตย์': '11:00 - 22:30'}\n",
    "        # convert to -> {'จันทร์': '10:00 - 20:30', 'อังคาร': '10:00 - 20:30', 'พุธ': '10:00 - 20:30', 'อาทิตย์': '11:00 - 22:30'}\n",
    "        for key, val in temp_openingHours.copy().items():\n",
    "            cur_split_day_range = key.split(' - ')\n",
    "            if(len(cur_split_day_range) == 1):\n",
    "                continue\n",
    "            # remove current key\n",
    "            del temp_openingHours[key]\n",
    "            # convert to two individual key with same value\n",
    "            is_pass_endDay = False\n",
    "            cur_start_day = cur_split_day_range[0]\n",
    "            cur_end_day = cur_split_day_range[1]\n",
    "            cur_Idx = days_of_week.index(cur_start_day)\n",
    "            while(not is_pass_endDay):\n",
    "                if(days_of_week[cur_Idx] == cur_end_day):\n",
    "                    is_pass_endDay = True\n",
    "                temp_openingHours[days_of_week[cur_Idx]] = val\n",
    "                cur_Idx = (cur_Idx + 1) % len(days_of_week)\n",
    "\n",
    "    # change openingHours to temp_openingHours\n",
    "    return temp_openingHours.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_img(restaurant_page_driver: webdriver) -> list[str]:\n",
    "    img_address = []\n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"start-maximized\")\n",
    "    \n",
    "    try:\n",
    "        find_mark_Idx = restaurant_page_driver.current_url.find('?')\n",
    "        res_mark_Idx = find_mark_Idx if find_mark_Idx != -1 else len(restaurant_page_driver.current_url)\n",
    "        # example of restaurant without photos: https://www.wongnai.com/restaurants/95958BB-%E0%B8%A3%E0%B9%89%E0%B8%B2%E0%B8%99%E0%B8%95%E0%B8%AD%E0%B8%87%E0%B8%AB%E0%B8%99%E0%B8%B6%E0%B9%88%E0%B8%87%E0%B8%AA%E0%B9%80%E0%B8%95%E0%B9%8A%E0%B8%81/photos\n",
    "        \n",
    "        cnt_retry = 0\n",
    "\n",
    "        cnt_proxy_port = 10000\n",
    "        max_proxy_port = 20000\n",
    "\n",
    "        while(True):\n",
    "            if(cnt_retry == 5):\n",
    "                print(\"max retry for scrape_img ...\")\n",
    "                break\n",
    "            # seach image section of current restaurant by this query\n",
    "            all_img_query = '%s/photos' % (restaurant_page_driver.current_url[:res_mark_Idx])\n",
    "\n",
    "            print(\"scrape img...\")\n",
    "            print(\"for: \", all_img_query)\n",
    "\n",
    "            # formulate the proxy url with authentication\n",
    "            proxy_url = f\"http://{os.environ['proxy_username']}:{os.environ['proxy_password']}@{os.environ['proxy_address']}:{cnt_proxy_port}\"\n",
    "            \n",
    "            # change the port with each new request (can use any port from 10000 to 20000). \n",
    "            # for example: in the first request 10000 port in the next request 10001 and so on.\n",
    "            cnt_proxy_port += 1\n",
    "            if(cnt_proxy_port > max_proxy_port):\n",
    "                cnt_proxy_port = 10000\n",
    "\n",
    "            # set selenium-wire options to use the proxy\n",
    "            seleniumwire_options = {\n",
    "                \"proxy\": {\n",
    "                    \"http\": proxy_url,\n",
    "                    \"https\": proxy_url\n",
    "                },\n",
    "            }\n",
    "\n",
    "            # set Chrome options to run in headless mode\n",
    "            options = Options()\n",
    "            options.add_argument(\"start-maximized\")\n",
    "            # options.add_argument(\"--headless=new\")\n",
    "            options.add_experimental_option(\n",
    "                \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    "            )\n",
    "\n",
    "            # initialize the Chrome driver with service, selenium-wire options, and chrome options\n",
    "            all_img_driver = webdriver.Edge(\n",
    "                service=Service(EdgeChromiumDriverManager().install()),\n",
    "                seleniumwire_options=seleniumwire_options,\n",
    "                options=options\n",
    "            )\n",
    "            all_img_driver.get(all_img_query)\n",
    "            print(\"after get to img url --> enter scrape img flow ...\")\n",
    "            \n",
    "            try:\n",
    "                WebDriverWait(all_img_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'brqSoI')))\n",
    "                all_img_elements = all_img_driver.find_elements(By.CLASS_NAME, 'brqSoI')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"retry find img...\")\n",
    "                all_img_driver.quit()\n",
    "                cnt_retry += 1\n",
    "                continue\n",
    "\n",
    "            prev_len = len(all_img_elements)\n",
    "            cnt_scroll_end = 0\n",
    "            max_img_cnt = 250\n",
    "            try:\n",
    "                while(True):\n",
    "                    # check if it scroll and retrive the same amount of image for 3 time\n",
    "                    # or amount of retrived images exceed \"max_img_cnt\" (may remove this condition later if you want all images)\n",
    "                    if(cnt_scroll_end == 3 or prev_len > max_img_cnt):\n",
    "                        break\n",
    "                    # scroll and wait for 2 msec\n",
    "                    all_img_driver.execute_script('window.scrollBy(0, document.body.scrollHeight)')\n",
    "                    time.sleep(2)\n",
    "                    # update value for next iteration\n",
    "                    all_img_elements = all_img_driver.find_elements(By.CLASS_NAME, 'brqSoI')\n",
    "                    cur_len = len(all_img_elements)\n",
    "                    if(prev_len == cur_len): \n",
    "                        cnt_scroll_end += 1\n",
    "                    else:\n",
    "                        cnt_scroll_end = 0\n",
    "                        prev_len = cur_len\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"prn err img 1\")\n",
    "                # pass\n",
    "        \n",
    "            # find image address and save in \"img_address\"\n",
    "            for cur_img_element in all_img_elements:\n",
    "                cur_img_address = cur_img_element.get_attribute('src')\n",
    "                cur_img_address = re.sub(r\"\\d+x\\d+\", \"400x0\", cur_img_address)\n",
    "                if(cur_img_address in img_address):\n",
    "                    break\n",
    "                img_address.append(cur_img_address)\n",
    "\n",
    "            \n",
    "            all_img_driver.quit()\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"cant find image\")\n",
    "\n",
    "    return img_address.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_location(restaurant_page_driver: webdriver, restaurant: Restaurant, province_th: str):\n",
    "\n",
    "    # find better address description on wongnai\n",
    "    # for example: \"8/88 อาคารเรียน ชั้น 2F, หมู่ที่5 ศรีสุนทร ถลาง ภูเก็ต ภูเก็ต (ชาบูชิโรบินสันถลาง) อ่านต่อได้ที่\"\n",
    "    address_wongnai = \"\"\n",
    "    try:\n",
    "        # WebDriverWait(restaurant_page_driver, 10).until(EC.visibility_of_element_located((By.CLASS_NAME, 'jEIapA'))) \n",
    "        possible_addressWongnai_elements = restaurant_page_driver.find_elements(By.CLASS_NAME, 'jEIapA')\n",
    "        for cur_element in possible_addressWongnai_elements:\n",
    "            cur_text = cur_element.text\n",
    "            if(province_th in cur_text):\n",
    "                address_wongnai = cur_text\n",
    "                break\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    print(\"address_wongnai --> \", address_wongnai)\n",
    "    \n",
    "    # find lat, long\n",
    "    lat = 0\n",
    "    long = 0\n",
    "    try:\n",
    "        # WebDriverWait(restaurant_page_driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'meta'))) \n",
    "        all_meta_data = restaurant_page_driver.find_elements(By.TAG_NAME, 'meta')\n",
    "        cnt_lat_long = 0\n",
    "        lat_property = \"place:location:latitude\"\n",
    "        long_property = \"place:location:longitude\"\n",
    "        for cur_meta_data in all_meta_data:\n",
    "            if(cnt_lat_long == 2):\n",
    "                break\n",
    "            cur_property = cur_meta_data.get_attribute('property')\n",
    "            if(cur_property):\n",
    "                if(cur_property == lat_property):\n",
    "                    print(cur_meta_data.get_attribute('content'))\n",
    "                    lat = float(cur_meta_data.get_attribute('content'))\n",
    "                    cnt_lat_long += 1\n",
    "                    continue\n",
    "                elif(cur_property == long_property):\n",
    "                    print(cur_meta_data.get_attribute('content'))\n",
    "                    long = float(cur_meta_data.get_attribute('content'))\n",
    "                    cnt_lat_long += 1\n",
    "                    continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"can't find lat, long\")\n",
    "\n",
    "    print(\"lat : \", lat)\n",
    "    print(\"long : \", long)\n",
    "    \n",
    "    restaurant.set_latitude(lat)\n",
    "    restaurant.set_longitude(long)\n",
    "\n",
    "    ######\n",
    "\n",
    "    # find location data \n",
    "    cnt_retry = 0\n",
    "    \n",
    "    cnt_proxy_port = 10000\n",
    "    max_proxy_port = 20000\n",
    "\n",
    "    # use 'lat', 'long' to find location data \n",
    "    try:\n",
    "        while(True):\n",
    "            if(cnt_retry == 10):\n",
    "                print(\"max retry for scrape Google Map ...\")\n",
    "                break\n",
    "\n",
    "            print(\"scrape Google Map...\")\n",
    "\n",
    "            possible_addressGoogleMap_elements = []        \n",
    "            try:\n",
    "                # formulate the proxy url with authentication\n",
    "                proxy_url = f\"http://{os.environ['proxy_username']}:{os.environ['proxy_password']}@{os.environ['proxy_address']}:{cnt_proxy_port}\"\n",
    "                \n",
    "                # change the port with each new request (can use any port from 10000 to 20000). \n",
    "                # for example: in the first request 10000 port in the next request 10001 and so on.\n",
    "                cnt_proxy_port += 1\n",
    "                if(cnt_proxy_port > max_proxy_port):\n",
    "                    cnt_proxy_port = 10000\n",
    "\n",
    "                # set selenium-wire options to use the proxy\n",
    "                seleniumwire_options = {\n",
    "                    \"proxy\": {\n",
    "                        \"http\": proxy_url,\n",
    "                        \"https\": proxy_url\n",
    "                    },\n",
    "                }\n",
    "\n",
    "                # set Chrome options to run in headless mode\n",
    "                # options = Options()\n",
    "                options = webdriver.ChromeOptions()\n",
    "                options.add_argument(\"start-maximized\")\n",
    "                # options.add_argument(\"--headless=new\")\n",
    "                options.add_experimental_option(\n",
    "                    \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    "                )\n",
    "\n",
    "                # initialize the Chrome driver with service, selenium-wire options, and chrome options\n",
    "                # google_map_driver = webdriver.Edge(\n",
    "                #     service=Service(EdgeChromiumDriverManager().install()),\n",
    "                #     seleniumwire_options=seleniumwire_options,\n",
    "                #     options=options\n",
    "                # )\n",
    "                google_map_driver = webdriver.Chrome(options=options)\n",
    "                \n",
    "                google_map_query = \"https://www.google.com/maps/search/?api=1&query=%s,%s\" % (lat, long)\n",
    "                google_map_driver.get(google_map_query)\n",
    "                \n",
    "                WebDriverWait(google_map_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'DkEaL')))\n",
    "                possible_addressGoogleMap_elements = google_map_driver.find_elements(By.CLASS_NAME, 'DkEaL')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"retry  scrape Google Map..\")\n",
    "                cnt_retry += 1\n",
    "                google_map_driver.close()\n",
    "                continue\n",
    "\n",
    "            # if found some wiered place that doesn't even have its address\n",
    "            # skip this case for now...\n",
    "            if(not len(possible_addressGoogleMap_elements)):\n",
    "                return\n",
    "\n",
    "            subStrDistrict = \"อำเภอ\"\n",
    "            subStrSubDistrict = \"ตำบล\"\n",
    "\n",
    "            if province_th == \"กรุงเทพมหานคร\":\n",
    "                subStrDistrict = \"เขต\"\n",
    "                subStrSubDistrict = \"แขวง\"\n",
    "\n",
    "            district = 0\n",
    "            subDirstrict = 0\n",
    "\n",
    "            # find location\n",
    "            useData = None\n",
    "            for cur_element in possible_addressGoogleMap_elements:\n",
    "                if province_th in cur_element.text and cur_element.text.find(subStrDistrict) != -1:\n",
    "                    useData = cur_element.text.replace(\",\",\"\").replace(\"เเ\",\"แ\")\n",
    "                    break\n",
    "            \n",
    "            if(useData != None):\n",
    "                # print(\"Full Address :\",useData)\n",
    "                # another brute force way in case of province 'กรุงเทพหมานคร' not have word 'แขวง' in address\n",
    "                if(province_th == 'กรุงเทพมหานคร' and useData.find(subStrSubDistrict) == -1):\n",
    "                    subAddress_split = useData.split(' ')\n",
    "                    cur_province_Idx = subAddress_split.index(province_th)\n",
    "                    district = subAddress_split[cur_province_Idx - 1].replace(\"เขต\",\"\")\n",
    "                    subDistrict = subAddress_split[cur_province_Idx - 2].replace(\"แขวง\",\"\")\n",
    "\n",
    "                else:\n",
    "                    start_address_index = useData.find(subStrSubDistrict)\n",
    "                    subAddress = useData[start_address_index:]\n",
    "                    district = subAddress[subAddress.find(subStrDistrict)+len(subStrDistrict):subAddress.find(province_th)].replace(\" \",\"\")               \n",
    "                    subDistrict = subAddress[subAddress.find(subStrSubDistrict)+len(subStrSubDistrict):subAddress.find(subStrDistrict)].replace(\" \",\"\")\n",
    "\n",
    "                if district == \"เมือง\":\n",
    "                    district = district+province_th\n",
    "\n",
    "                # filter row to find 'ISO_3166_code', 'zip_code', 'geo_code'\n",
    "                geo_code_df = pd.read_csv(fh.PATH_TO_GEOCODE)\n",
    "                filtered_rows = geo_code_df[\n",
    "                    (geo_code_df['province_th'] == province_th) & (geo_code_df['district_th'] == district) & (geo_code_df['subDistrict_th'] == subDistrict)\n",
    "                ]\n",
    "                filtered_rows.reset_index(inplace=True, drop=True)\n",
    "                \n",
    "                if not filtered_rows.empty:\n",
    "                    print(\"province :\",filtered_rows.loc[0, 'ISO_3166_code'], province_th)\n",
    "                    print(\"District :\",filtered_rows.loc[0, 'zip_code'], district)\n",
    "                    print(\"SubDistrict :\",filtered_rows.loc[0, 'geo_code'], subDistrict)\n",
    "\n",
    "                    restaurant.set_location(\n",
    "                        address = address_wongnai if len(address_wongnai) else useData,\n",
    "                        province = province_th,\n",
    "                        district = district,\n",
    "                        sub_district = subDistrict,\n",
    "                        province_code = filtered_rows.loc[0, 'ISO_3166_code'],\n",
    "                        district_code = filtered_rows.loc[0, 'zip_code'],\n",
    "                        sub_district_code = filtered_rows.loc[0, 'geo_code']\n",
    "                    )\n",
    "                else:\n",
    "                    print(\"province :\", province_th)\n",
    "                    print(\"District :\", district)\n",
    "                    print(\"SubDistrict :\", subDistrict)\n",
    "\n",
    "                    restaurant.set_location(\n",
    "                        address = address_wongnai if len(address_wongnai) else useData,\n",
    "                        province = province_th,\n",
    "                        district = district,\n",
    "                        sub_district = subDistrict,\n",
    "                        iso_code = 0,\n",
    "                        zip_code = 0,\n",
    "                        geo_code = 0\n",
    "                    )\n",
    "\n",
    "            \n",
    "            google_map_driver.close()\n",
    "            break\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"can't scrape location data\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_single_restaurant(link_to_restaurant: str, restaurant: Restaurant, province_th: str) -> None:\n",
    "\n",
    "    cnt_retry = 0\n",
    "\n",
    "    cnt_proxy_port = 10000\n",
    "    max_proxy_port = 20000    \n",
    "\n",
    "    while(True):\n",
    "\n",
    "        if(cnt_retry == 10):\n",
    "            print(\"max retry for scrape single restaurant ...\")\n",
    "            break\n",
    "\n",
    "        # formulate the proxy url with authentication\n",
    "        proxy_url = f\"http://{os.environ['proxy_username']}:{os.environ['proxy_password']}@{os.environ['proxy_address']}:{cnt_proxy_port}\"\n",
    "        \n",
    "        # change the port with each new request (can use any port from 10000 to 20000). \n",
    "        # for example: in the first request 10000 port in the next request 10001 and so on.\n",
    "        cnt_proxy_port += 1\n",
    "        if(cnt_proxy_port > max_proxy_port):\n",
    "            cnt_proxy_port = 10000\n",
    "\n",
    "        # set selenium-wire options to use the proxy\n",
    "        seleniumwire_options = {\n",
    "            \"proxy\": {\n",
    "                \"http\": proxy_url,\n",
    "                \"https\": proxy_url\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # set Chrome options to run in headless mode\n",
    "        options = Options()\n",
    "        options.add_argument(\"start-maximized\")\n",
    "        # options.add_argument(\"--headless=new\")\n",
    "        options.add_experimental_option(\n",
    "            \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    "        )\n",
    "\n",
    "        # initialize the Chrome driver with service, selenium-wire options, and chrome options\n",
    "        restaurant_page_driver = webdriver.Edge(\n",
    "            service=Service(EdgeChromiumDriverManager().install()),\n",
    "            seleniumwire_options=seleniumwire_options,\n",
    "            options=options\n",
    "        )\n",
    "        \n",
    "        print(\"scrape single restaurant...\")\n",
    "        print(\"for restaurant : \", link_to_restaurant)\n",
    "        restaurant_page_driver.get(link_to_restaurant)\n",
    "\n",
    "        try:\n",
    "            print(\"debug scrape_single_restaurant: map, phone text section\")\n",
    "            WebDriverWait(restaurant_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'jEIapA')))\n",
    "            print(\"debug scrape_single_restaurant: aside section\")\n",
    "            WebDriverWait(restaurant_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'dUuuBs')))\n",
    "            print(\"debug scrape_single_restaurant: meta data for lat/long\")\n",
    "            WebDriverWait(restaurant_page_driver, 1).until(EC.presence_of_element_located((By.TAG_NAME, 'meta'))) \n",
    "            \n",
    "        except Exception as e:\n",
    "            cnt_retry += 1\n",
    "            restaurant_page_driver.quit()\n",
    "            print(\"retry single restaurant...\")\n",
    "            continue\n",
    "\n",
    "        # find description\n",
    "        description = \"\"\n",
    "        try:\n",
    "            # example of restaurant with description: https://www.wongnai.com/restaurants/2928132aX-hisoviet-%E0%B9%84%E0%B8%AE%E0%B9%82%E0%B8%8B%E0%B9%80%E0%B8%A7%E0%B8%B5%E0%B8%A2%E0%B8%95-%E0%B8%82%E0%B9%89%E0%B8%B2%E0%B8%A7%E0%B9%80%E0%B8%9B%E0%B8%B5%E0%B8%A2%E0%B8%81%E0%B8%AB%E0%B8%99%E0%B9%89%E0%B8%B2%E0%B9%80%E0%B8%97%E0%B8%A8%E0%B8%9A%E0%B8%B2%E0%B8%A5?_st=cD0wO2I9MjkyODEzMjthZD10cnVlO3Q9MTcyNjE3NjI3NzUxNjtyaT0xWDdiNXdpcUxlbUhTRnByR1BwdmZzMnFTdkNWYm87aT0xWDcwWkdVUXZCeEgyWVdCM3owSzNSbTVxUklOVU07d3JlZj1zcjs%3D\n",
    "            try:\n",
    "                WebDriverWait(restaurant_page_driver, 1).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"contentRow\"]/div[1]/div[5]/p/span'))) \n",
    "                click_read_more =  restaurant_page_driver.find_element(By.XPATH, '//*[@id=\"contentRow\"]/div[1]/div[5]/p/span')\n",
    "                click_read_more.click()\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            WebDriverWait(restaurant_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"contentRow\"]/div[1]/div[5]/p'))) \n",
    "            description = restaurant_page_driver.find_element(By.XPATH, '//*[@id=\"contentRow\"]/div[1]/div[5]/p').text\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        print(\"description -> \", description)\n",
    "\n",
    "        # find phones\n",
    "        phones = []\n",
    "        try:\n",
    "            WebDriverWait(restaurant_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'jEIapA'))) \n",
    "            possible_phone_elements = restaurant_page_driver.find_elements(By.CLASS_NAME, 'jEIapA')\n",
    "            print(\"prn check possible phone ele:\")\n",
    "            print(possible_phone_elements)\n",
    "            for cur_element in possible_phone_elements:\n",
    "                cur_text = cur_element.text\n",
    "                if(\"เบอร์โทร : \" in cur_text):\n",
    "                    phones = cur_text.split(\"เบอร์โทร : \")[-1].split(\", \").copy()\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            print(\"no phones ...\")\n",
    "\n",
    "        print(\"phone -> \", phones)\n",
    "\n",
    "        # find websites\n",
    "        all_website_dict = {}\n",
    "        try:\n",
    "            WebDriverWait(restaurant_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'kKDiaN'))) \n",
    "            WebDriverWait(restaurant_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'cXFOMU'))) \n",
    "            container_website_elements = restaurant_page_driver.find_element(By.CLASS_NAME, 'kKDiaN')\n",
    "            all_website_elements = container_website_elements.find_elements(By.CLASS_NAME, 'cXFOMU')\n",
    "            for cur_website in all_website_elements:\n",
    "                cur_website_name = cur_website.text\n",
    "                cur_website_link = cur_website.get_attribute('href')\n",
    "                all_website_dict[cur_website_name] = cur_website_link\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"no website ...\")\n",
    "\n",
    "        print(all_website_dict)\n",
    "\n",
    "        # find price range\n",
    "        priceRange = \"\"\n",
    "        try:\n",
    "            WebDriverWait(restaurant_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'hpJBMe')))\n",
    "            possible_priceRange_elements = restaurant_page_driver.find_elements(By.CLASS_NAME, 'hpJBMe')\n",
    "            for cur_element in possible_priceRange_elements:\n",
    "                cur_text = cur_element.text\n",
    "                if(\"บาท\" in cur_text):\n",
    "                    priceRange = cur_text.replace('(', '').replace(')', '')\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            print(\"no price range ...\")        \n",
    "        \n",
    "        print(\"priceRange -> \", priceRange)\n",
    "\n",
    "        # find facilities\n",
    "        facilities = []\n",
    "        try:\n",
    "            # there will be diffrent XPATH for facilities section\n",
    "            container_list_facilities = None\n",
    "            is_find_container_list = False\n",
    "            try:\n",
    "                WebDriverWait(restaurant_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"contentRow\"]/div[2]/div/div[1]/div[2]/div/ul')))\n",
    "                container_list_facilities = restaurant_page_driver.find_element(By.XPATH, '//*[@id=\"contentRow\"]/div[2]/div/div[1]/div[2]/div/ul')\n",
    "                is_find_container_list = True\n",
    "                print(\"find facilities on div[2]\")\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "            if(not is_find_container_list):\n",
    "                WebDriverWait(restaurant_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"contentRow\"]/div[2]/div/div[1]/div[1]/div/ul')))\n",
    "                container_list_facilities = restaurant_page_driver.find_element(By.XPATH, '//*[@id=\"contentRow\"]/div[2]/div/div[1]/div[1]/div/ul')\n",
    "                print(\"find facilities on div[1]\")\n",
    "\n",
    "            WebDriverWait(restaurant_page_driver, 1).until(EC.visibility_of_element_located((By.TAG_NAME, 'li')))\n",
    "            all_list_facilities = container_list_facilities.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "            for cur_list_element in all_list_facilities:\n",
    "                all_span_elements = cur_list_element.find_elements(By.TAG_NAME, 'span')\n",
    "                allowed_className = \"buIyWl\"\n",
    "                # not_allowed_className = \"McJoy\"\n",
    "                for cur_span in all_span_elements:\n",
    "                    cur_class =  cur_span.get_attribute('class')\n",
    "                    is_allowed_facility_span = (allowed_className in cur_class)\n",
    "\n",
    "                    # check if is facility with correct mark symbol -> if it is then continue scrape for facility\n",
    "                    if(is_allowed_facility_span):\n",
    "                        cur_text = cur_list_element.find_element(By.CLASS_NAME, 'fFYUJu').text\n",
    "                        try:\n",
    "                            cur_sub_text = cur_list_element.find_element(By.CLASS_NAME, 'gFBGSr').text\n",
    "                            cur_text = ('%s %s') % (cur_text, cur_sub_text)\n",
    "                        except Exception as e:\n",
    "                            pass\n",
    "                        \n",
    "                        facilities.append(cur_text)\n",
    "                        break\n",
    "\n",
    "            print(\"cur facilities -> \", facilities)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"no facilities ...\")\n",
    "\n",
    "        # find rating\n",
    "        rating = 0\n",
    "        ratingCount = 0\n",
    "        try:\n",
    "            WebDriverWait(restaurant_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"contentRow\"]/div[1]/div[1]/div/div[1]/div/div[1]/div[1]/div/div/div/div')))\n",
    "            WebDriverWait(restaurant_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"contentRow\"]/div[1]/div[1]/div/div[1]/div/div[1]/span/span[2]')))\n",
    "            rating_element = restaurant_page_driver.find_element(By.XPATH, '//*[@id=\"contentRow\"]/div[1]/div[1]/div/div[1]/div/div[1]/div[1]/div/div/div/div')\n",
    "            ratingCount_element = restaurant_page_driver.find_element(By.XPATH, '//*[@id=\"contentRow\"]/div[1]/div[1]/div/div[1]/div/div[1]/span/span[2]')\n",
    "            \n",
    "            rating = float(rating_element.text)\n",
    "            ratingCount = int(ratingCount_element.text.split(' ')[0][1:])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"can't find rating and ratingCount\")\n",
    "\n",
    "        print(\"rating --> \", rating)\n",
    "        print(\"ratingCount --> \", ratingCount)\n",
    "\n",
    "        # find openingHours\n",
    "        openingHours = {}\n",
    "        try:\n",
    "            WebDriverWait(restaurant_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'gdNTro')))\n",
    "            all_openingHours_element = restaurant_page_driver.find_elements(By.CLASS_NAME, 'gdNTro')\n",
    "            for cur_openingHours_element in all_openingHours_element:\n",
    "                cur_all_td_elements = cur_openingHours_element.find_elements(By.TAG_NAME, 'td')\n",
    "                cur_day = cur_all_td_elements[0].text\n",
    "                cur_time = cur_all_td_elements[1].text\n",
    "                openingHours[cur_day] = cur_time\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"no opening hours ...\")\n",
    "\n",
    "        openingHours = convert_openinghours(openingHours)\n",
    "        print(\"cur opening hours: \")\n",
    "        print(openingHours)\n",
    "        \n",
    "        # scrape location\n",
    "        scrape_location(\n",
    "            restaurant_page_driver = restaurant_page_driver,\n",
    "            restaurant = restaurant,\n",
    "            province_th = province_th\n",
    "        )\n",
    "\n",
    "        # scrape image path\n",
    "        img_path = scrape_img(restaurant_page_driver)\n",
    "        print(\"cur img path -> \", img_path)\n",
    "\n",
    "        # set some of \"Restaurant\" object properties\n",
    "        restaurant.set_description(description)\n",
    "        restaurant.set_phone(phones)\n",
    "        restaurant.set_website(all_website_dict)\n",
    "        restaurant.set_priceRange(priceRange)\n",
    "        restaurant.set_facility(facilities)\n",
    "        restaurant.set_openingHour(openingHours)\n",
    "        restaurant.set_imgPath(img_path)\n",
    "        restaurant.set_rating(\n",
    "            score = rating, \n",
    "            rating_count = ratingCount\n",
    "        )\n",
    "        \n",
    "        restaurant_page_driver.quit()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_by_page(query_url: str, res_restaurant_df: pd.DataFrame) -> list[tuple]:\n",
    "    \n",
    "    # array of tuple which its elements will be use for retriving all current page restaurants data(in single page)\n",
    "    '''\n",
    "    res_data_by_page = [\n",
    "        ('name_page_1_1', 'sub_name_page_1_1', 'type_page_1_1', 'wonnai_url_page_1_1'),\n",
    "        ('name_page_1_2', 'sub_name_page_1_2', 'type_page_1_2', 'wonnai_url_page_1_2'),\n",
    "        ..... ,\n",
    "        ('name_page_1_last', 'sub_name_page_1_last', 'type_page_1_last', 'wonnai_url_page_1_last')\n",
    "    ]\n",
    "    '''\n",
    "    res_data_by_page = []\n",
    "    \n",
    "    cnt_retry = 0\n",
    "\n",
    "    cnt_proxy_port = 10000\n",
    "    max_proxy_port = 20000\n",
    "    \n",
    "    while(True):\n",
    "        \n",
    "        if(cnt_retry == 10):\n",
    "            print(\"max retry for scrape data by page ...\")\n",
    "            break\n",
    "\n",
    "        # formulate the proxy url with authentication\n",
    "        proxy_url = f\"http://{os.environ['proxy_username']}:{os.environ['proxy_password']}@{os.environ['proxy_address']}:{cnt_proxy_port}\"\n",
    "        \n",
    "        # change the port with each new request (can use any port from 10000 to 20000). \n",
    "        # for example: in the first request 10000 port in the next request 10001 and so on.\n",
    "        cnt_proxy_port += 1\n",
    "        if(cnt_proxy_port > max_proxy_port):\n",
    "            cnt_proxy_port = 10000\n",
    "\n",
    "        # set selenium-wire options to use the proxy\n",
    "        seleniumwire_options = {\n",
    "            \"proxy\": {\n",
    "                \"http\": proxy_url,\n",
    "                \"https\": proxy_url\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # set Chrome options to run in headless mode\n",
    "        options = Options()\n",
    "        options.add_argument(\"start-maximized\")\n",
    "        # options.add_argument(\"--headless=new\")\n",
    "        options.add_experimental_option(\n",
    "            \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    "        )\n",
    "      \n",
    "        # initialize the Chrome driver with service, selenium-wire options, and chrome options\n",
    "        driver = webdriver.Edge(\n",
    "            service=Service(EdgeChromiumDriverManager().install()),\n",
    "            seleniumwire_options=seleniumwire_options,\n",
    "            options=options\n",
    "        )\n",
    "        driver.get(query_url)\n",
    "        # scroll and wait for some msec\n",
    "        driver.execute_script('window.scrollBy(0, document.body.scrollHeight)')\n",
    "        # time.sleep(2)\n",
    "\n",
    "        print(\"check current page url --> \", driver.current_url)\n",
    "\n",
    "        # find group of restaurant on the nth page\n",
    "        all_restaurants_card = []\n",
    "        all_clickable_elements = []\n",
    "        try:\n",
    "            # wait for div (each restaurant section) to be present and visible\n",
    "            print(\"debug get_data_by_page: restaurants by one page section\")\n",
    "            WebDriverWait(driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'bcxPmJ')))\n",
    "            # wait for name, type element to be present and visible\n",
    "            print(\"debug get_data_by_page: name section\")\n",
    "            WebDriverWait(driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'Dtkmv')))\n",
    "            print(\"debug get_data_by_page: type section\")\n",
    "            WebDriverWait(driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'okmRN')))\n",
    "\n",
    "            all_restaurants_card = driver.find_elements(By.CLASS_NAME, 'dibyTT')\n",
    "            all_clickable_elements = driver.find_elements(By.CLASS_NAME, 'fsElrZ')\n",
    "            print(\"check cur current page elements --> \", all_restaurants_card)\n",
    "            print(\"len all page elements --> \", len(all_restaurants_card))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"retry find all_restaurants_card ...\")\n",
    "            cnt_retry += 1\n",
    "            driver.quit()\n",
    "            continue\n",
    "\n",
    "        # iterate to scrape each restaurant\n",
    "\n",
    "        for cur_restaurant_card, cur_clickable_element in zip(all_restaurants_card, all_clickable_elements):\n",
    "            # find restaurant name\n",
    "            cur_name = ''\n",
    "            cur_sub_name = ''\n",
    "\n",
    "            try:\n",
    "                # WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CLASS_NAME, 'Dtkmv')))\n",
    "                cur_name = cur_restaurant_card.find_element(By.CLASS_NAME, 'Dtkmv').text\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"err find name : \")\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "            # cut substring if there is sub name\n",
    "            try:\n",
    "                WebDriverWait(driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'dqdias')))\n",
    "                cur_sub_name = cur_restaurant_card.find_element(By.CLASS_NAME, 'dqdias').text\n",
    "                print(\"sub name -> \", cur_sub_name)\n",
    "                cur_Idx_sub_name = cur_name.rfind(cur_sub_name)\n",
    "                cur_name = cur_name[:cur_Idx_sub_name]\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(\"sub name\")\n",
    "\n",
    "            print('name -> ', cur_name)\n",
    "\n",
    "            # check if there is duplicate name of restaurant\n",
    "            if(not res_restaurant_df[(res_restaurant_df['name'] == cur_name) & (res_restaurant_df['sub_name'] == cur_sub_name)].empty):\n",
    "                print(\"find duplicate restaurant | name --> %s | sub_name --> %s\" % (cur_name, cur_sub_name))\n",
    "                continue\n",
    "\n",
    "            # find restaurant types\n",
    "            cur_restaurant_types = []\n",
    "            try:\n",
    "                # WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CLASS_NAME, 'okmRN')))\n",
    "                cur_restaurant_tags_elements = cur_restaurant_card.find_elements(By.CLASS_NAME, 'okmRN')\n",
    "                for cur_element in cur_restaurant_tags_elements:\n",
    "                    cur_restaurant_types.append(cur_element.text)\n",
    "            except Exception as e:\n",
    "                print(\"can't find types\")\n",
    "                continue\n",
    "\n",
    "            print(\"cur type -> \", cur_restaurant_types)\n",
    "\n",
    "            # find wongnai url of restaurant\n",
    "            cur_to_restaurant = cur_clickable_element.get_attribute('href')\n",
    "            print(\"check cur_to_restaurant --> \", cur_to_restaurant)\n",
    "\n",
    "            # add to result array of tuple \"res_data_by_page\"\n",
    "            res_data_by_page.append(\n",
    "                (cur_name, cur_sub_name, cur_restaurant_types, cur_to_restaurant)\n",
    "            )\n",
    "\n",
    "        driver.quit()\n",
    "        break\n",
    "    \n",
    "    return res_data_by_page.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_restaurants_by_province(province: str, wongnai_regionId: str) -> pd.DataFrame:\n",
    "\n",
    "    # res_restaurant_df = pd.DataFrame()\n",
    "    res_restaurant_df = create_restaurant_df(Restaurant())\n",
    "    \n",
    "    cnt_for_debug = 0\n",
    "\n",
    "    while(True):\n",
    "        if(cnt_for_debug == 1):\n",
    "            break\n",
    "        cnt_for_debug += 1\n",
    "        \n",
    "        print(\"scraping restaurant | province --> %s | page --> %s\" % (province, cnt_for_debug))\n",
    "        cur_query_url = \"https://www.wongnai.com/restaurants?categoryGroupId=9&regions=%s&page.number=%s\" % (wongnai_regionId, cnt_for_debug)\n",
    "        \n",
    "        try:\n",
    "            # get all name, subname, type, wongnai_url of all restaurant in current page\n",
    "            all_get_data_by_page = get_data_by_page(query_url=cur_query_url, res_restaurant_df=res_restaurant_df)\n",
    "            \n",
    "            # use data from 'res_get_data_by_page' to retrive data of specific restaurant\n",
    "            for cur_data_by_page in all_get_data_by_page:\n",
    "                cur_restaurant = Restaurant()\n",
    "                # get 'name', 'sub_name', 'type', 'wongnai_url'\n",
    "                cur_name = cur_data_by_page[0]\n",
    "                cur_sub_name = cur_data_by_page[1]\n",
    "                cur_types = cur_data_by_page[2]\n",
    "                cur_wongnai_url = cur_data_by_page[3]\n",
    "                \n",
    "                # continue scraping data for a specific resgtaurant\n",
    "                scrape_single_restaurant(\n",
    "                    link_to_restaurant = cur_wongnai_url,\n",
    "                    restaurant = cur_restaurant,\n",
    "                    province_th = province\n",
    "                )\n",
    "                \n",
    "                # set 'Restaurant' object properties (some of them will be set in method \"scrape_restaurant\")\n",
    "                cur_restaurant.set_name(cur_name)\n",
    "                cur_restaurant.set_sub_name(cur_sub_name)\n",
    "                cur_restaurant.set_restaurantType(cur_types)\n",
    "                cur_restaurant.set_wongnai_url(cur_wongnai_url)\n",
    "                \n",
    "                # create data frame represent data scrape from current restaurant card\n",
    "                cur_restaurant_df = create_restaurant_df(restaurant=cur_restaurant)\n",
    "\n",
    "                # concat all data frame result\n",
    "                res_restaurant_df = pd.concat([res_restaurant_df, cur_restaurant_df])\n",
    "        \n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    return res_restaurant_df.iloc[1:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory res_restaurant_scraping created successfully\n",
      "scraping restaurant | province --> ภูเก็ต | page --> 1\n",
      "check current page url -->  https://www.wongnai.com/restaurants?categoryGroupId=9&regions=843&page.number=1\n",
      "debug get_data_by_page: restaurants by one page section\n",
      "retry find all_restaurants_card ...\n",
      "check current page url -->  https://www.wongnai.com/restaurants?categoryGroupId=9&regions=843&page.number=1\n",
      "debug get_data_by_page: restaurants by one page section\n",
      "debug get_data_by_page: name section\n",
      "debug get_data_by_page: type section\n",
      "check cur current page elements -->  [<selenium.webdriver.remote.webelement.WebElement (session=\"c17e22e79ad1b822d7a73557de8a1836\", element=\"f.240442DF06A6018388DC6300C5AB73B7.d.9A28FB128B7DAA19CD02B5F56F2C6DF9.e.694\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c17e22e79ad1b822d7a73557de8a1836\", element=\"f.240442DF06A6018388DC6300C5AB73B7.d.9A28FB128B7DAA19CD02B5F56F2C6DF9.e.762\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c17e22e79ad1b822d7a73557de8a1836\", element=\"f.240442DF06A6018388DC6300C5AB73B7.d.9A28FB128B7DAA19CD02B5F56F2C6DF9.e.815\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c17e22e79ad1b822d7a73557de8a1836\", element=\"f.240442DF06A6018388DC6300C5AB73B7.d.9A28FB128B7DAA19CD02B5F56F2C6DF9.e.876\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c17e22e79ad1b822d7a73557de8a1836\", element=\"f.240442DF06A6018388DC6300C5AB73B7.d.9A28FB128B7DAA19CD02B5F56F2C6DF9.e.943\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c17e22e79ad1b822d7a73557de8a1836\", element=\"f.240442DF06A6018388DC6300C5AB73B7.d.9A28FB128B7DAA19CD02B5F56F2C6DF9.e.992\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c17e22e79ad1b822d7a73557de8a1836\", element=\"f.240442DF06A6018388DC6300C5AB73B7.d.9A28FB128B7DAA19CD02B5F56F2C6DF9.e.1050\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c17e22e79ad1b822d7a73557de8a1836\", element=\"f.240442DF06A6018388DC6300C5AB73B7.d.9A28FB128B7DAA19CD02B5F56F2C6DF9.e.1101\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c17e22e79ad1b822d7a73557de8a1836\", element=\"f.240442DF06A6018388DC6300C5AB73B7.d.9A28FB128B7DAA19CD02B5F56F2C6DF9.e.1150\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c17e22e79ad1b822d7a73557de8a1836\", element=\"f.240442DF06A6018388DC6300C5AB73B7.d.9A28FB128B7DAA19CD02B5F56F2C6DF9.e.1217\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c17e22e79ad1b822d7a73557de8a1836\", element=\"f.240442DF06A6018388DC6300C5AB73B7.d.9A28FB128B7DAA19CD02B5F56F2C6DF9.e.1268\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c17e22e79ad1b822d7a73557de8a1836\", element=\"f.240442DF06A6018388DC6300C5AB73B7.d.9A28FB128B7DAA19CD02B5F56F2C6DF9.e.1318\")>]\n",
      "len all page elements -->  12\n",
      "sub name ->  Phuket\n",
      "name ->  Deven's Chef Restaurant\n",
      "cur type ->  ['อาหารอินเดีย']\n",
      "check cur_to_restaurant -->  https://www.wongnai.com/restaurants/275423Yu-deven-s-chef-restaurant-phuket\n",
      "sub name ->  5 ถนนพูลผลภูเก็ต\n",
      "name ->  ยศข้าวต้ม\n",
      "cur type ->  ['ร้านข้าวต้ม', 'อาหารตามสั่ง']\n",
      "check cur_to_restaurant -->  https://www.wongnai.com/restaurants/454504ca-%E0%B8%A2%E0%B8%A8%E0%B8%82%E0%B9%89%E0%B8%B2%E0%B8%A7%E0%B8%95%E0%B9%89%E0%B8%A1-5-%E0%B8%96%E0%B8%99%E0%B8%99%E0%B8%9E%E0%B8%B9%E0%B8%A5%E0%B8%9C%E0%B8%A5%E0%B8%A0%E0%B8%B9%E0%B9%80%E0%B8%81%E0%B9%87%E0%B8%95?_st=cD0xO2I9NDU0NTA0O2FkPXRydWU7dD0xNzI2NzczODg3MDYxO3JpPTFYN2I2R0c4TnFGTVVDUEE5VUVzVTd5UDZkbDMyYztpPTFYNzBaYTFpbGQ3TmxTZ0prZFRZamV1Y3c0TU82Mzt3cmVmPXNyOw%3D%3D\n",
      "sub name ->  Patong\n",
      "name ->  Napa Massage\n",
      "cur type ->  ['คาเฟ่']\n",
      "check cur_to_restaurant -->  https://www.wongnai.com/restaurants/2686171Bf-napa-massage-patong?_st=cD0yO2I9MjY4NjE3MTthZD1mYWxzZTt0PTE3MjY3NzM2NzIyNzQ7cmk9MVg3YjZHRmhRRWtYSEpLY2FpVU5URGhuVlNtakVtO2k9MVg3MFphMUhpdXVFVW42QkEzb2MzeGdnaDZNcGtiO3dyZWY9c3I7\n",
      "sub name ->  สามกอง ภูเก็ต\n",
      "name ->  Pizza Hut\n",
      "cur type ->  ['พิซซ่า', 'ฟาสต์ฟู้ด/จานด่วน']\n",
      "check cur_to_restaurant -->  https://www.wongnai.com/restaurants/288696XG-pizza-hut-%E0%B8%AA%E0%B8%B2%E0%B8%A1%E0%B8%81%E0%B8%AD%E0%B8%87-%E0%B8%A0%E0%B8%B9%E0%B9%80%E0%B8%81%E0%B9%87%E0%B8%95?_st=cD0zO2I9Mjg4Njk2O2FkPWZhbHNlO3Q9MTcyNjc3Mzg4NzA3NTtyaT0xWDdiNkdHOE9YRW9tOXFFUW43WnpyVVRtdTU2WEE7aT0xWDcwWmExaWxkN05sU2dKa2RUWWpldWN3NE1PNjM7d3JlZj1zcjs%3D\n",
      "sub name ->  Phuket Floresta\n",
      "name ->  Tops Eatery\n",
      "cur type ->  ['อาหารนานาชาติ']\n",
      "check cur_to_restaurant -->  https://www.wongnai.com/restaurants/2133567Cu-tops-eatery-phuket-floresta?_st=cD00O2I9MjEzMzU2NzthZD1mYWxzZTt0PTE3MjY3NzM4ODcwNzY7cmk9MVg3YjZHRzhMdG9QNkJzTEo3a2RtaENoZEdRaVN0O2k9MVg3MFphMWlsZDdObFNnSmtkVFlqZXVjdzRNTzYzO3dyZWY9c3I7\n",
      "sub name ->  มาร์เก็ตวิลเลจ ภูเก็ต\n",
      "name ->  Pizza Hut\n",
      "cur type ->  ['พิซซ่า', 'ฟาสต์ฟู้ด/จานด่วน']\n",
      "check cur_to_restaurant -->  https://www.wongnai.com/restaurants/1962505ug-pizza-hut-%E0%B8%A1%E0%B8%B2%E0%B8%A3%E0%B9%8C%E0%B9%80%E0%B8%81%E0%B9%87%E0%B8%95%E0%B8%A7%E0%B8%B4%E0%B8%A5%E0%B9%80%E0%B8%A5%E0%B8%88-%E0%B8%A0%E0%B8%B9%E0%B9%80%E0%B8%81%E0%B9%87%E0%B8%95?_st=cD01O2I9MTk2MjUwNTthZD1mYWxzZTt0PTE3MjY3NzM4ODcwNzc7cmk9MVg3YjZHRzhTNkx3UlU3eHZscDBlTG5BbXBvQ0ZkO2k9MVg3MFphMWlsZDdObFNnSmtkVFlqZXVjdzRNTzYzO3dyZWY9c3I7\n",
      "sub name ->  ภูเก็ต\n",
      "name ->  โกเบนซ์ภูเก็ต\n",
      "cur type ->  ['อื่นๆ']\n",
      "check cur_to_restaurant -->  https://www.wongnai.com/restaurants/goben?_st=cD02O2I9ODU2NDthZD1mYWxzZTt0PTE3MjY3NzM4ODcwNzc7cmk9MVg3YjZHRzhQN2h1YzhZeDNqeEkwd2ptdzJqMEtUO2k9MVg3MFphMWlsZDdObFNnSmtkVFlqZXVjdzRNTzYzO3dyZWY9c3I7\n",
      "sub name ->  Porto de Phuket\n",
      "name ->  Tops Eatery\n",
      "cur type ->  ['อาหารนานาชาติ']\n",
      "check cur_to_restaurant -->  https://www.wongnai.com/restaurants/2133570IB-tops-eatery-porto-de-phuket?_st=cD03O2I9MjEzMzU3MDthZD1mYWxzZTt0PTE3MjY3NzM4ODcwNzg7cmk9MVg3YjZHRzhMZ2tKRmJjNFUxRGdlUHVhWFRZT2xPO2k9MVg3MFphMWlsZDdObFNnSmtkVFlqZXVjdzRNTzYzO3dyZWY9c3I7\n",
      "sub name ->  -\n",
      "name ->  Tiger Kola\n",
      "cur type ->  ['อาหารตามสั่ง']\n",
      "check cur_to_restaurant -->  https://www.wongnai.com/restaurants/2043844fT-tiger-kola?_st=cD04O2I9MjA0Mzg0NDthZD1mYWxzZTt0PTE3MjY3NzM4ODcwNzk7cmk9MVg3YjZHRzhSNDdRTUo3aENvang3Y3I1WmlwbEQ1O2k9MVg3MFphMWlsZDdObFNnSmtkVFlqZXVjdzRNTzYzO3dyZWY9c3I7\n",
      "sub name ->  น้ำเต้าหู้สามกอง\n",
      "name ->  สามกองน้ำเต้าหู้ ๒๕๓๘\n",
      "cur type ->  ['อาหารคลีน/สลัด', 'ของหวาน']\n",
      "check cur_to_restaurant -->  https://www.wongnai.com/restaurants/9997DH-%E0%B8%AA%E0%B8%B2%E0%B8%A1%E0%B8%81%E0%B8%AD%E0%B8%87%E0%B8%99%E0%B9%89%E0%B8%B3%E0%B9%80%E0%B8%95%E0%B9%89%E0%B8%B2%E0%B8%AB%E0%B8%B9%E0%B9%89-%E0%B9%92%E0%B9%95%E0%B9%93%E0%B9%98-%E0%B8%99%E0%B9%89%E0%B8%B3%E0%B9%80%E0%B8%95%E0%B9%89%E0%B8%B2%E0%B8%AB%E0%B8%B9%E0%B9%89%E0%B8%AA%E0%B8%B2%E0%B8%A1%E0%B8%81%E0%B8%AD%E0%B8%87?_st=cD05O2I9OTk5NzthZD1mYWxzZTt0PTE3MjY3NzM4ODcwODA7cmk9MVg3YjZHRzhRQ1poanMzdjhPTUdNSXpxYThsV3hlO2k9MVg3MFphMWlsZDdObFNnSmtkVFlqZXVjdzRNTzYzO3dyZWY9c3I7\n",
      "sub name\n",
      "name ->  Baba Pool Club @ศรีพันวา\n",
      "cur type ->  ['กึ่งผับ/ร้านเหล้า/บาร์', 'อาหารนานาชาติ']\n",
      "check cur_to_restaurant -->  https://www.wongnai.com/restaurants/babapoolclub?_st=cD0xMDtiPTI2MjA5O2FkPWZhbHNlO3Q9MTcyNjc3Mzg4NzA4MDtyaT0xWDdiNkdHOFNJV1VTZzNGeHJmaERkOHM4N0RqZXA7aT0xWDcwWmExaWxkN05sU2dKa2RUWWpldWN3NE1PNjM7d3JlZj1zcjs%3D\n",
      "sub name\n",
      "name ->  ร้านน้ำย้อย\n",
      "cur type ->  ['อาหารไทย', 'อาหารใต้']\n",
      "check cur_to_restaurant -->  https://www.wongnai.com/restaurants/110423VC-%E0%B8%A3%E0%B9%89%E0%B8%B2%E0%B8%99%E0%B8%99%E0%B9%89%E0%B8%B3%E0%B8%A2%E0%B9%89%E0%B8%AD%E0%B8%A2?_st=cD0xMTtiPTExMDQyMzthZD1mYWxzZTt0PTE3MjY3NzM4ODcwODA7cmk9MVg3YjZHRzhPWmJEb08wdDl3N0p5V1VtcnNabnhLO2k9MVg3MFphMWlsZDdObFNnSmtkVFlqZXVjdzRNTzYzO3dyZWY9c3I7\n",
      "scrape single restaurant...\n",
      "for restaurant :  https://www.wongnai.com/restaurants/275423Yu-deven-s-chef-restaurant-phuket\n",
      "debug scrape_single_restaurant: map, phone text section\n",
      "retry single restaurant...\n",
      "scrape single restaurant...\n",
      "for restaurant :  https://www.wongnai.com/restaurants/275423Yu-deven-s-chef-restaurant-phuket\n",
      "debug scrape_single_restaurant: map, phone text section\n",
      "debug scrape_single_restaurant: aside section\n",
      "debug scrape_single_restaurant: meta data for lat/long\n",
      "description ->  \n",
      "prn check possible phone ele:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"021e81b70f9744112e742fd49705eff1\", element=\"f.81E4F8E09E9D823A63DB3C42053ACA38.d.A9337A2FD7D5255D617277A2D6053AEE.e.882\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"021e81b70f9744112e742fd49705eff1\", element=\"f.81E4F8E09E9D823A63DB3C42053ACA38.d.A9337A2FD7D5255D617277A2D6053AEE.e.891\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"021e81b70f9744112e742fd49705eff1\", element=\"f.81E4F8E09E9D823A63DB3C42053ACA38.d.A9337A2FD7D5255D617277A2D6053AEE.e.900\")>]\n",
      "phone ->  ['0942395225']\n",
      "{'Facebook': 'https://www.facebook.com/Devenchefrestaurant', 'Instagram': 'https://instagram.com/deveninterchef', 'LINE@': 'http://line.naver.jp/ti/p/@indianfoods'}\n",
      "priceRange ->  251 - 500 บาท\n",
      "find facilities on div[2]\n",
      "cur facilities ->  ['ที่จอดรถ (มีที่จอดรถ)', 'Wi-Fi มี Wi-Fi บริการฟรี', 'เดลิเวอรี', 'เหมาะสำหรับเด็กๆ', 'เหมาะสำหรับมาเป็นกลุ่ม']\n",
      "rating -->  4.3\n",
      "ratingCount -->  30\n",
      "cur opening hours: \n",
      "{'อาทิตย์': '10:00 - 22:00', 'จันทร์': '10:00 - 22:00', 'อังคาร': '10:00 - 22:00', 'พุธ': '10:00 - 22:00', 'พฤหัสบดี': '10:00 - 22:00', 'ศุกร์': '10:00 - 22:00', 'เสาร์': '10:00 - 22:00'}\n",
      "address_wongnai -->  38/3, หมู่บ้าน 5 วิชิต เมืองภูเก็ต ภูเก็ต ภูเก็ต (Park 38 Hotels)\n",
      "7.8967736558925\n",
      "98.366336803883\n",
      "lat :  7.8967736558925\n",
      "long :  98.366336803883\n",
      "scrape Google Map...\n",
      "province : 83 ภูเก็ต\n",
      "District : 8301 เมืองภูเก็ต\n",
      "SubDistrict : 830105 วิชิต\n",
      "scrape img...\n",
      "for:  https://www.wongnai.com/restaurants/275423Yu-deven-s-chef-restaurant-phuket/photos\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m cur_regionId \u001b[38;5;241m=\u001b[39m cur_region_data[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# get dataframe result of all restaurants in current province\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m cur_res_allRestaurants_df \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_restaurants_by_province\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwongnai_regionId\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_regionId\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovince\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_province_th\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# remove duplicate restaurant \u001b[39;00m\n\u001b[0;32m     19\u001b[0m cur_res_allRestaurants_df\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub_name\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[53], line 30\u001b[0m, in \u001b[0;36mscrape_restaurants_by_province\u001b[1;34m(province, wongnai_regionId)\u001b[0m\n\u001b[0;32m     27\u001b[0m cur_wongnai_url \u001b[38;5;241m=\u001b[39m cur_data_by_page[\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# continue scraping data for a specific resgtaurant\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[43mscrape_single_restaurant\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlink_to_restaurant\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_wongnai_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestaurant\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_restaurant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovince_th\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprovince\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# set 'Restaurant' object properties (some of them will be set in method \"scrape_restaurant\")\u001b[39;00m\n\u001b[0;32m     37\u001b[0m cur_restaurant\u001b[38;5;241m.\u001b[39mset_name(cur_name)\n",
      "Cell \u001b[1;32mIn[51], line 224\u001b[0m, in \u001b[0;36mscrape_single_restaurant\u001b[1;34m(link_to_restaurant, restaurant, province_th)\u001b[0m\n\u001b[0;32m    217\u001b[0m scrape_location(\n\u001b[0;32m    218\u001b[0m     restaurant_page_driver \u001b[38;5;241m=\u001b[39m restaurant_page_driver,\n\u001b[0;32m    219\u001b[0m     restaurant \u001b[38;5;241m=\u001b[39m restaurant,\n\u001b[0;32m    220\u001b[0m     province_th \u001b[38;5;241m=\u001b[39m province_th\n\u001b[0;32m    221\u001b[0m )\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# scrape image path\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestaurant_page_driver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcur img path -> \u001b[39m\u001b[38;5;124m\"\u001b[39m, img_path)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# set some of \"Restaurant\" object properties\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[49], line 58\u001b[0m, in \u001b[0;36mscrape_img\u001b[1;34m(restaurant_page_driver)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# initialize the Chrome driver with service, selenium-wire options, and chrome options\u001b[39;00m\n\u001b[0;32m     53\u001b[0m all_img_driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mEdge(\n\u001b[0;32m     54\u001b[0m     service\u001b[38;5;241m=\u001b[39mService(EdgeChromiumDriverManager()\u001b[38;5;241m.\u001b[39minstall()),\n\u001b[0;32m     55\u001b[0m     seleniumwire_options\u001b[38;5;241m=\u001b[39mseleniumwire_options,\n\u001b[0;32m     56\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions\n\u001b[0;32m     57\u001b[0m )\n\u001b[1;32m---> 58\u001b[0m \u001b[43mall_img_driver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_img_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafter get to img url --> enter scrape img flow ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:368\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    352\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 354\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;66;03m# remove later prn..\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;66;03m# print(\"prn check name of command --> \", driver_command)\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# print('prn check response in side --> ', response)\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:306\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    304\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    305\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:326\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    323\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 326\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\urllib3\\request.py:81\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m     78\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     79\u001b[0m     )\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\urllib3\\request.py:173\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    170\u001b[0m extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(headers)\n\u001b[0;32m    171\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\urllib3\\poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    374\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    729\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    462\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    464\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    466\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:462\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 462\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\http\\client.py:1423\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1422\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1423\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1425\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# create directory 'res_restaurant_scraping'\n",
    "createDirectory(fh.STORE_RESTAURANT_SCRAPING, 'res_restaurant_scraping')\n",
    "\n",
    "# *** select one province from 'ALL_REGION_ID_WONGNAI'\n",
    "# *** so, change \"Idx_of_region\" everytime when scrape another province\n",
    "Idx_of_region = 0\n",
    "cur_region_data = ALL_REGION_ID_WONGNAI[Idx_of_region]\n",
    "\n",
    "cur_province_en = cur_region_data[0]\n",
    "cur_province_th = cur_region_data[1]\n",
    "cur_regionId = cur_region_data[2]\n",
    "\n",
    "# get dataframe result of all restaurants in current province\n",
    "cur_res_allRestaurants_df = scrape_restaurants_by_province(\n",
    "    wongnai_regionId = cur_regionId,\n",
    "    province = cur_province_th,\n",
    ")\n",
    "# remove duplicate restaurant \n",
    "cur_res_allRestaurants_df.drop_duplicates(subset=['name', 'sub_name'], inplace=True)\n",
    "# set new index\n",
    "cur_res_allRestaurants_df.set_index(['name', 'sub_name'], inplace=True)\n",
    "\n",
    "# save result dataframe to .csv\n",
    "res_file_name = 'res_restaurant_%s.csv' % (cur_province_en)\n",
    "res_path = os.path.join(fh.STORE_RESTAURANT_SCRAPING, 'res_restaurant_scraping', res_file_name) \n",
    "cur_res_allRestaurants_df.to_csv(res_path, encoding=\"utf-8\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
