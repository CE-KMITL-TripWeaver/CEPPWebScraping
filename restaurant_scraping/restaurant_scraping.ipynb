{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pyautogui\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import constants.constants as const\n",
    "import constants.file_handler_constants as fh\n",
    "from constants.restaurant_constants import *\n",
    "\n",
    "from packages.restaurant.Restaurant import *\n",
    "from packages.file_handler_package.file_handler import *\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv, dotenv_values \n",
    "\n",
    "from selenium.webdriver import Remote, ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.actions.wheel_input import ScrollOrigin\n",
    "from selenium.webdriver import ActionChains\n",
    "# from selenium import webdriver\n",
    "from selenium.webdriver.chrome.webdriver import WebDriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.edge.options import Options as EdgeOptions\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from selenium.webdriver.chromium.remote_connection import ChromiumRemoteConnection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_restaurant_df(restaurant: Restaurant) -> pd.DataFrame:\n",
    "    restaurant_dict = {\n",
    "        'name': [restaurant.get_name()],\n",
    "        'sub_name': [restaurant.get_sub_name()],\n",
    "        'wongnai_url' : [restaurant.get_wongnai_url()],\n",
    "        'restaurantType' : [restaurant.get_restaurantType()],\n",
    "        'facility' : [restaurant.get_facility()],\n",
    "        'description' : [restaurant.get_description()],\n",
    "        'imgPath': [restaurant.get_imgPath()],\n",
    "        'phone' : [restaurant.get_phone()],\n",
    "        'website' : [restaurant.get_website()],\n",
    "        'openingHour' : [restaurant.get_openingHour()],\n",
    "        'priceRange' : [restaurant.get_priceRange()],\n",
    "        'latitude' : [restaurant.get_latitude()],\n",
    "        'longitude' : [restaurant.get_longitude()],\n",
    "        # location\n",
    "        'address' : [restaurant.get_location().get_address()],\n",
    "        'province' : [restaurant.get_location().get_province()],\n",
    "        'district' : [restaurant.get_location().get_district()],\n",
    "        'subDistrict' : [restaurant.get_location().get_subDistrict()],\n",
    "        'province_code' : [restaurant.get_location().get_province_code()],\n",
    "        'district_code' : [restaurant.get_location().get_district_code()],\n",
    "        'sub_district_code' : [restaurant.get_location().get_sub_district_code()],\n",
    "\n",
    "        # rating\n",
    "        'score' : [restaurant.get_rating().get_score()],\n",
    "        'ratingCount' : [restaurant.get_rating().get_ratingCount()],\n",
    "    }\n",
    "    \n",
    "    restaurant_df = pd.DataFrame(restaurant_dict)\n",
    "    \n",
    "    return restaurant_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_openinghours(openingHours: dict) -> dict:\n",
    "    temp_openingHours = openingHours.copy()\n",
    "\n",
    "    if(len(temp_openingHours) == 0):\n",
    "        return temp_openingHours.copy()\n",
    "    \n",
    "    # cut substring represent special holiday\n",
    "    # for example:\n",
    "    # {'วันจันทร์(วันเฉลิมพระชนมพรรษา พระบาทสมเด็จพระปรเมนทรรามาธิบดีศรีสินทรมหาวชิราลงกรณ พระวชิรเกล้าเจ้าอยู่หัว (วันหยุดชดเชย))': '9:00–17:00'}\n",
    "    # change its key to -> {'วันจันทร์': '9:00–17:00'}\n",
    "    for key, val in temp_openingHours.copy().items():\n",
    "        start_Idx_special_holiday = key.find('(')\n",
    "        if(start_Idx_special_holiday != -1):\n",
    "            # changing keys of dictionary\n",
    "            new_key = key[:start_Idx_special_holiday]\n",
    "            temp_openingHours[new_key] = temp_openingHours.pop(key)\n",
    "\n",
    "    days_of_week = ['อาทิตย์', 'จันทร์', 'อังคาร', 'พุธ', 'พฤหัสบดี', 'ศุกร์', 'เสาร์']\n",
    "    # in case of temp_openingHours = {\"ทุกวัน\": '10:30 - 21:00'}\n",
    "    # convert it to dictionary with all days of week as a keys(same value)\n",
    "    if(len(temp_openingHours) == 1 and list(temp_openingHours.keys())[0] == 'ทุกวัน'):\n",
    "        temp_time = list(temp_openingHours.values())[0]\n",
    "        del temp_openingHours['ทุกวัน']\n",
    "        for cur_day_of_week in days_of_week:\n",
    "            temp_openingHours[cur_day_of_week] = temp_time\n",
    "\n",
    "    else:\n",
    "        # if there is range between day of week --> convert it to two individual key with same value\n",
    "        # for example: {'จันทร์ - พุธ': '10:00 - 20:30', 'อาทิตย์': '11:00 - 22:30'}\n",
    "        # convert to -> {'จันทร์': '10:00 - 20:30', 'อังคาร': '10:00 - 20:30', 'พุธ': '10:00 - 20:30', 'อาทิตย์': '11:00 - 22:30'}\n",
    "        for key, val in temp_openingHours.copy().items():\n",
    "            cur_split_day_range = key.split(' - ')\n",
    "            if(len(cur_split_day_range) == 1):\n",
    "                continue\n",
    "            # remove current key\n",
    "            del temp_openingHours[key]\n",
    "            # convert to two individual key with same value\n",
    "            is_pass_endDay = False\n",
    "            cur_start_day = cur_split_day_range[0]\n",
    "            cur_end_day = cur_split_day_range[1]\n",
    "            cur_Idx = days_of_week.index(cur_start_day)\n",
    "            while(not is_pass_endDay):\n",
    "                if(days_of_week[cur_Idx] == cur_end_day):\n",
    "                    is_pass_endDay = True\n",
    "                temp_openingHours[days_of_week[cur_Idx]] = val\n",
    "                cur_Idx = (cur_Idx + 1) % len(days_of_week)\n",
    "\n",
    "    # change openingHours to temp_openingHours\n",
    "    return temp_openingHours.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_img(restaurant_page_driver: webdriver) -> list[str]:\n",
    "    img_address = []\n",
    "    try:\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"start-maximized\")\n",
    "        find_mark_Idx = restaurant_page_driver.current_url.find('?')\n",
    "        \n",
    "        if(find_mark_Idx != -1):\n",
    "            # seach image section of current restaurant by this query\n",
    "            all_img_query = '%s/photos' % (restaurant_page_driver.current_url[:find_mark_Idx]) \n",
    "            all_img_driver = webdriver.Chrome(options=options) \n",
    "            all_img_driver.get(all_img_query)\n",
    "\n",
    "            #  scroll to the end of browser to retrive many images as possible\n",
    "            WebDriverWait(all_img_driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'brqSoI')))\n",
    "            all_img_elements = all_img_driver.find_elements(By.CLASS_NAME, 'brqSoI')\n",
    "            prev_len = len(all_img_elements)\n",
    "            cnt_scroll_end = 0\n",
    "            max_img_cnt = 250\n",
    "            while(True):\n",
    "                # check if it scroll and retrive the same amount of image for 3 time\n",
    "                # or amount of retrived images exceed \"max_img_cnt\" (may remove this condition later if you want all images)\n",
    "                if(cnt_scroll_end == 3 or prev_len > max_img_cnt):\n",
    "                    break\n",
    "                # scroll and wait for 2 msec\n",
    "                all_img_driver.execute_script('window.scrollBy(0, document.body.scrollHeight)')\n",
    "                time.sleep(2)\n",
    "                # update value for next iteration\n",
    "                all_img_elements = all_img_driver.find_elements(By.CLASS_NAME, 'brqSoI')\n",
    "                cur_len = len(all_img_elements)\n",
    "                if(prev_len == cur_len): \n",
    "                    cnt_scroll_end += 1\n",
    "                else:\n",
    "                    cnt_scroll_end = 0\n",
    "                    prev_len = cur_len\n",
    "        \n",
    "            # find image address and save in \"img_address\"\n",
    "            cnt_img = 0\n",
    "            for cur_img_element in all_img_elements:\n",
    "                cur_img_address = cur_img_element.get_attribute('src')\n",
    "                cur_img_address = re.sub(r\"\\d+x\\d+\", \"400x0\", cur_img_address)\n",
    "                if(cur_img_address in img_address):\n",
    "                    break\n",
    "                img_address.append(cur_img_address)\n",
    "                cnt_img += 1\n",
    "\n",
    "            all_img_driver.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"no img path...\")\n",
    "\n",
    "    return img_address.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_location(restaurant_page_driver: webdriver, restaurant: Restaurant, province_th: str):\n",
    "    possible_map_btn = restaurant_page_driver.find_elements(By.CLASS_NAME, 'dfUsxm')\n",
    "    map_btn = None\n",
    "    for cur_btn in possible_map_btn:\n",
    "        cur_text = cur_btn.text\n",
    "        if(cur_text == 'ดูเส้นทาง'):\n",
    "            map_btn = cur_btn\n",
    "            break\n",
    "\n",
    "    # find better address description on wongnai\n",
    "    # for example: \"8/88 อาคารเรียน ชั้น 2F, หมู่ที่5 ศรีสุนทร ถลาง ภูเก็ต ภูเก็ต (ชาบูชิโรบินสันถลาง) อ่านต่อได้ที่\"\n",
    "    possible_addressWongnai_elements = restaurant_page_driver.find_elements(By.CLASS_NAME, 'jEIapA')\n",
    "    address_wongnai = \"\"\n",
    "    for cur_element in possible_addressWongnai_elements:\n",
    "        cur_text = cur_element.text\n",
    "        if(province_th in cur_text):\n",
    "            address_wongnai = cur_text\n",
    "            break\n",
    "\n",
    "    try:\n",
    "        map_btn.click()\n",
    "        handle_tabs = restaurant_page_driver.window_handles\n",
    "        original_tab = handle_tabs[0]\n",
    "        google_map_tab = handle_tabs[1]\n",
    "\n",
    "        # switch to new tab which open google map\n",
    "        restaurant_page_driver.switch_to.window(google_map_tab)\n",
    "        print(\"check google map url -> \", restaurant_page_driver.current_url)\n",
    "        google_map_url = restaurant_page_driver.current_url\n",
    "        \n",
    "        # find lat, long\n",
    "        # extract the query part containing lat,long using regular expression\n",
    "        match = re.search(r\"query=([-+]?\\d*\\.\\d+|\\d+),([-+]?\\d*\\.\\d+|\\d+)\", google_map_url)\n",
    "        if match:\n",
    "            latitude = match.group(1)\n",
    "            longitude = match.group(2)\n",
    "            print(\"lat, long -> \",latitude, \" \", longitude)\n",
    "            restaurant.set_latitude(float(latitude))\n",
    "            restaurant.set_longitude(float(longitude))\n",
    "\n",
    "        # scrape location\n",
    "        subStrDistrict = \"อำเภอ\"\n",
    "        subStrSubDistrict = \"ตำบล\"\n",
    "\n",
    "        if province_th == \"กรุงเทพมหานคร\":\n",
    "            subStrDistrict = \"เขต\"\n",
    "            subStrSubDistrict = \"แขวง\"\n",
    "\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(restaurant_page_driver.page_source, 'html.parser')\n",
    "        possible_addressGoogleMap_elements = soup.find_all('span', class_='DkEaL')\n",
    "\n",
    "        # if found some wiered place that doesn't even have its address\n",
    "        # skip this case for now...\n",
    "        if(not len(possible_addressGoogleMap_elements)):\n",
    "            return\n",
    "\n",
    "        district = 0\n",
    "        subDirstrict = 0\n",
    "\n",
    "        # find location\n",
    "        useData = None\n",
    "        for cur_element in possible_addressGoogleMap_elements:\n",
    "            if province_th in cur_element.text and cur_element.text.find(subStrDistrict) != -1:\n",
    "                useData = cur_element.text.replace(\",\",\"\").replace(\"เเ\",\"แ\")\n",
    "                break\n",
    "        \n",
    "        if(useData != None):\n",
    "            # print(\"Full Address :\",useData)\n",
    "            # another brute force way in case of province 'กรุงเทพหมานคร' not have word 'แขวง' in address\n",
    "            if(province_th == 'กรุงเทพมหานคร' and useData.find(subStrSubDistrict) == -1):\n",
    "                subAddress_split = useData.split(' ')\n",
    "                cur_province_Idx = subAddress_split.index(province_th)\n",
    "                district = subAddress_split[cur_province_Idx - 1].replace(\"เขต\",\"\")\n",
    "                subDistrict = subAddress_split[cur_province_Idx - 2].replace(\"แขวง\",\"\")\n",
    "\n",
    "            else:\n",
    "                start_address_index = useData.find(subStrSubDistrict)\n",
    "                subAddress = useData[start_address_index:]\n",
    "                district = subAddress[subAddress.find(subStrDistrict)+len(subStrDistrict):subAddress.find(province_th)].replace(\" \",\"\")               \n",
    "                subDistrict = subAddress[subAddress.find(subStrSubDistrict)+len(subStrSubDistrict):subAddress.find(subStrDistrict)].replace(\" \",\"\")\n",
    "\n",
    "            if district == \"เมือง\":\n",
    "                district = district+province_th\n",
    "\n",
    "            # filter row to find 'ISO_3166_code', 'zip_code', 'geo_code'\n",
    "            geo_code_df = pd.read_csv(fh.PATH_TO_GEOCODE)\n",
    "            filtered_rows = geo_code_df[\n",
    "                (geo_code_df['province_th'] == province_th) & (geo_code_df['district_th'] == district) & (geo_code_df['subDistrict_th'] == subDistrict)\n",
    "            ]\n",
    "            filtered_rows.reset_index(inplace=True, drop=True)\n",
    "            \n",
    "            if not filtered_rows.empty:\n",
    "                print(\"province :\",filtered_rows.loc[0, 'ISO_3166_code'], province_th)\n",
    "                print(\"District :\",filtered_rows.loc[0, 'zip_code'], district)\n",
    "                print(\"SubDistrict :\",filtered_rows.loc[0, 'geo_code'], subDistrict)\n",
    "\n",
    "                restaurant.set_location(\n",
    "                    address = address_wongnai if len(address_wongnai) else useData,\n",
    "                    province = province_th,\n",
    "                    district = district,\n",
    "                    sub_district = subDistrict,\n",
    "                    province_code = filtered_rows.loc[0, 'ISO_3166_code'],\n",
    "                    district_code = filtered_rows.loc[0, 'zip_code'],\n",
    "                    sub_district_code = filtered_rows.loc[0, 'geo_code']\n",
    "                )\n",
    "            else:\n",
    "                print(\"province :\", province_th)\n",
    "                print(\"District :\", district)\n",
    "                print(\"SubDistrict :\", subDistrict)\n",
    "\n",
    "                restaurant.set_location(\n",
    "                    address = address_wongnai if len(address_wongnai) else useData,\n",
    "                    province = province_th,\n",
    "                    district = district,\n",
    "                    sub_district = subDistrict,\n",
    "                    iso_code = 0,\n",
    "                    zip_code = 0,\n",
    "                    geo_code = 0\n",
    "                )\n",
    "\n",
    "        # switch back to original tab\n",
    "        restaurant_page_driver.switch_to.window(original_tab)\n",
    "        print(\"check switch back original url -> \", restaurant_page_driver.current_url)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"cant find location...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_restaurant(link_to_restaurant: str, restaurant: Restaurant, province_th: str) -> None:\n",
    "    # navigate to the current restaurant page and continue scraping more data\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"start-maximized\")\n",
    "\n",
    "    restaurant_page_driver = webdriver.Chrome(options=options) \n",
    "    restaurant_page_driver.get(link_to_restaurant)\n",
    "\n",
    "    # find description\n",
    "    description = \"\"\n",
    "    try:\n",
    "        try:\n",
    "            click_read_more =  restaurant_page_driver.find_element(By.XPATH, '//*[@id=\"contentRow\"]/div[1]/div[5]/p/span')\n",
    "            click_read_more.click()\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        description = restaurant_page_driver.find_element(By.XPATH, '//*[@id=\"contentRow\"]/div[1]/div[5]/p').text\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    print(\"description -> \", description)\n",
    "\n",
    "    # find phones\n",
    "    phones = []\n",
    "    # try:\n",
    "    possible_phone_elements = restaurant_page_driver.find_elements(By.CLASS_NAME, 'jrmgwi')\n",
    "    print(\"prn check possible phone ele:\")\n",
    "    print(possible_phone_elements)\n",
    "    for cur_element in possible_phone_elements:\n",
    "        cur_text = cur_element.text\n",
    "        print(\"cur text -> \", cur_text)\n",
    "        if(\"เบอร์โทร : \" in cur_text):\n",
    "            phones = cur_text.split(\"เบอร์โทร : \")[-1].split(\", \").copy()\n",
    "            break\n",
    "    # except Exception as e:\n",
    "    #     print(\"no phones ...\")\n",
    "\n",
    "    print(\"phone1 -> \", phones)\n",
    "\n",
    "    # find websites\n",
    "    all_website_dict = {}\n",
    "    try:\n",
    "        container_website_elements = restaurant_page_driver.find_element(By.CLASS_NAME, 'kKDiaN')\n",
    "        all_website_elements = container_website_elements.find_elements(By.CLASS_NAME, 'cXFOMU')\n",
    "        for cur_website in all_website_elements:\n",
    "            cur_website_name = cur_website.text\n",
    "            cur_website_link = cur_website.get_attribute('href')\n",
    "            all_website_dict[cur_website_name] = cur_website_link\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"no website ...\")\n",
    "\n",
    "    # print(all_website_dict)\n",
    "\n",
    "    # find price range\n",
    "    priceRange = \"\"\n",
    "    try:\n",
    "        possible_priceRange_elements = restaurant_page_driver.find_elements(By.CLASS_NAME, 'hpJBMe')\n",
    "        for cur_element in possible_priceRange_elements:\n",
    "            cur_text = cur_element.text\n",
    "            if(\"บาท\" in cur_text):\n",
    "                priceRange = cur_text.replace('(', '').replace(')', '')\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(\"no price range ...\")        \n",
    "    \n",
    "    print(\"priceRange -> \", priceRange)\n",
    "\n",
    "    # find facilities\n",
    "    facilities = []\n",
    "    try:\n",
    "        container_list_facilities = restaurant_page_driver.find_element(By.XPATH, '//*[@id=\"contentRow\"]/div[2]/div/div[1]/div[2]/div/ul')\n",
    "        all_list_facilities = container_list_facilities.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "        for cur_list_element in all_list_facilities:\n",
    "            all_span_elements = cur_list_element.find_elements(By.TAG_NAME, 'span')\n",
    "            allowed_className = \"buIyWl\"\n",
    "            # not_allowed_className = \"McJoy\"\n",
    "            for cur_span in all_span_elements:\n",
    "                cur_class =  cur_span.get_attribute('class')\n",
    "                is_allowed_facility_span = (allowed_className in cur_class)\n",
    "\n",
    "                # check if is facility with correct mark symbol -> if it is then continue scrape for facility\n",
    "                if(is_allowed_facility_span):\n",
    "                    cur_text = cur_list_element.find_element(By.CLASS_NAME, 'fFYUJu').text\n",
    "                    try:\n",
    "                        cur_sub_text = cur_list_element.find_element(By.CLASS_NAME, 'gFBGSr').text\n",
    "                        cur_text = ('%s %s') % (cur_text, cur_sub_text)\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                    \n",
    "                    facilities.append(cur_text)\n",
    "                    break\n",
    "\n",
    "        print(\"cur facilities -> \", facilities)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"no facilities ...\")\n",
    "\n",
    "    # find rating\n",
    "    rating = 0\n",
    "    ratingCount = 0\n",
    "    try:\n",
    "        rating_element = restaurant_page_driver.find_element(By.XPATH, '//*[@id=\"contentRow\"]/div[1]/div[1]/div/div[1]/div/div[1]/div[1]/div/div/div/div')\n",
    "        ratingCount_element = restaurant_page_driver.find_element(By.XPATH, '//*[@id=\"contentRow\"]/div[1]/div[1]/div/div[1]/div/div[1]/span/span[2]')\n",
    "        # print(\"check ....\")\n",
    "        # print(rating_element.text)\n",
    "        # print(ratingCount_element.text)\n",
    "        rating = float(rating_element.text)\n",
    "        ratingCount = int(ratingCount_element.text.split(' ')[0][1:])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"can't find rating and ratingCount\")\n",
    "\n",
    "    print(\"rating --> \", rating)\n",
    "    print(\"ratingCount --> \", ratingCount)\n",
    "\n",
    "    # find openingHours\n",
    "    openingHours = {}\n",
    "    try:\n",
    "        all_openingHours_element = restaurant_page_driver.find_elements(By.CLASS_NAME, 'gdNTro')\n",
    "        for cur_openingHours_element in all_openingHours_element:\n",
    "            cur_all_td_elements = cur_openingHours_element.find_elements(By.TAG_NAME, 'td')\n",
    "            cur_day = cur_all_td_elements[0].text\n",
    "            cur_time = cur_all_td_elements[1].text\n",
    "            openingHours[cur_day] = cur_time\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"no opening hours ...\")\n",
    "\n",
    "    openingHours = convert_openinghours(openingHours)\n",
    "    print(\"cur opening hours: \")\n",
    "    print(openingHours)\n",
    "\n",
    "    # scrape location\n",
    "    scrape_location(\n",
    "        restaurant_page_driver = restaurant_page_driver,\n",
    "        restaurant = restaurant,\n",
    "        province_th = province_th\n",
    "    )\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    # scrape image path\n",
    "    img_path = scrape_img(restaurant_page_driver)\n",
    "    print(\"cur img path -> \", img_path)\n",
    "\n",
    "    # set some of \"Restaurant\" object properties\n",
    "    restaurant.set_description(description)\n",
    "    restaurant.set_phone(phones)\n",
    "    restaurant.set_website(all_website_dict)\n",
    "    restaurant.set_priceRange(priceRange)\n",
    "    restaurant.set_facility(facilities)\n",
    "    restaurant.set_openingHour(openingHours)\n",
    "    restaurant.set_imgPath(img_path)\n",
    "    restaurant.set_rating(\n",
    "        score = rating, \n",
    "        rating_count = ratingCount\n",
    "    )\n",
    "\n",
    "    restaurant_page_driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_restaurants_by_province(province: str, wongnai_regionId: str) -> pd.DataFrame:\n",
    "    # loading variables from .env file\n",
    "    # load_dotenv() \n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"start-maximized\")\n",
    "    \n",
    "    \n",
    "    res_restaurant_df = pd.DataFrame()\n",
    "    is_last_page = False\n",
    "    cur_query_url = \"https://www.wongnai.com/restaurants?categoryGroupId=9&regions=%s\" % (wongnai_regionId)\n",
    "    # cur_query_url = \"https://www.wongnai.com/restaurants/2631009Uv-%E0%B8%8A%E0%B8%B2%E0%B8%A3%E0%B9%8C%E0%B8%A1-%E0%B9%80%E0%B8%81%E0%B8%B2%E0%B8%B0%E0%B8%A2%E0%B8%AD-%E0%B8%AA%E0%B8%87%E0%B8%82%E0%B8%A5%E0%B8%B2/photos/566b0e2df2cb4b919ce903081a2eef3d\"\n",
    "    \n",
    "    cnt_for_debug = 0\n",
    "    while(not is_last_page):\n",
    "        if(cnt_for_debug == 20):\n",
    "            break\n",
    "        cnt_for_debug += 1\n",
    "    \n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(cur_query_url)\n",
    "\n",
    "        # scroll and wait for 2 msec\n",
    "        driver.execute_script('window.scrollBy(0, document.body.scrollHeight)')\n",
    "        time.sleep(2)\n",
    "        print(\"check current page url --> \", driver.current_url)\n",
    "\n",
    "        # find first group of restaurant on the first page\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'dibyTT')))\n",
    "        all_restaurants_card = driver.find_elements(By.CLASS_NAME, 'dibyTT')\n",
    "        all_clickable_elements = driver.find_elements(By.CLASS_NAME, 'fsElrZ')\n",
    "\n",
    "        # iterate to scrape each restaurant and set propeties of 'Restaurant' object\n",
    "        for cur_restaurant_card, cur_clickable_element in zip(all_restaurants_card, all_clickable_elements):\n",
    "            cur_restaurant = Restaurant()\n",
    "\n",
    "            # find restaurant name\n",
    "            cur_name = cur_restaurant_card.find_element(By.CLASS_NAME, 'Dtkmv').text\n",
    "            cur_sub_name = ''\n",
    "            # cut substring if there is sub name\n",
    "            try:\n",
    "                cur_sub_name = cur_restaurant_card.find_element(By.CLASS_NAME, 'dqdias').text\n",
    "                print(\"sub name -> \", cur_sub_name)\n",
    "                cur_Idx_sub_name = cur_name.rfind(cur_sub_name)\n",
    "                cur_name = cur_name[:cur_Idx_sub_name]\n",
    "                \n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            print('name -> ', cur_name)\n",
    "\n",
    "            # find restaurant types\n",
    "            cur_restaurant_types = []\n",
    "            cur_restaurant_tags_elements = cur_restaurant_card.find_elements(By.CLASS_NAME, 'okmRN')\n",
    "            for cur_element in cur_restaurant_tags_elements:\n",
    "                cur_restaurant_types.append(cur_element.text)\n",
    "            print(\"cur type -> \", cur_restaurant_types)\n",
    "        \n",
    "            time.sleep(2)\n",
    "            # navigate to the current restaurant page and continue scraping more data\n",
    "            # get url via \"href\" attribute of tag 'a' -> navigate restaurant page\n",
    "            link_to_restaurant = cur_clickable_element.get_attribute('href')\n",
    "            scrape_restaurant(\n",
    "                link_to_restaurant = link_to_restaurant,\n",
    "                restaurant = cur_restaurant,\n",
    "                province_th = province\n",
    "            )\n",
    "            # set 'Restaurant' object properties (some of them will be set in method \"scrape_restaurant\")\n",
    "            cur_restaurant.set_name(cur_name)\n",
    "            cur_restaurant.set_sub_name(cur_sub_name)\n",
    "            cur_restaurant.set_restaurantType(cur_restaurant_types)\n",
    "            cur_restaurant.set_wongnai_url(link_to_restaurant)\n",
    "\n",
    "            # create data frame represent data scrape from current restaurant card\n",
    "            cur_restaurant_df = create_restaurant_df(restaurant=cur_restaurant)\n",
    "            \n",
    "            # concat all data frame result\n",
    "            res_restaurant_df = pd.concat([res_restaurant_df, cur_restaurant_df])   \n",
    "\n",
    "                \n",
    "        # find button to click next -> get url via \"href\" attribute of tag 'a' -> navigate to the next page in a new browser window (aviod wongnai might not allowed web scraping).\n",
    "        time.sleep(2)\n",
    "        next_page_element = driver.find_element(By.XPATH, '//*[@id=\"contentContainer\"]/div[1]/div[2]/div[2]/div[1]/div[2]/a[2]')\n",
    "        link_to_nextPage = next_page_element.get_attribute('href')\n",
    "        # after scrap everything in current page -> check if it is the lastpage\n",
    "        if(not link_to_nextPage):\n",
    "            is_last_page = True\n",
    "\n",
    "        # if not last page -> set new query to navigate to the next page in a new browser window(next iteration)\n",
    "        cur_query_url = link_to_nextPage\n",
    "        \n",
    "        # close current browser tab    \n",
    "        driver.close() \n",
    "\n",
    "    return res_restaurant_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory res_restaurant_scraping created successfully\n",
      "check current page url -->  https://www.wongnai.com/restaurants?categoryGroupId=9&regions=843\n",
      "name ->  ชินจาโยป่าตอง\n",
      "cur type ->  ['อาหารเกาหลี']\n",
      "description ->  \n",
      "prn check possible phone ele:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"7087dc263815b11136f440ba2256650e\", element=\"f.89820D7DE742853557844D6BD4989B17.d.F5DB9271E8282E4011B52C3E1FF76BE1.e.104\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"7087dc263815b11136f440ba2256650e\", element=\"f.89820D7DE742853557844D6BD4989B17.d.F5DB9271E8282E4011B52C3E1FF76BE1.e.105\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"7087dc263815b11136f440ba2256650e\", element=\"f.89820D7DE742853557844D6BD4989B17.d.F5DB9271E8282E4011B52C3E1FF76BE1.e.106\")>]\n",
      "cur text ->  135/22, ราษฏร์อุทิศ 200ปี ป่าตอง กะทู้ ภูเก็ต ภูเก็ต (ร้านชินจาโยป่าตอง หน้าโรงแรมพาราไดซ์ป่าตองตึกหลายสี5ชั้น)\n",
      "ดูเส้นทาง\n",
      "cur text ->  เบอร์โทร : +66825311745\n",
      "phone1 ->  ['+66825311745']\n",
      "no website ...\n",
      "priceRange ->  101 - 250 บาท\n",
      "cur facilities ->  ['Wi-Fi มี Wi-Fi บริการฟรี', 'สัตว์เลี้ยงเข้าได้', 'เดลิเวอรี', 'เหมาะสำหรับเด็กๆ', 'เหมาะสำหรับมาเป็นกลุ่ม']\n",
      "can't find rating and ratingCount\n",
      "rating -->  0\n",
      "ratingCount -->  0\n",
      "cur opening hours: \n",
      "{'ศุกร์': '15:00 - 23:30', 'อาทิตย์': '16:00 - 23:30', 'จันทร์': '16:00 - 23:30', 'อังคาร': '16:00 - 23:30', 'พุธ': '16:00 - 23:30', 'พฤหัสบดี': '16:00 - 23:30'}\n",
      "check google map url ->  https://www.google.com/maps/search/?api=1&query=7.895039895775943,98.29986300000019\n",
      "lat, long ->  7.895039895775943   98.29986300000019\n",
      "province : 83 ภูเก็ต\n",
      "District : 8302 กะทู้\n",
      "SubDistrict : 830202 ป่าตอง\n",
      "check switch back original url ->  https://www.wongnai.com/restaurants/2062840hc-%E0%B8%8A%E0%B8%B4%E0%B8%99%E0%B8%88%E0%B8%B2%E0%B9%82%E0%B8%A2%E0%B8%9B%E0%B9%88%E0%B8%B2%E0%B8%95%E0%B8%AD%E0%B8%87?_st=cD0wO2I9MjA2Mjg0MDthZD10cnVlO3Q9MTcyNjIzMDkxNDQ1NztyaT0xWDdiNXlWYVJYNzRPenBCRllKSUVFZFpZYWszSk07aT0xWDcwWklIQXl2YVozb0lpWmJlT2p3NlNMOGVPbVA7d3JlZj1zcjs%3D\n",
      "no img path...\n",
      "cur img path ->  []\n",
      "name ->  The Beach Phuket\n",
      "cur type ->  ['กึ่งผับ/ร้านเหล้า/บาร์', 'ผับ/เที่ยวกลางคืน', 'อาหารนานาชาติ']\n",
      "description ->  \n",
      "prn check possible phone ele:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"8196e2b66bf8e2f1c92017580dcbc16e\", element=\"f.80D571E5EB97885BA05AA578FB619706.d.2A7C1D6231D63B2281527B24D652C1C9.e.106\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"8196e2b66bf8e2f1c92017580dcbc16e\", element=\"f.80D571E5EB97885BA05AA578FB619706.d.2A7C1D6231D63B2281527B24D652C1C9.e.107\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"8196e2b66bf8e2f1c92017580dcbc16e\", element=\"f.80D571E5EB97885BA05AA578FB619706.d.2A7C1D6231D63B2281527B24D652C1C9.e.108\")>]\n",
      "cur text ->  72 9 ตำบลเชิงทะเล อำเภอถลาง ภูเก็ต 83110 ประเทศไทย ภูเก็ต\n",
      "ดูเส้นทาง\n",
      "cur text ->  เบอร์โทร : 0626683818\n",
      "phone1 ->  ['0626683818']\n",
      "no website ...\n",
      "priceRange ->  101 - 250 บาท\n",
      "no facilities ...\n",
      "can't find rating and ratingCount\n",
      "rating -->  0\n",
      "ratingCount -->  0\n",
      "cur opening hours: \n",
      "{}\n",
      "check google map url ->  https://www.google.com/maps/search/?api=1&query=7.988023900000001,98.2887908\n",
      "lat, long ->  7.988023900000001   98.2887908\n",
      "province : 83 ภูเก็ต\n",
      "District : 8303 ถลาง\n",
      "SubDistrict : 830303 เชิงทะเล\n",
      "check switch back original url ->  https://www.wongnai.com/restaurants/2551791bp-the-beach-phuket?_st=cD0xO2I9MjU1MTc5MTthZD10cnVlO3Q9MTcyNjIzMDkxNDQ3MjtyaT0xWDdiNXlWYU91enRCRnNEbnJraEV2WkZnMFhseEQ7aT0xWDcwWklIQXl2YVozb0lpWmJlT2p3NlNMOGVPbVA7d3JlZj1zcjs%3D\n",
      "cur img path ->  ['https://img.wongnai.com/p/400x0/2024/02/20/462aceb561a94bada0190b2e896313a7.jpg', 'https://img.wongnai.com/p/400x0/2024/02/20/214a6bd854d54670b16c905e47066899.jpg', 'https://img.wongnai.com/p/400x0/2024/02/08/012faf6c060b4b7a8239ed4a2e58acf9.jpg', 'https://img.wongnai.com/p/400x0/2024/02/08/ac8f262a72b2467d9610dc4d262f8b82.jpg', 'https://img.wongnai.com/p/400x0/2024/02/08/40dd2294d73f4bb4a03c6abb885cd6b1.jpg', 'https://img.wongnai.com/p/400x0/2024/02/08/53bed58ec2bf4cdfb1b922b849377857.jpg', 'https://img.wongnai.com/p/400x0/2024/02/08/01df21f969cb46628dd8bff2f5150359.jpg', 'https://img.wongnai.com/p/400x0/2024/02/08/44ba294356ba4fbb91e71f6b63b629b1.jpg', 'https://img.wongnai.com/p/400x0/2024/01/16/36976d69d6ca40a98b557aed42d1ffe2.jpg', 'https://img.wongnai.com/p/400x0/2024/01/16/0b8e5d4458e84bdea194f5be04074a99.jpg', 'https://img.wongnai.com/p/400x0/2024/01/16/e9e2abdb60454dadb093b75b87d48396.jpg', 'https://img.wongnai.com/p/400x0/2023/12/29/0d8b9d74cdf44b35b5a2691e8cfbe2d3.jpg', 'https://img.wongnai.com/p/400x0/2023/12/29/26f9dae89b974ce48d34be69e33cd5a6.jpg', 'https://img.wongnai.com/p/400x0/2023/12/29/1362176ab47842f6aaf0d6d6f8c4c5da.jpg', 'https://img.wongnai.com/p/400x0/2023/12/29/91591c1a11934c6abc8c2a3b3f78e40a.jpg', 'https://img.wongnai.com/p/400x0/2023/12/29/b7f695c558574443972e5153694127be.jpg', 'https://img.wongnai.com/p/400x0/2023/12/29/60c5cee86f304d67abdfcc0014fe5c99.jpg', 'https://img.wongnai.com/p/400x0/2023/12/29/f6902ef3139d4322b61e4ada753c70f2.jpg', 'https://img.wongnai.com/p/400x0/2023/12/29/e80eb0d54cf84a0c914be6fb5b6c139f.jpg', 'https://img.wongnai.com/p/400x0/2023/12/29/91371e1329d5415bbc056443fe2138f2.jpg', 'https://img.wongnai.com/p/400x0/2023/12/29/fa45b051b3824622859e2ab322d7d4c9.jpg', 'https://img.wongnai.com/p/400x0/2023/12/29/253866f381674d29a0a2e0a49d743b6f.jpg', 'https://img.wongnai.com/p/400x0/2023/12/19/1a9b87e1cc52456c84a5be971122590e.jpg', 'https://img.wongnai.com/p/400x0/2023/12/18/9e632bc4989c4f3ab0aa997eea2ffe9e.jpg']\n",
      "sub name ->  Patong\n",
      "name ->  Napa Massage\n",
      "cur type ->  ['คาเฟ่']\n",
      "description ->  \n",
      "prn check possible phone ele:\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"62a78c43022a02950645a0880e46a206\", element=\"f.9D416FD3F5DF77E3A3BBA076B3D85654.d.E1F66B96E9D1A488DA8322265E09EAEB.e.96\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"62a78c43022a02950645a0880e46a206\", element=\"f.9D416FD3F5DF77E3A3BBA076B3D85654.d.E1F66B96E9D1A488DA8322265E09EAEB.e.97\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"62a78c43022a02950645a0880e46a206\", element=\"f.9D416FD3F5DF77E3A3BBA076B3D85654.d.E1F66B96E9D1A488DA8322265E09EAEB.e.98\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"62a78c43022a02950645a0880e46a206\", element=\"f.9D416FD3F5DF77E3A3BBA076B3D85654.d.E1F66B96E9D1A488DA8322265E09EAEB.e.99\")>]\n",
      "cur text ->  9 ถ. ทวีวงศ์ ตำบลป่าตอง อำเภอกะทู้ ภูเก็ต 83150 ไทย ภูเก็ต\n",
      "ดูเส้นทาง\n",
      "cur text ->  เบอร์โทร : 0905493847\n",
      "phone1 ->  ['0905493847']\n",
      "no website ...\n",
      "priceRange ->  ต่ำกว่า 100 บาท\n",
      "no facilities ...\n",
      "can't find rating and ratingCount\n",
      "rating -->  0\n",
      "ratingCount -->  0\n",
      "cur opening hours: \n",
      "{}\n",
      "check google map url ->  https://www.google.com/maps/search/?api=1&query=7.8942633,98.2953232\n",
      "lat, long ->  7.8942633   98.2953232\n",
      "province : 83 ภูเก็ต\n",
      "District : 8302 กะทู้\n",
      "SubDistrict : 830202 ป่าตอง\n",
      "check switch back original url ->  https://www.wongnai.com/restaurants/2686171Bf-napa-massage-patong?_st=cD0yO2I9MjY4NjE3MTthZD1mYWxzZTt0PTE3MjYyMzA3MDU5MTM7cmk9MVg3YjV5VkE5UFpQM25KelFQYnhZQ1poNmZVcnJVO2k9MVg3MFpJR2tlTzRTZWxTNnZPVTM1d3BLMzNzUWh5O3dyZWY9c3I7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m cur_regionId \u001b[38;5;241m=\u001b[39m cur_region_data[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# get dataframe result of all restaurants in current province\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m cur_res_allRestaurants_df \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_restaurants_by_province\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwongnai_regionId\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_regionId\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovince\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_province_th\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# remove duplicate restaurant \u001b[39;00m\n\u001b[0;32m     22\u001b[0m cur_res_allRestaurants_df\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub_name\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[23], line 63\u001b[0m, in \u001b[0;36mscrape_restaurants_by_province\u001b[1;34m(province, wongnai_regionId)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# navigate to the current restaurant page and continue scraping more data\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# get url via \"href\" attribute of tag 'a' -> navigate restaurant page\u001b[39;00m\n\u001b[0;32m     62\u001b[0m link_to_restaurant \u001b[38;5;241m=\u001b[39m cur_clickable_element\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m \u001b[43mscrape_restaurant\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlink_to_restaurant\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlink_to_restaurant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestaurant\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_restaurant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovince_th\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprovince\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# set 'Restaurant' object properties (some of them will be set in method \"scrape_restaurant\")\u001b[39;00m\n\u001b[0;32m     69\u001b[0m cur_restaurant\u001b[38;5;241m.\u001b[39mset_name(cur_name)\n",
      "Cell \u001b[1;32mIn[22], line 148\u001b[0m, in \u001b[0;36mscrape_restaurant\u001b[1;34m(link_to_restaurant, restaurant, province_th)\u001b[0m\n\u001b[0;32m    145\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# scrape image path\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestaurant_page_driver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcur img path -> \u001b[39m\u001b[38;5;124m\"\u001b[39m, img_path)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# set some of \"Restaurant\" object properties\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[20], line 27\u001b[0m, in \u001b[0;36mscrape_img\u001b[1;34m(restaurant_page_driver)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# scroll and wait for 2 msec\u001b[39;00m\n\u001b[0;32m     26\u001b[0m all_img_driver\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindow.scrollBy(0, document.body.scrollHeight)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# update value for next iteration\u001b[39;00m\n\u001b[0;32m     29\u001b[0m all_img_elements \u001b[38;5;241m=\u001b[39m all_img_driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrqSoI\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # loading variables from .env file\n",
    "# load_dotenv() \n",
    "\n",
    "cnt_for_debug = 0\n",
    "for cur_region_data in ALL_REGION_ID_WONGNAI:\n",
    "    # create directory 'res_restaurant_scraping'\n",
    "    createDirectory(fh.STORE_RESTAURANT_SCRAPING, 'res_restaurant_scraping')\n",
    "\n",
    "    if(cnt_for_debug == 1):\n",
    "        break\n",
    "    \n",
    "    cur_province_en = cur_region_data[0]\n",
    "    cur_province_th = cur_region_data[1]\n",
    "    cur_regionId = cur_region_data[2]\n",
    "\n",
    "    # get dataframe result of all restaurants in current province\n",
    "    cur_res_allRestaurants_df = scrape_restaurants_by_province(\n",
    "        wongnai_regionId = cur_regionId,\n",
    "        province = cur_province_th\n",
    "    )\n",
    "    # remove duplicate restaurant \n",
    "    cur_res_allRestaurants_df.drop_duplicates(subset=['name', 'sub_name'], inplace=True)\n",
    "    # set new index\n",
    "    cur_res_allRestaurants_df.set_index(['name', 'sub_name'], inplace=True)\n",
    "\n",
    "    cnt_for_debug += 1\n",
    "    \n",
    "    # save result dataframe to .csv\n",
    "    res_file_name = 'res_restaurant_%s.csv' % (cur_province_en)\n",
    "    res_path = os.path.join(fh.STORE_RESTAURANT_SCRAPING, 'res_restaurant_scraping', res_file_name) \n",
    "    cur_res_allRestaurants_df.to_csv(res_path, encoding=\"utf-8\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
