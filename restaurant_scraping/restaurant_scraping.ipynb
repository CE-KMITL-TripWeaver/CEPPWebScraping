{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pyautogui\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import constants.constants as const\n",
    "import constants.file_handler_constants as fh\n",
    "from constants.restaurant_constants import *\n",
    "\n",
    "from packages.restaurant.Restaurant import *\n",
    "from packages.file_handler_package.file_handler import *\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.actions.wheel_input import ScrollOrigin\n",
    "from selenium.webdriver import ActionChains\n",
    "# from selenium import webdriver\n",
    "from selenium.webdriver.chrome.webdriver import WebDriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.edge.options import Options as EdgeOptions\n",
    "from selenium.webdriver.remote.webelement import WebElement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_openinghours(openingHours: dict) -> dict:\n",
    "    temp_openingHours = openingHours.copy()\n",
    "\n",
    "    if(len(temp_openingHours) == 0):\n",
    "        return temp_openingHours.copy()\n",
    "    \n",
    "    # cut substring represent special holiday\n",
    "    # for example:\n",
    "    # {'วันจันทร์(วันเฉลิมพระชนมพรรษา พระบาทสมเด็จพระปรเมนทรรามาธิบดีศรีสินทรมหาวชิราลงกรณ พระวชิรเกล้าเจ้าอยู่หัว (วันหยุดชดเชย))': '9:00–17:00'}\n",
    "    # change its key to -> {'วันจันทร์': '9:00–17:00'}\n",
    "    for key, val in temp_openingHours.copy().items():\n",
    "        start_Idx_special_holiday = key.find('(')\n",
    "        if(start_Idx_special_holiday != -1):\n",
    "            # changing keys of dictionary\n",
    "            new_key = key[:start_Idx_special_holiday]\n",
    "            temp_openingHours[new_key] = temp_openingHours.pop(key)\n",
    "\n",
    "    days_of_week = ['อาทิตย์', 'จันทร์', 'อังคาร', 'พุธ', 'พฤหัสบดี', 'ศุกร์', 'เสาร์']\n",
    "    # in case of temp_openingHours = {\"ทุกวัน\": '10:30 - 21:00'}\n",
    "    # convert it to dictionary with all days of week as a keys(same value)\n",
    "    if(len(temp_openingHours) == 1 and list(temp_openingHours.keys())[0] == 'ทุกวัน'):\n",
    "        temp_time = list(temp_openingHours.values())[0]\n",
    "        del temp_openingHours['ทุกวัน']\n",
    "        for cur_day_of_week in days_of_week:\n",
    "            temp_openingHours[cur_day_of_week] = temp_time\n",
    "\n",
    "    else:\n",
    "        # if there is range between day of week --> convert it to two individual key with same value\n",
    "        # for example: {'จันทร์ - พุธ': '10:00 - 20:30', 'อาทิตย์': '11:00 - 22:30'}\n",
    "        # convert to -> {'จันทร์': '10:00 - 20:30', 'อังคาร': '10:00 - 20:30', 'พุธ': '10:00 - 20:30', 'อาทิตย์': '11:00 - 22:30'}\n",
    "        for key, val in temp_openingHours.copy().items():\n",
    "            cur_split_day_range = key.split(' - ')\n",
    "            if(len(cur_split_day_range) == 1):\n",
    "                continue\n",
    "            # remove current key\n",
    "            del temp_openingHours[key]\n",
    "            # convert to two individual key with same value\n",
    "            is_pass_endDay = False\n",
    "            cur_start_day = cur_split_day_range[0]\n",
    "            cur_end_day = cur_split_day_range[1]\n",
    "            cur_Idx = days_of_week.index(cur_start_day)\n",
    "            while(not is_pass_endDay):\n",
    "                if(days_of_week[cur_Idx] == cur_end_day):\n",
    "                    is_pass_endDay = True\n",
    "                temp_openingHours[days_of_week[cur_Idx]] = val\n",
    "                cur_Idx = (cur_Idx + 1) % len(days_of_week)\n",
    "\n",
    "    # change openingHours to temp_openingHours\n",
    "    return temp_openingHours.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_img():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_location():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_restaurant(link_to_restaurant: str, restaurant: Restaurant) -> None:\n",
    "    # navigate to the current restaurant page and continue scraping more data\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"start-maximized\")\n",
    "\n",
    "    restaurant_page_driver = webdriver.Chrome(options=options) \n",
    "    restaurant_page_driver.get(link_to_restaurant)\n",
    "\n",
    "    # find websites\n",
    "    all_website_dict = {}\n",
    "    try:\n",
    "        container_website_elements = restaurant_page_driver.find_element(By.CLASS_NAME, 'kKDiaN')\n",
    "        all_website_elements = container_website_elements.find_elements(By.CLASS_NAME, 'cXFOMU')\n",
    "        for cur_website in all_website_elements:\n",
    "            cur_website_name = cur_website.text\n",
    "            cur_website_link = cur_website.get_attribute('href')\n",
    "            all_website_dict[cur_website_name] = cur_website_link\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"no website ...\")\n",
    "\n",
    "    print(all_website_dict)\n",
    "\n",
    "    # find price range\n",
    "    priceRange = \"\"\n",
    "    try:\n",
    "        possible_priceRange_elements = restaurant_page_driver.find_elements(By.CLASS_NAME, 'hpJBMe')\n",
    "        for cur_element in possible_priceRange_elements:\n",
    "            cur_text = cur_element.text\n",
    "            if(\"บาท\" in cur_text):\n",
    "                priceRange = cur_text.replace('(', '').replace(')', '')\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(\"no price range ...\")        \n",
    "    \n",
    "    print(priceRange)\n",
    "\n",
    "    # find facilities\n",
    "    facilities = []\n",
    "    try:\n",
    "        container_list_facilities = restaurant_page_driver.find_element(By.XPATH, '//*[@id=\"contentRow\"]/div[2]/div/div[1]/div[2]/div/ul')\n",
    "        all_list_facilities = container_list_facilities.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "        for cur_list_element in all_list_facilities:\n",
    "            all_span_elements = cur_list_element.find_elements(By.TAG_NAME, 'span')\n",
    "            allowed_className = \"buIyWl\"\n",
    "            # not_allowed_className = \"McJoy\"\n",
    "            for cur_span in all_span_elements:\n",
    "                cur_class =  cur_span.get_attribute('class')\n",
    "                is_allowed_facility_span = (allowed_className in cur_class)\n",
    "\n",
    "                # check if is facility with correct mark symbol -> if it is then continue scrape for facility\n",
    "                if(is_allowed_facility_span):\n",
    "                    cur_text = cur_list_element.find_element(By.CLASS_NAME, 'fFYUJu').text\n",
    "                    try:\n",
    "                        cur_sub_text = cur_list_element.find_element(By.CLASS_NAME, 'gFBGSr').text\n",
    "                        cur_text = ('%s %s') % (cur_text, cur_sub_text)\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                    \n",
    "                    facilities.append(cur_text)\n",
    "                    break\n",
    "\n",
    "        print(\"cur facilities -> \", facilities)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"no facilities ...\")\n",
    "\n",
    "    \n",
    "    # find openingHours\n",
    "    openingHours = {}\n",
    "    try:\n",
    "        all_openingHours_element = restaurant_page_driver.find_elements(By.CLASS_NAME, 'gdNTro')\n",
    "        for cur_openingHours_element in all_openingHours_element:\n",
    "            cur_all_td_elements = cur_openingHours_element.find_elements(By.TAG_NAME, 'td')\n",
    "            cur_day = cur_all_td_elements[0].text\n",
    "            cur_time = cur_all_td_elements[1].text\n",
    "            openingHours[cur_day] = cur_time\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"no opening hours ...\")\n",
    "\n",
    "    openingHours = convert_openinghours(openingHours)\n",
    "    print(\"cur opening hours: \")\n",
    "    print(openingHours)\n",
    " \n",
    "    # scrape location\n",
    "\n",
    "    # scrape image path\n",
    "\n",
    "    restaurant_page_driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_restaurants_by_province(province: str, wongnai_regionId: str) -> pd.DataFrame:\n",
    "    # prepare option to create new driver for some scraping task\n",
    "    # for example: get to google map or next page without click on the same browser(wongnai might not allowed) \n",
    "    # options = webdriver.ChromeOptions()\n",
    "    # options.add_argument(\"start-maximized\")\n",
    "    \n",
    "    res_restaurant_df = pd.DataFrame()\n",
    "    is_last_page = False\n",
    "    cur_query_url = \"https://www.wongnai.com/restaurants?categoryGroupId=9&regions=%s\" % (wongnai_regionId)\n",
    "    \n",
    "    # create webdriver instance using option to mazimize current window\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"start-maximized\")\n",
    "\n",
    "    cnt_for_debug = 0\n",
    "    while(not is_last_page):\n",
    "        if(cnt_for_debug == 2):\n",
    "            break\n",
    "        cnt_for_debug += 1\n",
    "\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(cur_query_url)\n",
    "        \n",
    "        # find first group of restaurant on the first page\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'dibyTT')))\n",
    "        all_restaurants_card = driver.find_elements(By.CLASS_NAME, 'dibyTT')\n",
    "        all_clickable_elements = driver.find_elements(By.CLASS_NAME, 'fsElrZ')\n",
    "\n",
    "        # iterate to scrape each restaurant and set propeties of 'Restaurant' object\n",
    "        for cur_restaurant_card, cur_clickable_element in zip(all_restaurants_card, all_clickable_elements):\n",
    "            cur_restaurant = Restaurant()\n",
    "\n",
    "            # find restaurant name\n",
    "            cur_name = cur_restaurant_card.find_element(By.CLASS_NAME, 'Dtkmv').text\n",
    "            cur_sub_name = ''\n",
    "            # cut substring if there is sub name\n",
    "            try:\n",
    "                cur_sub_name = cur_restaurant_card.find_element(By.CLASS_NAME, 'dqdias').text\n",
    "                print(\"sub name -> \", cur_sub_name)\n",
    "                cur_Idx_sub_name = cur_name.rfind(cur_sub_name)\n",
    "                cur_name = cur_name[:cur_Idx_sub_name]\n",
    "                \n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            print('name -> ', cur_name)\n",
    "            cur_restaurant.set_name(cur_name)\n",
    "            cur_restaurant.set_sub_name(cur_sub_name)\n",
    "\n",
    "            # find restaurant tags\n",
    "            cur_restaurant_tags = []\n",
    "            cur_restaurant_tags_elements = cur_restaurant_card.find_elements(By.CLASS_NAME, 'okmRN')\n",
    "            for cur_element in cur_restaurant_tags_elements:\n",
    "                cur_restaurant_tags.append(cur_element.text)\n",
    "            print(\"cur tags\")\n",
    "            print(cur_restaurant_tags)\n",
    "\n",
    "            # set some properties of 'Restaurant' object\n",
    "            cur_restaurant.set_name(cur_name)\n",
    "            cur_restaurant.set_sub_name(cur_sub_name)\n",
    "            cur_restaurant.set_restaurantTag(cur_restaurant_tags)\n",
    "\n",
    "            time.sleep(2)\n",
    "            # navigate to the current restaurant page and continue scraping more data\n",
    "            # get url via \"href\" attribute of tag 'a' -> navigate restaurant page\n",
    "            link_to_restaurant = cur_clickable_element.get_attribute('href')\n",
    "            scrape_restaurant(\n",
    "                link_to_restaurant = link_to_restaurant,\n",
    "                restaurant = cur_restaurant,\n",
    "            )\n",
    "            \n",
    "        # find button to click next -> get url via \"href\" attribute of tag 'a' -> navigate to the next page in a new browser window (aviod wongnai might not allowed web scraping).\n",
    "        time.sleep(2)\n",
    "        next_page_element = driver.find_element(By.XPATH, '//*[@id=\"contentContainer\"]/div[1]/div[2]/div[2]/div[1]/div[2]/a[2]')\n",
    "        link_to_nextPage = next_page_element.get_attribute('href')\n",
    "        # after scrap everything in current page -> check if it is the lastpage\n",
    "        if(not link_to_nextPage):\n",
    "            break\n",
    "\n",
    "        # if not last page -> set new query to navigate to the next page in a new browser window(next iteration)\n",
    "        cur_query_url = link_to_nextPage\n",
    "        # close current browser tab    \n",
    "        driver.close() \n",
    "\n",
    "    return res_restaurant_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub name ->  Phuket\n",
      "name ->  Wood x Good Cafe คาเฟ่ภูเก็ต\n",
      "cur tags\n",
      "['เบเกอรี/เค้ก', 'คาเฟ่']\n",
      "{'Facebook': 'https://www.facebook.com/woodxgoodcafe', 'Instagram': 'https://instagram.com/https://www.instagram.com/woodxgood_cafe/', 'LINE@': 'http://line.naver.jp/ti/p/@woodxgoodcafe'}\n",
      "ต่ำกว่า 100 บาท\n",
      "cur facilities ->  ['ที่จอดรถ (มีที่จอดรถ)', 'เดลิเวอรี']\n",
      "cur opening hours: \n",
      "{'อาทิตย์': '08:00 - 20:00', 'จันทร์': '08:00 - 20:00', 'อังคาร': '08:00 - 20:00', 'พุธ': '08:00 - 20:00', 'พฤหัสบดี': '08:00 - 20:00', 'ศุกร์': '08:00 - 20:00', 'เสาร์': '08:00 - 20:00'}\n",
      "sub name ->  พูนผลไนท์พลาซ่า\n",
      "name ->  หวังตี้เยี่ยน 皇帝宴\n",
      "cur tags\n",
      "['อาหารจีน', 'ชาบู/สุกี้ยากี้/หม้อไฟ', 'อาหารตามสั่ง']\n",
      "no website ...\n",
      "{}\n",
      "501 - 1,000 บาท\n",
      "cur facilities ->  ['ที่จอดรถ (มีที่จอดรถ)', 'Wi-Fi มี Wi-Fi บริการฟรี', 'เดลิเวอรี', 'เหมาะสำหรับเด็กๆ', 'เหมาะสำหรับมาเป็นกลุ่ม']\n",
      "cur opening hours: \n",
      "{'อาทิตย์': '11:00 - 22:00', 'จันทร์': '11:00 - 22:00', 'อังคาร': '11:00 - 22:00', 'พุธ': '11:00 - 22:00', 'พฤหัสบดี': '11:00 - 22:00', 'ศุกร์': '11:00 - 22:00', 'เสาร์': '11:00 - 22:00'}\n",
      "sub name ->  Patong\n",
      "name ->  Napa Massage\n",
      "cur tags\n",
      "['คาเฟ่']\n",
      "no website ...\n",
      "{}\n",
      "101 - 250 บาท\n",
      "no facilities ...\n",
      "cur opening hours: \n",
      "{}\n",
      "sub name ->  สามกอง ภูเก็ต\n",
      "name ->  Pizza Hut\n",
      "cur tags\n",
      "['พิซซ่า', 'ฟาสต์ฟู้ด/จานด่วน']\n",
      "no website ...\n",
      "{}\n",
      "251 - 500 บาท\n",
      "cur facilities ->  ['เดลิเวอรี']\n",
      "cur opening hours: \n",
      "{'อาทิตย์': '09:30 - 22:00', 'จันทร์': '09:30 - 22:00', 'อังคาร': '09:30 - 22:00', 'พุธ': '09:30 - 22:00', 'พฤหัสบดี': '09:30 - 22:00', 'ศุกร์': '09:30 - 22:00', 'เสาร์': '09:30 - 22:00'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Service.__del__ at 0x000001A4A8352520>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 189, in __del__\n",
      "    self.stop()\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 146, in stop\n",
      "    self.send_remote_shutdown_command()\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 131, in send_remote_shutdown_command\n",
      "    if not self.is_connectable():\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 120, in is_connectable\n",
      "    return utils.is_connectable(self.port)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\utils.py\", line 101, in is_connectable\n",
      "    socket_ = socket.create_connection((host, port), 1)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\socket.py\", line 844, in create_connection\n",
      "    exceptions.clear()  # raise only the last error\n",
      "    ^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub name ->  ภูเก็ต\n",
      "name ->  โกเบนซ์ภูเก็ต\n",
      "cur tags\n",
      "['อื่นๆ']\n",
      "no website ...\n",
      "{}\n",
      "no price range ...\n",
      "\n",
      "no facilities ...\n",
      "no opening hours ...\n",
      "cur opening hours: \n",
      "{}\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=127.0.6533.100)\nStacktrace:\n\tGetHandleVerifier [0x00007FF600379632+30946]\n\t(No symbol) [0x00007FF60032E3C9]\n\t(No symbol) [0x00007FF600226FDA]\n\t(No symbol) [0x00007FF6001FCB85]\n\t(No symbol) [0x00007FF6002A37A7]\n\t(No symbol) [0x00007FF6002AA8C7]\n\t(No symbol) [0x00007FF60029CA30]\n\t(No symbol) [0x00007FF60026A6E5]\n\t(No symbol) [0x00007FF60026B021]\n\tGetHandleVerifier [0x00007FF6004AF83D+1301229]\n\tGetHandleVerifier [0x00007FF6004BBDB7+1351783]\n\tGetHandleVerifier [0x00007FF6004B2A03+1313971]\n\tGetHandleVerifier [0x00007FF6003ADD06+245686]\n\t(No symbol) [0x00007FF60033758F]\n\t(No symbol) [0x00007FF600333804]\n\t(No symbol) [0x00007FF600333992]\n\t(No symbol) [0x00007FF60032A3EF]\n\tBaseThreadInitThunk [0x00007FFFA700257D+29]\n\tRtlUserThreadStart [0x00007FFFA7B0AF28+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m cur_regionId \u001b[38;5;241m=\u001b[39m cur_region_data[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# get dataframe result of all restaurants in current province\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m cur_res_allRestaurants_df \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_restaurants_by_province\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwongnai_regionId\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_regionId\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovince\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_province\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m cnt_for_debug \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# save result dataframe to .csv\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 67\u001b[0m, in \u001b[0;36mscrape_restaurants_by_province\u001b[1;34m(province, wongnai_regionId)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# navigate to the current restaurant page and continue scraping more data\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# get url via \"href\" attribute of tag 'a' -> navigate restaurant page\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     link_to_restaurant \u001b[38;5;241m=\u001b[39m cur_clickable_element\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m     \u001b[43mscrape_restaurant\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlink_to_restaurant\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlink_to_restaurant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestaurant\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_restaurant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# find button to click next -> get url via \"href\" attribute of tag 'a' -> navigate to the next page in a new browser window (aviod wongnai might not allowed web scraping).\u001b[39;00m\n\u001b[0;32m     73\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 91\u001b[0m, in \u001b[0;36mscrape_restaurant\u001b[1;34m(link_to_restaurant, restaurant)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(openingHours)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# scrape location\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# scrape image path\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m \u001b[43mrestaurant_page_driver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:465\u001b[0m, in \u001b[0;36mWebDriver.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Closes the current window.\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \n\u001b[0;32m    460\u001b[0m \u001b[38;5;124;03m    :Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m            driver.close()\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLOSE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=127.0.6533.100)\nStacktrace:\n\tGetHandleVerifier [0x00007FF600379632+30946]\n\t(No symbol) [0x00007FF60032E3C9]\n\t(No symbol) [0x00007FF600226FDA]\n\t(No symbol) [0x00007FF6001FCB85]\n\t(No symbol) [0x00007FF6002A37A7]\n\t(No symbol) [0x00007FF6002AA8C7]\n\t(No symbol) [0x00007FF60029CA30]\n\t(No symbol) [0x00007FF60026A6E5]\n\t(No symbol) [0x00007FF60026B021]\n\tGetHandleVerifier [0x00007FF6004AF83D+1301229]\n\tGetHandleVerifier [0x00007FF6004BBDB7+1351783]\n\tGetHandleVerifier [0x00007FF6004B2A03+1313971]\n\tGetHandleVerifier [0x00007FF6003ADD06+245686]\n\t(No symbol) [0x00007FF60033758F]\n\t(No symbol) [0x00007FF600333804]\n\t(No symbol) [0x00007FF600333992]\n\t(No symbol) [0x00007FF60032A3EF]\n\tBaseThreadInitThunk [0x00007FFFA700257D+29]\n\tRtlUserThreadStart [0x00007FFFA7B0AF28+40]\n"
     ]
    }
   ],
   "source": [
    "cnt_for_debug = 0\n",
    "for cur_region_data in ALL_REGION_ID_WONGNAI:\n",
    "    if(cnt_for_debug == 1):\n",
    "        break\n",
    "    \n",
    "    cur_province = cur_region_data[1]\n",
    "    cur_regionId = cur_region_data[2]\n",
    "\n",
    "    # get dataframe result of all restaurants in current province\n",
    "    cur_res_allRestaurants_df = scrape_restaurants_by_province(\n",
    "        wongnai_regionId = cur_regionId,\n",
    "        province = cur_province\n",
    "    )\n",
    "    cnt_for_debug += 1\n",
    "    # save result dataframe to .csv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
