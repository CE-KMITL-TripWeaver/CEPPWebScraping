{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import constants.constants as const\n",
    "import constants.file_handler_constants as fh\n",
    "from constants.accommodation_constants import *\n",
    "\n",
    "from packages.accommodation.accommodation import *\n",
    "from packages.file_handler_package.file_handler import *\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, dotenv_values \n",
    "\n",
    "from selenium.webdriver import Remote, ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.actions.wheel_input import ScrollOrigin\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "from selenium.webdriver.edge.options import Options\n",
    "\n",
    "\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_accommodation_df(accommodation: Accommodation) -> pd.DataFrame:\n",
    "    accommodation_dict = {\n",
    "        'name' : [accommodation.get_name()],\n",
    "        'description' : [accommodation.get_description()],\n",
    "        'latitude' : [accommodation.get_latitude()],\n",
    "        'longitude' : [accommodation.get_longitude()],\n",
    "        'imgPath' : [accommodation.get_imgPath()],\n",
    "        'phone': [accommodation.get_phone()],\n",
    "        'website': [accommodation.get_website()],\n",
    "        'star': [accommodation.get_star()],\n",
    "        'facility': [accommodation.get_facility()],\n",
    "        'tag': [accommodation.get_tag()],\n",
    "        'type': [accommodation.get_type()],\n",
    "\n",
    "        # location\n",
    "        'address' : [accommodation.get_location().get_address()],\n",
    "        'province' : [accommodation.get_location().get_province()],\n",
    "        'district' : [accommodation.get_location().get_district()],\n",
    "        'subDistrict' : [accommodation.get_location().get_sub_district()],\n",
    "        'province_code' : [accommodation.get_location().get_province_code()],\n",
    "        'district_code' : [accommodation.get_location().get_district_code()],\n",
    "        'sub_district_code' : [accommodation.get_location().get_sub_district_code()],\n",
    "\n",
    "        # rating\n",
    "        'score' : [accommodation.get_rating().get_score()],\n",
    "        'ratingCount' : [accommodation.get_rating().get_ratingCount()],\n",
    "    }\n",
    "\n",
    "    accommodation_df = pd.DataFrame(accommodation_dict)\n",
    "    \n",
    "    return accommodation_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_url_by_page(link_to_accommodation: str, page: int) -> str:\n",
    "\n",
    "    if(page == 1):\n",
    "        return link_to_accommodation\n",
    "    \n",
    "    first_page_url_split = link_to_accommodation.split('-')\n",
    "    nth_count_page = 'oa%s' % ((page - 1) * 30)\n",
    "    first_page_url_split[-2] = nth_count_page\n",
    "    res_page_url =  \"-\".join(first_page_url_split)\n",
    "\n",
    "    return res_page_url\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_img(accommodation_page_driver: webdriver) -> list[str]:\n",
    "    \n",
    "    res_imgPath = []\n",
    "\n",
    "    # find button and click\n",
    "    # to see image modal\n",
    "    try:\n",
    "        print(\"p2\")\n",
    "        # click_img_btn = accommodation_page_driver.find_element(By.CLASS_NAME, 'QXsnf')\n",
    "        WebDriverWait(accommodation_page_driver, 2).until(EC.visibility_of_element_located((By.CLASS_NAME, 'GuzzA')))\n",
    "        click_img_btn = accommodation_page_driver.find_element(By.CLASS_NAME, 'GuzzA')\n",
    "        print(\"p3\")\n",
    "        \n",
    "        # Move to the element and click\n",
    "        actions = ActionChains(accommodation_page_driver)\n",
    "        actions.move_to_element(click_img_btn).click().perform()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"can't open modal image\")\n",
    "        return res_imgPath\n",
    "\n",
    "    # scrape image address\n",
    "    try:\n",
    "        is_end_scrape_img = False\n",
    "        cnt_retry = 0\n",
    "        print(\"p7\")\n",
    "        while(not is_end_scrape_img):\n",
    "            if(cnt_retry == 20):\n",
    "                print(\"max retry for scrape image...\")\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                WebDriverWait(accommodation_page_driver, 2).until(EC.visibility_of_element_located((By.CLASS_NAME, 'cfCAA')))\n",
    "                all_img_elements = accommodation_page_driver.find_elements(By.CLASS_NAME, 'cfCAA')\n",
    "                print(\"find image element -> \", len(all_img_elements))\n",
    "                for cur_img_element in all_img_elements:\n",
    "                    cur_bgImg_val = cur_img_element.value_of_css_property('background-image')\n",
    "                    match = re.search(r'url\\(\"(.*?)\"\\)', cur_bgImg_val)\n",
    "                    if match:\n",
    "                        res_imgPath.append(match.group(1))\n",
    "\n",
    "                is_end_scrape_img = True\n",
    "\n",
    "            except Exception as e:\n",
    "                cnt_retry += 1\n",
    "                print(\"retry scrape img...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "            pass\n",
    "    \n",
    "\n",
    "    return res_imgPath.copy()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_location(accommodation_page_driver: webdriver, latitude: float, longitude: float, province_th: str) -> Location:\n",
    "\n",
    "    # find better address description on wongnai\n",
    "    # for example: \"991 ถนนพระราม 1 Pathum Wan, กรุงเทพมหานคร (กทม.) 10330 ไทย\"\n",
    "    address_tripAdvisor = \"\"\n",
    "    possible_address_xpath = [\n",
    "        '//*[@id=\"lithium-root\"]/main/span/div[4]/div/div[1]/div[3]/div/div[3]/div[1]/div[2]/span[2]/span',\n",
    "        '//*[@id=\"lithium-root\"]/main/span/div[4]/div/div[1]/div[3]/div/div[3]/div[1]/div[1]/span[2]/span',\n",
    "    ]\n",
    "\n",
    "\n",
    "    for cur_address_xpath in possible_address_xpath:\n",
    "        try:\n",
    "            WebDriverWait(accommodation_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, cur_address_xpath)))\n",
    "            address_element = accommodation_page_driver.find_element(By.XPATH, cur_address_xpath)\n",
    "            address_tripAdvisor = address_element.text\n",
    "            \n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "\n",
    "    # start scrape location\n",
    "    res_location = Location()\n",
    "    cnt_retry = 0\n",
    "    try:\n",
    "        while(True):\n",
    "            if(cnt_retry == 10):\n",
    "                print(\"max retry for scrape Google Map ...\")\n",
    "                break\n",
    "            \n",
    "            # set up new webdriver to work googlemap url(query for specific lat/long)\n",
    "            possible_addressGoogleMap_elements = []\n",
    "            try:\n",
    "                # set Chrome options to run in headless mode\n",
    "                # options = Options()\n",
    "                options = webdriver.ChromeOptions()\n",
    "                options.add_argument(\"start-maximized\")\n",
    "                # options.add_argument(\"--headless=new\")\n",
    "                options.add_experimental_option(\n",
    "                    \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    "                )\n",
    "\n",
    "                google_map_driver = webdriver.Chrome(options=options)\n",
    "                \n",
    "                google_map_query = \"https://www.google.com/maps/search/?api=1&query=%s,%s\" % (latitude, longitude)\n",
    "                google_map_driver.get(google_map_query)\n",
    "                print(\"scrape location data for, \", google_map_query)\n",
    "                \n",
    "                WebDriverWait(google_map_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'DkEaL')))\n",
    "                possible_addressGoogleMap_elements = google_map_driver.find_elements(By.CLASS_NAME, 'DkEaL')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"retry  scrape Google Map..\")\n",
    "                cnt_retry += 1\n",
    "                google_map_driver.close()\n",
    "                continue\n",
    "\n",
    "\n",
    "            # after init new webdriver -> continure scrape location data\n",
    "\n",
    "            # if found some wiered place that doesn't even have its address\n",
    "            # skip this case for now...\n",
    "            if(not len(possible_addressGoogleMap_elements)):\n",
    "                return res_location\n",
    "\n",
    "            subStrDistrict = \"อำเภอ\"\n",
    "            subStrSubDistrict = \"ตำบล\"\n",
    "\n",
    "            if province_th == \"กรุงเทพมหานคร\":\n",
    "                subStrDistrict = \"เขต\"\n",
    "                subStrSubDistrict = \"แขวง\"\n",
    "\n",
    "            district = 0\n",
    "            subDirstrict = 0\n",
    "\n",
    "            # find location\n",
    "            useData = None\n",
    "            for cur_element in possible_addressGoogleMap_elements:\n",
    "                if province_th in cur_element.text and cur_element.text.find(subStrDistrict) != -1:\n",
    "                    useData = cur_element.text.replace(\",\",\"\").replace(\"เเ\",\"แ\")\n",
    "                    break\n",
    "           \n",
    "            if(useData != None):\n",
    "                # print(\"Full Address :\",useData)\n",
    "                # another brute force way in case of province 'กรุงเทพหมานคร' not have word 'แขวง' in address\n",
    "                if(province_th == 'กรุงเทพมหานคร' and useData.find(subStrSubDistrict) == -1):\n",
    "                    subAddress_split = useData.split(' ')\n",
    "                    cur_province_Idx = subAddress_split.index(province_th)\n",
    "                    district = subAddress_split[cur_province_Idx - 1].replace(\"เขต\",\"\")\n",
    "\n",
    "                else:\n",
    "                    start_address_index = useData.find(subStrDistrict)\n",
    "                    subAddress = useData[start_address_index:]\n",
    "                    district = subAddress[subAddress.find(subStrDistrict)+len(subStrDistrict):subAddress.find(province_th)].replace(\" \",\"\")               \n",
    "\n",
    "                if district == \"เมือง\":\n",
    "                    district = district+province_th\n",
    "\n",
    "                # filter row to find 'ISO_3166_code', 'zip_code', 'geo_code'\n",
    "                geo_code_df = pd.read_csv(fh.PATH_TO_GEOCODE)\n",
    "                filtered_rows = geo_code_df[\n",
    "                    (geo_code_df['province_th'] == province_th) & (geo_code_df['district_th'] == district)\n",
    "                ]\n",
    "                filtered_rows.reset_index(inplace=True, drop=True)\n",
    "                \n",
    "                if not filtered_rows.empty:\n",
    "                    print(\"found province :\",filtered_rows.loc[0, 'ISO_3166_code'], province_th)\n",
    "                    print(\"found District :\",filtered_rows.loc[0, 'zip_code'], district)\n",
    "\n",
    "                    res_location.set_address(address_tripAdvisor if len(address_tripAdvisor) else useData)\n",
    "                    res_location.set_province(province_th)\n",
    "                    res_location.set_district(district)\n",
    "                    res_location.set_sub_district(\"\")\n",
    "                    res_location.set_province_code(filtered_rows.loc[0, 'ISO_3166_code'])\n",
    "                    res_location.set_district_code(filtered_rows.loc[0, 'zip_code'])\n",
    "                    res_location.set_sub_district_code(0)\n",
    "\n",
    "                else:\n",
    "                    print(\"not found province :\", province_th)\n",
    "                    print(\"not found District :\", district)\n",
    "\n",
    "                    res_location.set_address(address_tripAdvisor if len(address_tripAdvisor) else useData)\n",
    "                    res_location.set_province(province_th)\n",
    "                    res_location.set_district(district)\n",
    "                    res_location.set_sub_district(\"\")\n",
    "                    res_location.set_province_code(0)\n",
    "                    res_location.set_district_code(0)\n",
    "                    res_location.set_sub_district_code(0)\n",
    "\n",
    "            google_map_driver.close()\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"can't scrape location data\")\n",
    "\n",
    "    return res_location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape lat/long, and types (there are in another page of current accommodation)\n",
    "def scrape_location_latlong_types(accommodation_page_driver: webdriver, link_to_adjust_page: str) -> tuple[float, float, list[str]]:\n",
    "    lat = 0\n",
    "    long = 0\n",
    "\n",
    "    # create new webdriver to continue scrape lat/long, openingHours in adjust accommodation page\n",
    "    cnt_retry = 0\n",
    "    \n",
    "    while(True):\n",
    "        # if(cnt_retry == 10):\n",
    "        #     print(\"max retry for scrape single accommodation ...\")\n",
    "        #     break\n",
    "\n",
    "        # formulate the proxy url with authentication\n",
    "        proxy_url = f\"http://{os.environ['proxy_username']}:{os.environ['proxy_password']}@{os.environ['proxy_address']}:{os.environ['proxy_port']}\"\n",
    "        \n",
    "        # set selenium-wire options to use the proxy\n",
    "        seleniumwire_options = {\n",
    "            \"proxy\": {\n",
    "                \"http\": proxy_url,\n",
    "                \"https\": proxy_url\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # set Chrome options to run in headless mode\n",
    "        options = Options()\n",
    "        options.add_argument(\"start-maximized\")\n",
    "        options.add_argument(\"--lang=th-TH\")\n",
    "        # options.add_argument(\"--headless=new\")\n",
    "        options.add_experimental_option(\n",
    "            \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    "        )\n",
    "\n",
    "        # initialize the Chrome driver with service, selenium-wire options, and chrome options\n",
    "        adjust_page_driver = webdriver.Edge(\n",
    "            service=Service(EdgeChromiumDriverManager().install()),\n",
    "            seleniumwire_options=seleniumwire_options,\n",
    "            options=options\n",
    "        )\n",
    "        \n",
    "        # retry in case of web restrictions, some elements not loaded\n",
    "        try:\n",
    "            print(\"scrape data in adjust accommodation page...\")\n",
    "            print(\"for link : \", link_to_adjust_page)\n",
    "            adjust_page_driver.get(link_to_adjust_page)\n",
    "\n",
    "            print(\"debug option of adjust page: \")\n",
    "            WebDriverWait(adjust_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'DiHOR')))\n",
    "\n",
    "            # find dropdown --> click display data below --> cick display lat/long input form\n",
    "            possible_target_btn = adjust_page_driver.find_elements(By.CLASS_NAME, 'DiHOR')\n",
    "            for cur_dropdown_btn in possible_target_btn:\n",
    "                cur_dropdown_text = cur_dropdown_btn.text\n",
    "                if(\"แนะนำการแก้ไขข้อมูลของสถานที่นี้\" in cur_dropdown_text):\n",
    "                    print(\"found target dropdown btn ...\")\n",
    "                    cur_dropdown_btn.click()\n",
    "                    WebDriverWait(adjust_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"lithium-root\"]/main/div[2]/div[3]/div[1]/div/div[2]/div[2]/div/div/div[2]/button')))\n",
    "                    # find button click to display lat/long input form\n",
    "                    display_lat_long_btn = adjust_page_driver.find_element(By.XPATH, '//*[@id=\"lithium-root\"]/main/div[2]/div[3]/div[1]/div/div[2]/div[2]/div/div/div[2]/button')\n",
    "                    display_lat_long_btn.click()\n",
    "\n",
    "        except Exception as e:\n",
    "            cnt_retry += 1\n",
    "            adjust_page_driver.quit()\n",
    "            print(\"retry adjust page...\")\n",
    "            continue\n",
    "\n",
    "      \n",
    "        # find lat/long\n",
    "        try:\n",
    "            WebDriverWait(adjust_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"lithium-root\"]/main/div[2]/div[3]/div[1]/div/div[2]/div[2]/div/div/div[2]/div/div/div[3]/div[1]/div/div[2]/div/div/div/span')))\n",
    "            WebDriverWait(adjust_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"lithium-root\"]/main/div[2]/div[3]/div[1]/div/div[2]/div[2]/div/div/div[2]/div/div/div[3]/div[2]/div/div[2]/div/div/div/span')))\n",
    "    \n",
    "            lat_input_container = adjust_page_driver.find_element(By.XPATH, '//*[@id=\"lithium-root\"]/main/div[2]/div[3]/div[1]/div/div[2]/div[2]/div/div/div[2]/div/div/div[3]/div[1]/div/div[2]/div/div/div/span')\n",
    "            lat_input_element = lat_input_container.find_element(By.TAG_NAME, 'input')\n",
    "            lat = float(lat_input_element.get_attribute('value'))\n",
    "\n",
    "            long_input_container = adjust_page_driver.find_element(By.XPATH, '//*[@id=\"lithium-root\"]/main/div[2]/div[3]/div[1]/div/div[2]/div[2]/div/div/div[2]/div/div/div[3]/div[2]/div/div[2]/div/div/div/span')\n",
    "            long_input_element = long_input_container.find_element(By.TAG_NAME, 'input')\n",
    "            long = float(long_input_element.get_attribute('value'))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"can't find lat/long\")\n",
    "        \n",
    "        print(\"lat : \", lat)\n",
    "        print(\"long : \", long)\n",
    "\n",
    "        # **if can't find lat/long --> don't scrape this attaction\n",
    "        if(lat == 0 and long == 0):\n",
    "            print(\"in scrape_location_latlong_openingHours --> can't find lat/long --> 0, 0\")\n",
    "            return lat, long, [\"ไม่รู้จัก\"]\n",
    "\n",
    "        # find type\n",
    "        types = []\n",
    "        all_accomodation_types = [\"โรงแรม\", \"โมเตล\", \"รีสอร์ท\", \"ที่พักพร้อมอาหารเช้า\", \"โรงแรมขนาดเล็ก\", \"Condominium/Apartment\", \"วิลล่า\", \"พื้นที่ตั้งแคมป์\", \"โฮสเทล\", \"Vacation Rental House\", \"ไม่รู้จัก\"] \n",
    "        try:\n",
    "            # PMWyE\n",
    "            WebDriverWait(adjust_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'PMWyE')))\n",
    "            all_checkbox_containers = adjust_page_driver.find_elements(By.CLASS_NAME, 'PMWyE')\n",
    "            for i in range(len(all_checkbox_containers)):\n",
    "                cur_checkbox = all_checkbox_containers[i].find_element(By.TAG_NAME, 'span')\n",
    "                is_check = True if cur_checkbox.get_attribute('class') != 'U' else False\n",
    "                if(is_check):\n",
    "                    types.append(all_accomodation_types[i])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"can't find type\")\n",
    "\n",
    "        print(\"types --> \", types)\n",
    "\n",
    "        adjust_page_driver.quit()\n",
    "        break\n",
    "\n",
    "    return lat, long, types.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_single_accommodation(link_to_accommodation: str, province_th: str) -> Accommodation:\n",
    "    \n",
    "    accommodation = Accommodation()\n",
    "    cnt_retry = 0\n",
    "    \n",
    "    while(True):\n",
    "        # if(cnt_retry == 10):\n",
    "        #     print(\"max retry for scrape single accommodation ...\")\n",
    "        #     break\n",
    "\n",
    "        # formulate the proxy url with authentication\n",
    "        proxy_url = f\"http://{os.environ['proxy_username']}:{os.environ['proxy_password']}@{os.environ['proxy_address']}:{os.environ['proxy_port']}\"\n",
    "        \n",
    "        # set selenium-wire options to use the proxy\n",
    "        seleniumwire_options = {\n",
    "            \"proxy\": {\n",
    "                \"http\": proxy_url,\n",
    "                \"https\": proxy_url\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # set web browser options to run\n",
    "        options = Options()\n",
    "        options.add_argument(\"start-maximized\")\n",
    "        options.add_argument(\"--lang=th-TH\")\n",
    "        options.add_experimental_option(\n",
    "            \"prefs\", \n",
    "            {\n",
    "                \"profile.managed_default_content_settings.images\": 2, # Disable image\n",
    "                \"profile.default_content_setting_values.cookies\": 2,  # Block all cookies\n",
    "                \"profile.default_content_settings.popups\": 0,         # Disable popups\n",
    "                \"profile.managed_default_content_settings.cookies\": 2  # Disable third-party cookies\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # initialize the web driver with service, selenium-wire options, and web browser options\n",
    "        accommodation_page_driver = webdriver.Edge(\n",
    "            service=Service(EdgeChromiumDriverManager().install()),\n",
    "            seleniumwire_options=seleniumwire_options,\n",
    "            options=options\n",
    "        )\n",
    "        \n",
    "        # retry in case of web restrictions and some elements not loaded\n",
    "        try:\n",
    "            print(\"******************************************************\")\n",
    "            print(\"scrape single accommodation...\")\n",
    "            print(\"for accommodation : \", link_to_accommodation)\n",
    "            accommodation_page_driver.get(link_to_accommodation)\n",
    "            # accommodation_page_driver.add_cookie()\n",
    "\n",
    "            print(\"debug scrape_single_accommodation: top info component section\")\n",
    "            # WebDriverWait(accommodation_page_driver, 2).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"lithium-root\"]/main/span/div[4]/div/div[1]/div[3]/div')))\n",
    "            # top_info_container = accommodation_page_driver.find_element(By.XPATH, '//*[@id=\"lithium-root\"]/main/span/div[4]/div/div[1]/div[3]/div')\n",
    "\n",
    "            print(\"debug scrape_single_accommodation: bottom info component section\")\n",
    "            WebDriverWait(accommodation_page_driver, 2).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"ABOUT_TAB\"]')))\n",
    "            bottom_info_container = accommodation_page_driver.find_element(By.XPATH, '//*[@id=\"ABOUT_TAB\"]')\n",
    "\n",
    "            print(\"debug scrape_single_attraction: common component section\")\n",
    "            WebDriverWait(accommodation_page_driver, 2).until(EC.visibility_of_element_located((By.CLASS_NAME, 'IDaDx')))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"retry single accommodation case 1...\")\n",
    "            cnt_retry += 1\n",
    "            accommodation_page_driver.quit()\n",
    "            continue\n",
    "        \n",
    "\n",
    "\n",
    "        # find name\n",
    "        name = \"\"\n",
    "        try:\n",
    "            WebDriverWait(accommodation_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'rRtyp')))\n",
    "            name_element = accommodation_page_driver.find_element(By.CLASS_NAME, 'rRtyp')\n",
    "            name = name_element.text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"can't find name\")\n",
    "\n",
    "        print(\"name -> \", name)\n",
    "\n",
    "        # find description\n",
    "        description = \"\"\n",
    "        try:\n",
    "            try:\n",
    "                # find button to click readmore (if it exists, it likely to be the first elements of class 'lszDU')\n",
    "                WebDriverWait(accommodation_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'lszDU')))\n",
    "                click_readmore_btn = accommodation_page_driver.find_element(By.CLASS_NAME, 'lszDU')\n",
    "                click_readmore_btn.click()\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            WebDriverWait(accommodation_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'zYHGB')))\n",
    "            all_description_elements = accommodation_page_driver.find_elements(By.CLASS_NAME, 'zYHGB')\n",
    "            for cur_element in all_description_elements:\n",
    "                cur_text =  cur_element.text\n",
    "                if(len(cur_text)):\n",
    "                    description += cur_text + '\\n'\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"can't find description\")\n",
    "\n",
    "        print(\"description -> \", description)\n",
    "        \n",
    "        # find phone\n",
    "        phone = \"\"\n",
    "        try:\n",
    "            WebDriverWait(accommodation_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"lithium-root\"]/main/span/div[4]/div/div[1]/div[3]/div/div[3]/div[1]/div[3]/div[2]/div/a')))\n",
    "            phone_element = accommodation_page_driver.find_element(By.XPATH, '//*[@id=\"lithium-root\"]/main/span/div[4]/div/div[1]/div[3]/div/div[3]/div[1]/div[3]/div[2]/div/a')\n",
    "            phone_element_href = phone_element.get_attribute('href')\n",
    "            if(\"tel\" in phone_element_href):\n",
    "                phone = phone_element.text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"can't find phone\")\n",
    "\n",
    "        print(\"phone --> \", phone)\n",
    "\n",
    "        # find rating\n",
    "        rating = 0\n",
    "        rating_count = 0\n",
    "        try:\n",
    "            WebDriverWait(accommodation_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'dGsKv')))\n",
    "            rating_container = accommodation_page_driver.find_element(By.CLASS_NAME, 'dGsKv')\n",
    "            \n",
    "            rating_element = rating_container.find_element(By.CLASS_NAME, 'kJyXc')\n",
    "            rating = float(rating_element.text)\n",
    "\n",
    "            rating_count_element = rating_container.find_element(By.CLASS_NAME, 'KxBGd')\n",
    "            rating_count = int(rating_count_element.text.replace(',', '').replace('รีวิว ', '').replace(' รายการ', ''))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"can't find rating and rating_count\")\n",
    "\n",
    "        print(\"rating --> \", rating)\n",
    "        print(\"rating_count --> \", rating_count)\n",
    "\n",
    "        # find facilities, tags\n",
    "        facilities = []\n",
    "        tags = []\n",
    "        try:\n",
    "            target_xpath = [\n",
    "                '//*[@id=\"ABOUT_TAB\"]/div[2]/div[2]/div[2]',\n",
    "                '//*[@id=\"ABOUT_TAB\"]/div[2]/div[2]/div[5]',\n",
    "                '//*[@id=\"ABOUT_TAB\"]/div[2]/div[2]/div[8]'\n",
    "            ]\n",
    "            Idx_target = 0\n",
    "            Idx_topic = 0\n",
    "            \n",
    "            WebDriverWait(accommodation_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'vqEpQ')))\n",
    "            all_topic_elements = accommodation_page_driver.find_elements(By.CLASS_NAME, 'vqEpQ')\n",
    "            fixed_topic = [\"สิ่งอำนวยความสะดวกของสถานที่ให้บริการ\", \"สิ่งอำนวยความสะดวกในห้องพัก\", \"ประเภทห้องพัก\"]\n",
    "\n",
    "            while(Idx_target < len(target_xpath)):\n",
    "                try:\n",
    "                    WebDriverWait(accommodation_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, target_xpath[Idx_target])))\n",
    "                    target_container = accommodation_page_driver.find_element(By.XPATH, target_xpath[Idx_target])\n",
    "\n",
    "                    cur_topic = all_topic_elements[Idx_topic].text\n",
    "                    print(\"cur_topic --> \", cur_topic)\n",
    "\n",
    "                    if(cur_topic not in fixed_topic):\n",
    "                        Idx_topic += 1\n",
    "                        continue\n",
    "\n",
    "                    if(cur_topic == \"สิ่งอำนวยความสะดวกของสถานที่ให้บริการ\" or cur_topic == \"สิ่งอำนวยความสะดวกในห้องพัก\"):\n",
    "                        all_facility_elements = target_container.find_elements(By.CLASS_NAME, 'gFttI')\n",
    "                        for cur_facility_element in all_facility_elements:\n",
    "                            cur_facility_text = cur_facility_element.text\n",
    "                            if(not len(cur_facility_text)):\n",
    "                                continue\n",
    "                            facilities.append(cur_facility_text)\n",
    "\n",
    "                    elif(cur_topic ==  \"ประเภทห้องพัก\"):\n",
    "                        all_tag_elements = target_container.find_elements(By.CLASS_NAME, 'gFttI')\n",
    "                        for cur_tag_element in all_tag_elements:\n",
    "                            cur_tag_text = cur_tag_element.text\n",
    "                            if(not len(cur_tag_text)):\n",
    "                                continue                        \n",
    "                            tags.append(cur_tag_text)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "                Idx_target += 1\n",
    "                Idx_topic += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"can't find facilities or tags\")\n",
    "\n",
    "        print(\"facilities --> \", facilities)\n",
    "        print(\"tags --> \", tags)\n",
    "\n",
    "        # find star\n",
    "        star = 0\n",
    "        try:\n",
    "            WebDriverWait(accommodation_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'JXZuC')))\n",
    "            star_container = accommodation_page_driver.find_element(By.CLASS_NAME, 'JXZuC')\n",
    "            star_element = star_container.find_element(By.TAG_NAME, 'title')\n",
    "            star = star_element.text.split(' ')[0]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"can't find star\")\n",
    "\n",
    "        print(\"star --> \", star)\n",
    "\n",
    "\n",
    "        # convert accommodation url to adjust page url\n",
    "        # for example: from 'https://th.tripadvisor.com/Hotel_Review-g10804710-d586602-Reviews-Pacific_Club_Resort-Karon_Beach_Karon_Phuket.html' to 'https://th.tripadvisor.com/ImproveListing-d586602.html'\n",
    "        link_to_adjust_page = 'https://th.tripadvisor.com/ImproveListing-%s.html' % (link_to_accommodation.split('-')[2])\n",
    "\n",
    "        # ** find lat/long, location data and openingHours (there are in another page of current accommodation)\n",
    "        # ** if this accommodation not have lat/long\n",
    "        # ** don't continue to scrape\n",
    "        lat, long, types = scrape_location_latlong_types(\n",
    "            accommodation_page_driver = accommodation_page_driver,\n",
    "            link_to_adjust_page = link_to_adjust_page\n",
    "        )\n",
    "        \n",
    "        # **if can't find lat/long --> don't scrape this attaction\n",
    "        if(lat == 0 and long == 0):\n",
    "            print(\"in scrape_single_accommodation --> can't find lat/long --> don't scrape this accommodation ...\")\n",
    "            accommodation_page_driver.quit()\n",
    "            return Accommodation()\n",
    "\n",
    "\n",
    "        # find location\n",
    "        location = scrape_location(\n",
    "            accommodation_page_driver = accommodation_page_driver,\n",
    "            latitude = lat,\n",
    "            longitude = long,\n",
    "            province_th = province_th\n",
    "        )\n",
    "        print(\"province :\", location.get_province_code(), location.get_province())\n",
    "        print(\"District :\", location.get_district_code(), location.get_district())\n",
    "        print(\"Address : \", location.get_address())\n",
    "\n",
    "\n",
    "        # find img_path\n",
    "        img_path = scrape_img(accommodation_page_driver)\n",
    "        print(\"cur img path -> \", img_path)\n",
    "\n",
    "        # set some of \"accommodation\" object properties\n",
    "        accommodation.set_name(name)\n",
    "        accommodation.set_description(description)\n",
    "        accommodation.set_phone(phone)\n",
    "        accommodation.set_latitude(lat)\n",
    "        accommodation.set_longitude(long)\n",
    "        accommodation.set_imgPath(img_path)\n",
    "        accommodation.set_website(link_to_accommodation)\n",
    "        accommodation.set_facility(facilities)\n",
    "        accommodation.set_tag(tags)\n",
    "        accommodation.set_type(types)\n",
    "        accommodation.set_star(star)\n",
    "        accommodation.set_location(\n",
    "            address = location.get_address(),\n",
    "            province = location.get_province(),\n",
    "            district = location.get_district(),\n",
    "            sub_district = location.get_sub_district(),\n",
    "            province_code = location.get_province_code(),\n",
    "            district_code = location.get_district_code(),\n",
    "            sub_district_code = location.get_sub_district_code()\n",
    "        )\n",
    "        accommodation.set_rating(\n",
    "            score = rating,\n",
    "            rating_count = rating_count\n",
    "        )\n",
    "\n",
    "        accommodation_page_driver.quit()\n",
    "        break\n",
    "\n",
    "    return accommodation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_url_by_page(query_url: str, page: int) -> list[str]:\n",
    "\n",
    "    res_url_by_page = []\n",
    "\n",
    "    cnt_retry = 0\n",
    "    \n",
    "    while(True):\n",
    "        \n",
    "        if(cnt_retry == 10):\n",
    "            print(\"max retry for scrape data by page ...\")\n",
    "            break\n",
    "\n",
    "        # formulate the proxy url with authentication\n",
    "        # os.environ['proxy_port']\n",
    "        proxy_url = f\"http://{os.environ['proxy_username']}:{os.environ['proxy_password']}@{os.environ['proxy_address']}:{os.environ['proxy_port']}\"\n",
    "        \n",
    "        # set selenium-wire options to use the proxy\n",
    "        seleniumwire_options = {\n",
    "            \"proxy\": {\n",
    "                \"http\": proxy_url,\n",
    "                \"https\": proxy_url\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # set Chrome options to run in headless mode\n",
    "        options = Options()\n",
    "        options.add_argument(\"start-maximized\")\n",
    "        options.add_argument(\"--lang=th-TH\")\n",
    "        # options.add_argument(\"--headless=new\")\n",
    "        options.add_experimental_option(\n",
    "            \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    "        )\n",
    "      \n",
    "        # initialize the Chrome driver with service, selenium-wire options, and chrome options\n",
    "        driver = webdriver.Edge(\n",
    "            service=Service(EdgeChromiumDriverManager().install()),\n",
    "            seleniumwire_options=seleniumwire_options,\n",
    "            options=options\n",
    "        )\n",
    "        \n",
    "        # just check for ip\n",
    "        # print(\"just check for ip :\")\n",
    "        # driver.get(\"https://httpbin.io/ip\")\n",
    "        # print(driver.page_source)\n",
    "\n",
    "        # find group of accommodation on the nth page\n",
    "        all_accommodations_card = []\n",
    "\n",
    "        # retry in case of web restrictions and some elements not loaded\n",
    "        try:\n",
    "            query_url_by_page = convert_url_by_page(\n",
    "                link_to_accommodation = query_url,\n",
    "                page = page\n",
    "            )\n",
    "            driver.get(query_url_by_page)\n",
    "            # scroll and wait for some msec\n",
    "            driver.execute_script('window.scrollBy(0, document.body.scrollHeight)')\n",
    "            \n",
    "            print(\"check current page url --> \", driver.current_url)\n",
    "\n",
    "            # wait for div (each accommodation section) to be present and visible\n",
    "            print(\"b1 part 1\")\n",
    "            print(\"debug get_all_url_by_page: accommodation by one page section\")\n",
    "            WebDriverWait(driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'jhsNf')))\n",
    "            all_accommodations_card = driver.find_elements(By.CLASS_NAME, 'jhsNf')\n",
    "\n",
    "            # if current page is 1, find button \"ดูทั้งหมด\"(if it exist) --> click to load more accommodation card elements\n",
    "            # assume that page 1 of target province (phuket for now) not less than 10\n",
    "            # if(page == 1 and len(all_accommodations_card) <= 10):\n",
    "            #     print(\"b 0.5\")\n",
    "            #     print(\"debug get_all_url_by_page: get click more btn for page 1\")\n",
    "            #     WebDriverWait(driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'sOtnj')))\n",
    "            #     click_more_btn = driver.find_element(By.CLASS_NAME, 'sOtnj')\n",
    "            #     click_more_btn.click()\n",
    "\n",
    "            #     # wait for div (each accommodation section) to be present and visible\n",
    "            #     print(\"b1 part 2\")\n",
    "            #     print(\"debug get_all_url_by_page: accommodation by one page section\")\n",
    "            #     WebDriverWait(driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'jhsNf')))\n",
    "            #     all_accommodations_card = driver.find_elements(By.CLASS_NAME, 'jhsNf')\n",
    "\n",
    "            # check if all accomodation card can get tag a and its attribute for url\n",
    "            print(\"b2\")\n",
    "            print(\"check in loop ...\")\n",
    "            for cur_accommodation_card in all_accommodations_card:\n",
    "\n",
    "                cur_accommodation_url = cur_accommodation_card.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                print(\"cur_accommodation_url : \", cur_accommodation_url)\n",
    "                res_url_by_page.append(cur_accommodation_url)\n",
    "            \n",
    "            driver.quit()\n",
    "            break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"retry find get_all_url_by_page ...\")\n",
    "            cnt_retry += 1\n",
    "            driver.quit()\n",
    "            continue\n",
    "\n",
    "    return res_url_by_page.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_accommodations_by_province(page: int, province_url: str, province: str) -> pd.DataFrame:\n",
    "    # res_accommodation_df = pd.DataFrame()\n",
    "    res_accommodation_df = create_accommodation_df(Accommodation())\n",
    "    \n",
    "    cnt_for_debug = 0\n",
    "        \n",
    "    print(\"scraping accommodation | province --> %s | page --> %s\" % (province, page))\n",
    "\n",
    "    all_url_by_page = get_all_url_by_page(query_url = province_url, page = page)\n",
    "\n",
    "    # use data from 'res_get_data_by_page' to retrive data of specific accommodation\n",
    "    for cur_accommodation_url in all_url_by_page:\n",
    "        # just use to limit amount of place --> will be removed \n",
    "        if(cnt_for_debug == 5):\n",
    "            break\n",
    "\n",
    "        # continue scraping data for a specific resgtaurant\n",
    "        cur_accommodation = scrape_single_accommodation(\n",
    "            link_to_accommodation = cur_accommodation_url,\n",
    "            province_th = province\n",
    "        )\n",
    "\n",
    "        cnt_for_debug += 1\n",
    "\n",
    "        # create data frame represent data scrape from current accommodation card\n",
    "        cur_accommodation_df = create_accommodation_df(accommodation=cur_accommodation)\n",
    "\n",
    "        # concat all data frame result\n",
    "        res_accommodation_df = pd.concat([res_accommodation_df, cur_accommodation_df])\n",
    "    \n",
    "    return res_accommodation_df.iloc[1:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping accommodation | province --> ภูเก็ต | page --> 1\n",
      "check current page url -->  https://th.tripadvisor.com/Hotels-g293920-Phuket-Hotels.html\n",
      "b1 part 1\n",
      "debug get_all_url_by_page: accommodation by one page section\n",
      "b2\n",
      "check in loop ...\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g10804710-d535970-Reviews-Beyond_Karon-Karon_Beach_Karon_Phuket.html?spAttributionToken=MjkwMDUxNzA\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g297930-d315568-Reviews-Phuket_Marriott_Resort_Spa_Merlin_Beach-Patong_Kathu_Phuket.html\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g297930-d13140255-Reviews-Hotel_Clover_Patong_Phuket-Patong_Kathu_Phuket.html\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g1210687-d1379794-Reviews-Chanalai_Romantica_Resort-Kata_Beach_Karon_Phuket.html\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g297930-d12725009-Reviews-The_Marina_Phuket_Hotel-Patong_Kathu_Phuket.html\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g1210687-d308958-Reviews-Chanalai_Garden_Resort-Kata_Beach_Karon_Phuket.html\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g1210687-d19116177-Reviews-Pamookkoo_Resort-Kata_Beach_Karon_Phuket.html?spAttributionToken=MjkwOTk1OTY\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g297930-d557954-Reviews-Baan_Laimai_Beach_Resort_Spa-Patong_Kathu_Phuket.html\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g1223683-d519702-Reviews-JW_Marriott_Phuket_Resort_Spa-Mai_Khao_Thalang_District_Phuket.html\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g297930-d9865117-Reviews-Crest_Resort_Pool_Villas-Patong_Kathu_Phuket.html\n",
      "******************************************************\n",
      "scrape single accommodation...\n",
      "for accommodation :  https://th.tripadvisor.com/Hotel_Review-g10804710-d535970-Reviews-Beyond_Karon-Karon_Beach_Karon_Phuket.html?spAttributionToken=MjkwMDUxNzA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1:60352: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 115, in read\n",
      "    data = self.o.read(rlen)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\server.py\", line 113, in handle\n",
      "    root_layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\modes\\http_proxy.py\", line 23, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\tls.py\", line 285, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 100, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 206, in __call__\n",
      "    if not self._process_flow(flow):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 288, in _process_flow\n",
      "    return self.handle_upstream_connect(f)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 247, in handle_upstream_connect\n",
      "    f.response = self.read_response_headers()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 48, in read_response_headers\n",
      "    return http1.read_response_head(self.server_conn.rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 90, in read_response_head\n",
      "    http_version, status_code, message = _read_response_line(rfile)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 283, in _read_response_line\n",
      "    line = _get_first_line(rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 228, in _get_first_line\n",
      "    line = rfile.readline()\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 157, in readline\n",
      "    ch = self.read(1)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 133, in read\n",
      "    raise exceptions.TcpTimeout()\n",
      "seleniumwire.thirdparty.mitmproxy.exceptions.TcpTimeout: None\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug scrape_single_accommodation: top info component section\n",
      "debug scrape_single_accommodation: bottom info component section\n",
      "retry single accommodation case 1...\n",
      "******************************************************\n",
      "scrape single accommodation...\n",
      "for accommodation :  https://th.tripadvisor.com/Hotel_Review-g10804710-d535970-Reviews-Beyond_Karon-Karon_Beach_Karon_Phuket.html?spAttributionToken=MjkwMDUxNzA\n",
      "debug scrape_single_accommodation: top info component section\n",
      "debug scrape_single_accommodation: bottom info component section\n",
      "debug scrape_single_attraction: common component section\n",
      "name ->  บียอนด์ กะรน\n",
      "can't find description\n",
      "description ->  \n",
      "phone -->  +66 76 330 006\n",
      "rating -->  4.5\n",
      "rating_count -->  1580\n",
      "cur_topic -->  ข้อมูลที่ควรทราบ\n",
      "cur_topic -->  สิ่งอำนวยความสะดวกของสถานที่ให้บริการ\n",
      "cur_topic -->  สิ่งอำนวยความสะดวกในห้องพัก\n",
      "cur_topic -->  ประเภทห้องพัก\n",
      "facilities -->  ['ที่จอดรถฟรี', 'อินเทอร์เน็ตฟรี', 'สระว่ายน้ำ', 'บาร์ / เลานจ์', 'ชายหาด', 'การดำน้ำ', 'บริการดูแลเด็กเล็ก', 'บริการรถรับ-ส่งสนามบิน', 'เครื่องปรับอากาศ', 'บริการทำความสะอาด', 'ระเบียงส่วนตัว', 'บริการรูมเซอร์วิส', 'มินิบาร์', 'ตู้เย็น', 'ทีวีจอแบน', 'ไดร์เป่าผม']\n",
      "tags -->  ['วิวมหาสมุทร', 'ห้องพักปลอดบุหรี่']\n",
      "star -->  4.0\n",
      "scrape data in adjust accommodation page...\n",
      "for link :  https://th.tripadvisor.com/ImproveListing-d535970.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1:60449: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 115, in read\n",
      "    data = self.o.read(rlen)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\server.py\", line 113, in handle\n",
      "    root_layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\modes\\http_proxy.py\", line 23, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\tls.py\", line 285, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 100, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 206, in __call__\n",
      "    if not self._process_flow(flow):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 288, in _process_flow\n",
      "    return self.handle_upstream_connect(f)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 247, in handle_upstream_connect\n",
      "    f.response = self.read_response_headers()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 48, in read_response_headers\n",
      "    return http1.read_response_head(self.server_conn.rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 90, in read_response_head\n",
      "    http_version, status_code, message = _read_response_line(rfile)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 283, in _read_response_line\n",
      "    line = _get_first_line(rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 228, in _get_first_line\n",
      "    line = rfile.readline()\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 157, in readline\n",
      "    ch = self.read(1)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 133, in read\n",
      "    raise exceptions.TcpTimeout()\n",
      "seleniumwire.thirdparty.mitmproxy.exceptions.TcpTimeout: None\n",
      "\n",
      "127.0.0.1:60445: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 115, in read\n",
      "    data = self.o.read(rlen)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\server.py\", line 113, in handle\n",
      "    root_layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\modes\\http_proxy.py\", line 23, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\tls.py\", line 285, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 100, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 206, in __call__\n",
      "    if not self._process_flow(flow):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 288, in _process_flow\n",
      "    return self.handle_upstream_connect(f)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 247, in handle_upstream_connect\n",
      "    f.response = self.read_response_headers()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 48, in read_response_headers\n",
      "    return http1.read_response_head(self.server_conn.rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 90, in read_response_head\n",
      "    http_version, status_code, message = _read_response_line(rfile)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 283, in _read_response_line\n",
      "    line = _get_first_line(rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 228, in _get_first_line\n",
      "    line = rfile.readline()\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 157, in readline\n",
      "    ch = self.read(1)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 133, in read\n",
      "    raise exceptions.TcpTimeout()\n",
      "seleniumwire.thirdparty.mitmproxy.exceptions.TcpTimeout: None\n",
      "\n",
      "127.0.0.1:60444: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 115, in read\n",
      "    data = self.o.read(rlen)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\server.py\", line 113, in handle\n",
      "    root_layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\modes\\http_proxy.py\", line 23, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\tls.py\", line 285, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 100, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 206, in __call__\n",
      "    if not self._process_flow(flow):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 288, in _process_flow\n",
      "    return self.handle_upstream_connect(f)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 247, in handle_upstream_connect\n",
      "    f.response = self.read_response_headers()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 48, in read_response_headers\n",
      "    return http1.read_response_head(self.server_conn.rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 90, in read_response_head\n",
      "    http_version, status_code, message = _read_response_line(rfile)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 283, in _read_response_line\n",
      "    line = _get_first_line(rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 228, in _get_first_line\n",
      "    line = rfile.readline()\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 157, in readline\n",
      "    ch = self.read(1)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 133, in read\n",
      "    raise exceptions.TcpTimeout()\n",
      "seleniumwire.thirdparty.mitmproxy.exceptions.TcpTimeout: None\n",
      "\n",
      "127.0.0.1:60470: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 115, in read\n",
      "    data = self.o.read(rlen)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\server.py\", line 113, in handle\n",
      "    root_layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\modes\\http_proxy.py\", line 23, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\tls.py\", line 285, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 100, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 206, in __call__\n",
      "    if not self._process_flow(flow):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 288, in _process_flow\n",
      "    return self.handle_upstream_connect(f)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 247, in handle_upstream_connect\n",
      "    f.response = self.read_response_headers()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 48, in read_response_headers\n",
      "    return http1.read_response_head(self.server_conn.rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 90, in read_response_head\n",
      "    http_version, status_code, message = _read_response_line(rfile)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 283, in _read_response_line\n",
      "    line = _get_first_line(rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 228, in _get_first_line\n",
      "    line = rfile.readline()\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 157, in readline\n",
      "    ch = self.read(1)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 133, in read\n",
      "    raise exceptions.TcpTimeout()\n",
      "seleniumwire.thirdparty.mitmproxy.exceptions.TcpTimeout: None\n",
      "\n",
      "127.0.0.1:60483: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 115, in read\n",
      "    data = self.o.read(rlen)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\server.py\", line 113, in handle\n",
      "    root_layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\modes\\http_proxy.py\", line 23, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\tls.py\", line 285, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 100, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 206, in __call__\n",
      "    if not self._process_flow(flow):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 288, in _process_flow\n",
      "    return self.handle_upstream_connect(f)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 247, in handle_upstream_connect\n",
      "    f.response = self.read_response_headers()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 48, in read_response_headers\n",
      "    return http1.read_response_head(self.server_conn.rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 90, in read_response_head\n",
      "    http_version, status_code, message = _read_response_line(rfile)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 283, in _read_response_line\n",
      "    line = _get_first_line(rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 228, in _get_first_line\n",
      "    line = rfile.readline()\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 157, in readline\n",
      "    ch = self.read(1)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 133, in read\n",
      "    raise exceptions.TcpTimeout()\n",
      "seleniumwire.thirdparty.mitmproxy.exceptions.TcpTimeout: None\n",
      "\n",
      "127.0.0.1:60512: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 115, in read\n",
      "    data = self.o.read(rlen)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\server.py\", line 113, in handle\n",
      "    root_layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\modes\\http_proxy.py\", line 23, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\tls.py\", line 285, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 100, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 206, in __call__\n",
      "    if not self._process_flow(flow):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 288, in _process_flow\n",
      "    return self.handle_upstream_connect(f)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 247, in handle_upstream_connect\n",
      "    f.response = self.read_response_headers()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 48, in read_response_headers\n",
      "    return http1.read_response_head(self.server_conn.rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 90, in read_response_head\n",
      "    http_version, status_code, message = _read_response_line(rfile)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 283, in _read_response_line\n",
      "    line = _get_first_line(rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 228, in _get_first_line\n",
      "    line = rfile.readline()\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 157, in readline\n",
      "    ch = self.read(1)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 133, in read\n",
      "    raise exceptions.TcpTimeout()\n",
      "seleniumwire.thirdparty.mitmproxy.exceptions.TcpTimeout: None\n",
      "\n",
      "127.0.0.1:60511: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 115, in read\n",
      "    data = self.o.read(rlen)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\server.py\", line 113, in handle\n",
      "    root_layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\modes\\http_proxy.py\", line 23, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\tls.py\", line 285, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 100, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 206, in __call__\n",
      "    if not self._process_flow(flow):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 288, in _process_flow\n",
      "    return self.handle_upstream_connect(f)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 247, in handle_upstream_connect\n",
      "    f.response = self.read_response_headers()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 48, in read_response_headers\n",
      "    return http1.read_response_head(self.server_conn.rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 90, in read_response_head\n",
      "    http_version, status_code, message = _read_response_line(rfile)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 283, in _read_response_line\n",
      "    line = _get_first_line(rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 228, in _get_first_line\n",
      "    line = rfile.readline()\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 157, in readline\n",
      "    ch = self.read(1)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 133, in read\n",
      "    raise exceptions.TcpTimeout()\n",
      "seleniumwire.thirdparty.mitmproxy.exceptions.TcpTimeout: None\n",
      "\n",
      "127.0.0.1:60515: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 115, in read\n",
      "    data = self.o.read(rlen)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\server.py\", line 113, in handle\n",
      "    root_layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\modes\\http_proxy.py\", line 23, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\tls.py\", line 285, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 100, in __call__\n",
      "    layer()\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 206, in __call__\n",
      "    if not self._process_flow(flow):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 288, in _process_flow\n",
      "    return self.handle_upstream_connect(f)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http.py\", line 247, in handle_upstream_connect\n",
      "    f.response = self.read_response_headers()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\server\\protocol\\http1.py\", line 48, in read_response_headers\n",
      "    return http1.read_response_head(self.server_conn.rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 90, in read_response_head\n",
      "    http_version, status_code, message = _read_response_line(rfile)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 283, in _read_response_line\n",
      "    line = _get_first_line(rfile)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\http\\http1\\read.py\", line 228, in _get_first_line\n",
      "    line = rfile.readline()\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 157, in readline\n",
      "    ch = self.read(1)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\thirdparty\\mitmproxy\\net\\tcp.py\", line 133, in read\n",
      "    raise exceptions.TcpTimeout()\n",
      "seleniumwire.thirdparty.mitmproxy.exceptions.TcpTimeout: None\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug option of adjust page: \n",
      "retry adjust page...\n",
      "scrape data in adjust accommodation page...\n",
      "for link :  https://th.tripadvisor.com/ImproveListing-d535970.html\n",
      "debug option of adjust page: \n",
      "found target dropdown btn ...\n",
      "lat :  7.829528\n",
      "long :  98.295\n",
      "types -->  ['รีสอร์ท']\n",
      "scrape location data for,  https://www.google.com/maps/search/?api=1&query=7.829528,98.295\n",
      "found province : 83 ภูเก็ต\n",
      "found District : 8301 เมืองภูเก็ต\n",
      "province : 83 ภูเก็ต\n",
      "District : 8301 เมืองภูเก็ต\n",
      "Address :  51 ถ. กะรน, หาดกะรน, กะรน, จังหวัดภูเก็ต 83100 ไทย\n",
      "p2\n",
      "p3\n",
      "p7\n",
      "retry scrape img...\n",
      "retry scrape img...\n",
      "find image element ->  15\n",
      "cur img path ->  ['https://media-cdn.tripadvisor.com/media/photo-s/2d/04/96/40/caption.jpg', 'https://media-cdn.tripadvisor.com/media/photo-s/2d/04/ea/5a/caption.jpg', 'https://media-cdn.tripadvisor.com/media/photo-s/2d/04/9a/d2/caption.jpg', 'https://media-cdn.tripadvisor.com/media/photo-s/2d/04/96/3d/caption.jpg', 'https://media-cdn.tripadvisor.com/media/photo-s/2d/04/9a/fd/caption.jpg', 'https://media-cdn.tripadvisor.com/media/photo-s/2d/04/ea/5d/caption.jpg', 'https://media-cdn.tripadvisor.com/media/photo-s/24/52/6f/96/beyond-resort-karon.jpg', 'https://media-cdn.tripadvisor.com/media/photo-s/15/8c/0d/cc/beyond-resort-karon.jpg', 'https://media-cdn.tripadvisor.com/media/photo-s/15/a0/7c/b2/pool.jpg', 'https://media-cdn.tripadvisor.com/media/photo-s/15/a1/0b/66/beyond-resort-karon.jpg', 'https://media-cdn.tripadvisor.com/media/photo-s/15/a0/7d/23/beach-restaurant.jpg', 'https://media-cdn.tripadvisor.com/media/photo-s/15/a0/7d/11/beyond-cafe.jpg', 'https://media-cdn.tripadvisor.com/media/photo-s/15/a1/09/4c/beyond-resort-karon.jpg', 'https://media-cdn.tripadvisor.com/media/photo-s/15/a0/7c/c7/beach-bar.jpg', 'https://media-cdn.tripadvisor.com/media/photo-s/15/a0/7c/e5/beyond-cafe.jpg']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\socket.py:836\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    835\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m--> 836\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[0;32m    837\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m\n\u001b[0;32m     14\u001b[0m cur_province_url \u001b[38;5;241m=\u001b[39m cur_region_data[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# cur_res_allAccommodations_df = create_accommodation_df(Accommodation())\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# get dataframe result of all accommodation in current province\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m cur_res_allAccommodations_df \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_accommodations_by_province\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovince_url\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_province_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovince\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_province_th\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# don't forget to remove row with lat/long be zero\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# remove duplicate accommodation\u001b[39;00m\n\u001b[0;32m     28\u001b[0m cur_res_allAccommodations_df\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[10], line 18\u001b[0m, in \u001b[0;36mscrape_accommodations_by_province\u001b[1;34m(page, province_url, province)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# continue scraping data for a specific resgtaurant\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m cur_accommodation \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_single_accommodation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlink_to_accommodation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_accommodation_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovince_th\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprovince\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m cnt_for_debug \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# create data frame represent data scrape from current accommodation card\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 37\u001b[0m, in \u001b[0;36mscrape_single_accommodation\u001b[1;34m(link_to_accommodation, province_th)\u001b[0m\n\u001b[0;32m     26\u001b[0m options\u001b[38;5;241m.\u001b[39madd_experimental_option(\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     28\u001b[0m     {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     }\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# initialize the web driver with service, selenium-wire options, and web browser options\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m accommodation_page_driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEdge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mService\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEdgeChromiumDriverManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseleniumwire_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseleniumwire_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# retry in case of web restrictions and some elements not loaded\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\seleniumwire\\webdriver.py:280\u001b[0m, in \u001b[0;36mEdge.__init__\u001b[1;34m(self, seleniumwire_options, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m         caps \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesired_capabilities\u001b[39m\u001b[38;5;124m'\u001b[39m, DesiredCapabilities\u001b[38;5;241m.\u001b[39mCHROME\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[0;32m    278\u001b[0m         caps\u001b[38;5;241m.\u001b[39mupdate(config)\n\u001b[1;32m--> 280\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\edge\\webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[0;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbrowser_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEDGE\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrowserName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvendor_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mms\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:55\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     52\u001b[0m     options\u001b[38;5;241m.\u001b[39mbrowser_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39menv_path() \u001b[38;5;129;01mor\u001b[39;00m finder\u001b[38;5;241m.\u001b[39mget_driver_path()\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m executor \u001b[38;5;241m=\u001b[39m ChromiumRemoteConnection(\n\u001b[0;32m     58\u001b[0m     remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[0;32m     59\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mbrowser_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m     ignore_proxy\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39m_ignore_local_proxy,\n\u001b[0;32m     63\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py:109\u001b[0m, in \u001b[0;36mService.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massert_process_still_running()\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_connectable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# sleep increasing: 0.01, 0.06, 0.11, 0.16, 0.21, 0.26, 0.31, 0.36, 0.41, 0.46, 0.5\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py:126\u001b[0m, in \u001b[0;36mService.is_connectable\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_connectable\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Establishes a socket connection to determine if the service running\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m    on the port is accessible.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_connectable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\common\\utils.py:101\u001b[0m, in \u001b[0;36mis_connectable\u001b[1;34m(port, host)\u001b[0m\n\u001b[0;32m     99\u001b[0m socket_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     socket_ \u001b[38;5;241m=\u001b[39m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _is_connectable_exceptions:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\socket.py:843\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m error \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_errors:\n\u001b[1;32m--> 843\u001b[0m         exceptions\u001b[38;5;241m.\u001b[39mclear()  \u001b[38;5;66;03m# raise only the last error\u001b[39;00m\n\u001b[0;32m    844\u001b[0m     exceptions\u001b[38;5;241m.\u001b[39mappend(exc)\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# *** select one province from 'ALL_PROVINCE_ACCOMM_DATA'\n",
    "# *** so, change \"Idx_of_region\" everytime when scrape another province\n",
    "Idx_of_region = 0\n",
    "cur_region_data = ALL_PROVINCE_ACCOMM_DATA[Idx_of_region]\n",
    "\n",
    "# select first and last page to scrape\n",
    "# but in this module will not have any effect (just some dummy number to use with file name)\n",
    "# will have effect on module \"mulProcess_accommodation_scraping_proxy\"\n",
    "first_page = 11\n",
    "last_page = 20\n",
    "\n",
    "cur_province_en = cur_region_data[0]\n",
    "cur_province_th = cur_region_data[1]\n",
    "cur_province_url = cur_region_data[2]\n",
    "\n",
    "# cur_res_allAccommodations_df = create_accommodation_df(Accommodation())\n",
    "\n",
    "# get dataframe result of all accommodation in current province\n",
    "cur_res_allAccommodations_df = scrape_accommodations_by_province(\n",
    "    page = 1,\n",
    "    province_url = cur_province_url,\n",
    "    province = cur_province_th\n",
    ")\n",
    "\n",
    "# don't forget to remove row with lat/long be zero\n",
    "\n",
    "# remove duplicate accommodation\n",
    "cur_res_allAccommodations_df.drop_duplicates(subset=['name'], inplace=True)\n",
    "# set new index\n",
    "cur_res_allAccommodations_df.set_index(['name'], inplace=True)\n",
    "\n",
    "# create directory to store result of scraping accommodation\n",
    "# for example: 'accommodation_scraping\\res_accommodation_scraping\\res_accommodation_Phuket'\n",
    "createDirectory(fh.STORE_ACCOMM_SCRAPING, os.path.join('res_accommodation_scraping', 'res_accommodation_%s' % (cur_province_en)))\n",
    "\n",
    "# save result dataframe to .csv\n",
    "# for example: 'res_accommodation_Phuket_page_1_44.csv'\n",
    "res_file_name = 'res_accommodation_%s_page_%s_%s.csv' % (cur_province_en, first_page, last_page)\n",
    "res_path = os.path.join(fh.STORE_ACCOMM_SCRAPING, 'res_accommodation_scraping', 'res_accommodation_%s' % (cur_province_en), res_file_name)\n",
    "cur_res_allAccommodations_df.to_csv(res_path, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://th.tripadvisor.com/Hotel_Review-g297930-d315568-Reviews-Phuket_Marriott_Resort_Spa_Merlin_Beach-Patong_Kathu_Phuket.html#/media/315568/?albumid=101&type=0&category=101\n",
    "# https://th.tripadvisor.com/Hotel_Review-g1210687-d1379794-Reviews-Chanalai_Romantica_Resort-Kata_Beach_Karon_Phuket.html#/media/1379794/?albumid=101&type=0&category=101\n",
    "# \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
