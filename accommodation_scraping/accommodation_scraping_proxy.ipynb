{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pyautogui\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import constants.constants as const\n",
    "import constants.file_handler_constants as fh\n",
    "from constants.accommodation_constants import *\n",
    "\n",
    "from packages.accommodation.accommodation import *\n",
    "from packages.file_handler_package.file_handler import *\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv, dotenv_values \n",
    "\n",
    "from selenium.webdriver import Remote, ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.actions.wheel_input import ScrollOrigin\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "from selenium.webdriver.edge.options import Options\n",
    "\n",
    "\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_accommodation_df(accommodation: Accommodation) -> pd.DataFrame:\n",
    "    accommodation_dict = {\n",
    "        'name' : [accommodation.get_name()],\n",
    "        'description' : [accommodation.get_description()],\n",
    "        'latitude' : [accommodation.get_latitude()],\n",
    "        'longitude' : [accommodation.get_longitude()],\n",
    "        'imgPath' : [accommodation.get_imgPath()],\n",
    "        'phone': [accommodation.get_phone()],\n",
    "        'website': [accommodation.get_website()],\n",
    "        'star': [accommodation.get_star()],\n",
    "        'facility': [accommodation.get_facility()],\n",
    "        'tag': [accommodation.get_tag()],\n",
    "        'type': [accommodation.get_type()],\n",
    "\n",
    "        # location\n",
    "        'address' : [accommodation.get_location().get_address()],\n",
    "        'province' : [accommodation.get_location().get_province()],\n",
    "        'district' : [accommodation.get_location().get_district()],\n",
    "        'subDistrict' : [accommodation.get_location().get_sub_district()],\n",
    "        'province_code' : [accommodation.get_location().get_province_code()],\n",
    "        'district_code' : [accommodation.get_location().get_district_code()],\n",
    "        'sub_district_code' : [accommodation.get_location().get_sub_district_code()],\n",
    "\n",
    "        # rating\n",
    "        'score' : [accommodation.get_rating().get_score()],\n",
    "        'ratingCount' : [accommodation.get_rating().get_ratingCount()],\n",
    "    }\n",
    "\n",
    "    accommodation_df = pd.DataFrame(accommodation_dict)\n",
    "    \n",
    "    return accommodation_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_url_by_page(link_to_accommodation: str, page: int) -> str:\n",
    "\n",
    "    if(page == 1):\n",
    "        return link_to_accommodation\n",
    "    \n",
    "    first_page_url_split = link_to_accommodation.split('-')\n",
    "    nth_count_page = 'oa%s' % ((page - 1) * 30)\n",
    "    first_page_url_split[-2] = nth_count_page\n",
    "    res_page_url =  \"-\".join(first_page_url_split)\n",
    "\n",
    "    return res_page_url\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_img(accommodation_page_driver: webdriver) -> list[str]:\n",
    "    \n",
    "    res_imgPath = []\n",
    "\n",
    "    # find button and click\n",
    "    # to see image modal\n",
    "    try:\n",
    "        print(\"p2\")\n",
    "        click_img_btn = accommodation_page_driver.find_element(By.CLASS_NAME, 'QXsnf')\n",
    "        print(\"p3\")\n",
    "        click_img_btn.click()\n",
    "        \n",
    "        click_gallery_btn = None\n",
    "        possible_gallery_btn_xpath = '//*[@id=\"lithium-root\"]/main/span/div[4]/div/div[2]/div[3]/div/div[1]/span/div/div[2]/div[2]/div/div[2]/div[2]/div[2]/div[2]/div[2]/button'\n",
    "    \n",
    "        cnt_debug = 0\n",
    "        while(True):\n",
    "            if(cnt_debug == 30):\n",
    "                break\n",
    "            try:\n",
    "               cnt_debug += 1\n",
    "               print(\"m1\")\n",
    "            #    WebDriverWait(accommodation_page_driver, 2).until(EC.visibility_of_element_located((By.XPATH, possible_gallery_btn_xpath)))\n",
    "               print(\"m2\")\n",
    "               click_gallery_btn = accommodation_page_driver.find_element(By.XPATH, possible_gallery_btn_xpath)\n",
    "               break\n",
    "               print(\"m3\")\n",
    "               \n",
    "            except Exception as e:\n",
    "                print(\"retry load galley ...\")\n",
    "\n",
    "        if(not click_gallery_btn):\n",
    "            print(\"s1\")\n",
    "            return res_imgPath\n",
    "        \n",
    "        click_gallery_btn.click()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"can't open modal image\")\n",
    "        return res_imgPath\n",
    "\n",
    "    # scrape image address\n",
    "    try:\n",
    "        is_end_scrape_img = False\n",
    "        cnt_retry = 0\n",
    "        print(\"p7\")\n",
    "        while(not is_end_scrape_img):\n",
    "            if(cnt_retry == 10):\n",
    "                print(\"max retry for scrape image...\")\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                WebDriverWait(accommodation_page_driver, 2).until(EC.visibility_of_element_located((By.CLASS_NAME, 'cfCAA')))\n",
    "                all_img_elements = accommodation_page_driver.find_elements(By.CLASS_NAME, 'cfCAA')\n",
    "                print(\"find image element -> \", len(all_img_elements))\n",
    "                for cur_img_element in all_img_elements:\n",
    "                    cur_bgImg_val = cur_img_element.value_of_css_property('background-image')\n",
    "                    match = re.search(r'url\\(\"(.*?)\"\\)', cur_bgImg_val)\n",
    "                    if match:\n",
    "                        res_imgPath.append(match.group(1))\n",
    "\n",
    "                is_end_scrape_img = True\n",
    "\n",
    "            except Exception as e:\n",
    "                cnt_retry += 1\n",
    "                print(\"retry scrape img...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "            pass\n",
    "    \n",
    "\n",
    "    return res_imgPath.copy()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_location(accommodation_page_driver: webdriver, latitude: float, longitude: float, province_th: str) -> Location:\n",
    "\n",
    "    # find better address description on wongnai\n",
    "    # for example: \"991 ถนนพระราม 1 Pathum Wan, กรุงเทพมหานคร (กทม.) 10330 ไทย\"\n",
    "    address_tripAdvisor = \"\"\n",
    "    possible_address_xpath = [\n",
    "        '//*[@id=\"lithium-root\"]/main/span/div[4]/div/div[1]/div[3]/div/div[3]/div[1]/div[2]/span[2]/span',\n",
    "    ]\n",
    "\n",
    "\n",
    "    for cur_address_xpath in possible_address_xpath:\n",
    "        try:\n",
    "            WebDriverWait(accommodation_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, cur_address_xpath)))\n",
    "            address_element = accommodation_page_driver.find_element(By.XPATH, cur_address_xpath)\n",
    "            address_tripAdvisor = address_element.text\n",
    "            \n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "\n",
    "    # start scrape location\n",
    "    res_location = Location()\n",
    "    cnt_retry = 0\n",
    "    try:\n",
    "        while(True):\n",
    "            if(cnt_retry == 10):\n",
    "                print(\"max retry for scrape Google Map ...\")\n",
    "                break\n",
    "            \n",
    "            # set up new webdriver to work googlemap url(query for specific lat/long)\n",
    "            possible_addressGoogleMap_elements = []\n",
    "            try:\n",
    "                # set Chrome options to run in headless mode\n",
    "                # options = Options()\n",
    "                options = webdriver.ChromeOptions()\n",
    "                options.add_argument(\"start-maximized\")\n",
    "                # options.add_argument(\"--headless=new\")\n",
    "                options.add_experimental_option(\n",
    "                    \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    "                )\n",
    "\n",
    "                google_map_driver = webdriver.Chrome(options=options)\n",
    "                \n",
    "                google_map_query = \"https://www.google.com/maps/search/?api=1&query=%s,%s\" % (latitude, longitude)\n",
    "                google_map_driver.get(google_map_query)\n",
    "                print(\"scrape location data for, \", google_map_query)\n",
    "                \n",
    "                WebDriverWait(google_map_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'DkEaL')))\n",
    "                possible_addressGoogleMap_elements = google_map_driver.find_elements(By.CLASS_NAME, 'DkEaL')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"retry  scrape Google Map..\")\n",
    "                cnt_retry += 1\n",
    "                google_map_driver.close()\n",
    "                continue\n",
    "\n",
    "\n",
    "            # after init new webdriver -> continure scrape location data\n",
    "\n",
    "            # if found some wiered place that doesn't even have its address\n",
    "            # skip this case for now...\n",
    "            if(not len(possible_addressGoogleMap_elements)):\n",
    "                return res_location\n",
    "\n",
    "            subStrDistrict = \"อำเภอ\"\n",
    "            subStrSubDistrict = \"ตำบล\"\n",
    "\n",
    "            if province_th == \"กรุงเทพมหานคร\":\n",
    "                subStrDistrict = \"เขต\"\n",
    "                subStrSubDistrict = \"แขวง\"\n",
    "\n",
    "            district = 0\n",
    "            subDirstrict = 0\n",
    "\n",
    "            # find location\n",
    "            useData = None\n",
    "            for cur_element in possible_addressGoogleMap_elements:\n",
    "                if province_th in cur_element.text and cur_element.text.find(subStrDistrict) != -1:\n",
    "                    useData = cur_element.text.replace(\",\",\"\").replace(\"เเ\",\"แ\")\n",
    "                    break\n",
    "           \n",
    "            if(useData != None):\n",
    "                # print(\"Full Address :\",useData)\n",
    "                # another brute force way in case of province 'กรุงเทพหมานคร' not have word 'แขวง' in address\n",
    "                if(province_th == 'กรุงเทพมหานคร' and useData.find(subStrSubDistrict) == -1):\n",
    "                    subAddress_split = useData.split(' ')\n",
    "                    cur_province_Idx = subAddress_split.index(province_th)\n",
    "                    district = subAddress_split[cur_province_Idx - 1].replace(\"เขต\",\"\")\n",
    "\n",
    "                else:\n",
    "                    start_address_index = useData.find(subStrDistrict)\n",
    "                    subAddress = useData[start_address_index:]\n",
    "                    district = subAddress[subAddress.find(subStrDistrict)+len(subStrDistrict):subAddress.find(province_th)].replace(\" \",\"\")               \n",
    "\n",
    "                if district == \"เมือง\":\n",
    "                    district = district+province_th\n",
    "\n",
    "                # filter row to find 'ISO_3166_code', 'zip_code', 'geo_code'\n",
    "                geo_code_df = pd.read_csv(fh.PATH_TO_GEOCODE)\n",
    "                filtered_rows = geo_code_df[\n",
    "                    (geo_code_df['province_th'] == province_th) & (geo_code_df['district_th'] == district)\n",
    "                ]\n",
    "                filtered_rows.reset_index(inplace=True, drop=True)\n",
    "                \n",
    "                if not filtered_rows.empty:\n",
    "                    print(\"found province :\",filtered_rows.loc[0, 'ISO_3166_code'], province_th)\n",
    "                    print(\"found District :\",filtered_rows.loc[0, 'zip_code'], district)\n",
    "\n",
    "                    res_location.set_address(address_tripAdvisor if len(address_tripAdvisor) else useData)\n",
    "                    res_location.set_province(province_th)\n",
    "                    res_location.set_district(district)\n",
    "                    res_location.set_sub_district(\"\")\n",
    "                    res_location.set_province_code(filtered_rows.loc[0, 'ISO_3166_code'])\n",
    "                    res_location.set_district_code(filtered_rows.loc[0, 'zip_code'])\n",
    "                    res_location.set_sub_district_code(0)\n",
    "\n",
    "                else:\n",
    "                    print(\"not found province :\", province_th)\n",
    "                    print(\"not found District :\", district)\n",
    "\n",
    "                    res_location.set_address(address_tripAdvisor if len(address_tripAdvisor) else useData)\n",
    "                    res_location.set_province(province_th)\n",
    "                    res_location.set_district(district)\n",
    "                    res_location.set_sub_district(\"\")\n",
    "                    res_location.set_province_code(0)\n",
    "                    res_location.set_district_code(0)\n",
    "                    res_location.set_sub_district_code(0)\n",
    "\n",
    "            google_map_driver.close()\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"can't scrape location data\")\n",
    "\n",
    "    return res_location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape lat/long, and openingHours (there are in another page of current accommodation)\n",
    "def scrape_location_latlong_openingHours(accommodation_page_driver: webdriver, link_to_adjust_page: str) -> tuple[float, float]:\n",
    "    lat = 0\n",
    "    long = 0\n",
    "\n",
    "    # create new webdriver to continue scrape lat/long, openingHours in adjust accommodation page\n",
    "    cnt_retry = 0\n",
    "    \n",
    "    while(True):\n",
    "        # if(cnt_retry == 10):\n",
    "        #     print(\"max retry for scrape single accommodation ...\")\n",
    "        #     break\n",
    "\n",
    "        # formulate the proxy url with authentication\n",
    "        proxy_url = f\"http://{os.environ['proxy_username']}:{os.environ['proxy_password']}@{os.environ['proxy_address']}:{os.environ['proxy_port']}\"\n",
    "        \n",
    "        # set selenium-wire options to use the proxy\n",
    "        seleniumwire_options = {\n",
    "            \"proxy\": {\n",
    "                \"http\": proxy_url,\n",
    "                \"https\": proxy_url\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # set Chrome options to run in headless mode\n",
    "        options = Options()\n",
    "        options.add_argument(\"start-maximized\")\n",
    "        options.add_argument(\"--lang=th-TH\")\n",
    "        # options.add_argument(\"--headless=new\")\n",
    "        options.add_experimental_option(\n",
    "            \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    "        )\n",
    "\n",
    "        # initialize the Chrome driver with service, selenium-wire options, and chrome options\n",
    "        adjust_page_driver = webdriver.Edge(\n",
    "            service=Service(EdgeChromiumDriverManager().install()),\n",
    "            seleniumwire_options=seleniumwire_options,\n",
    "            options=options\n",
    "        )\n",
    "        \n",
    "        # retry in case of web restrictions, some elements not loaded\n",
    "        try:\n",
    "            print(\"scrape data in adjust accommodation page...\")\n",
    "            print(\"for link : \", link_to_adjust_page)\n",
    "            adjust_page_driver.get(link_to_adjust_page)\n",
    "\n",
    "            print(\"debug option of adjust page: \")\n",
    "            WebDriverWait(adjust_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'DiHOR')))\n",
    "\n",
    "            # find dropdown --> click display data below --> cick display lat/long input form\n",
    "            possible_target_btn = adjust_page_driver.find_elements(By.CLASS_NAME, 'DiHOR')\n",
    "            for cur_dropdown_btn in possible_target_btn:\n",
    "                cur_dropdown_text = cur_dropdown_btn.text\n",
    "                if(\"แนะนำการแก้ไขข้อมูลของสถานที่นี้\" in cur_dropdown_text):\n",
    "                    print(\"found target dropdown btn ...\")\n",
    "                    cur_dropdown_btn.click()\n",
    "                    WebDriverWait(adjust_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"lithium-root\"]/main/div[2]/div[3]/div[1]/div/div[2]/div[2]/div/div/div[2]/button')))\n",
    "                    # find button click to display lat/long input form\n",
    "                    display_lat_long_btn = adjust_page_driver.find_element(By.XPATH, '//*[@id=\"lithium-root\"]/main/div[2]/div[3]/div[1]/div/div[2]/div[2]/div/div/div[2]/button')\n",
    "                    display_lat_long_btn.click()\n",
    "\n",
    "        except Exception as e:\n",
    "            cnt_retry += 1\n",
    "            adjust_page_driver.quit()\n",
    "            print(\"retry adjust page...\")\n",
    "            continue\n",
    "\n",
    "      \n",
    "        # find lat/long\n",
    "        try:\n",
    "            WebDriverWait(adjust_page_driver, 2).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"lithium-root\"]/main/div[2]/div[3]/div[1]/div/div[2]/div[2]/div/div/div[2]/div/div/div[3]/div[1]/div/div[2]/div/div/div/span')))\n",
    "            WebDriverWait(adjust_page_driver, 2).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"lithium-root\"]/main/div[2]/div[3]/div[1]/div/div[2]/div[2]/div/div/div[2]/div/div/div[3]/div[2]/div/div[2]/div/div/div/span')))\n",
    "    \n",
    "            lat_input_container = adjust_page_driver.find_element(By.XPATH, '//*[@id=\"lithium-root\"]/main/div[2]/div[3]/div[1]/div/div[2]/div[2]/div/div/div[2]/div/div/div[3]/div[1]/div/div[2]/div/div/div/span')\n",
    "            lat_input_element = lat_input_container.find_element(By.TAG_NAME, 'input')\n",
    "            lat = float(lat_input_element.get_attribute('value'))\n",
    "\n",
    "            long_input_container = adjust_page_driver.find_element(By.XPATH, '//*[@id=\"lithium-root\"]/main/div[2]/div[3]/div[1]/div/div[2]/div[2]/div/div/div[2]/div/div/div[3]/div[2]/div/div[2]/div/div/div/span')\n",
    "            long_input_element = long_input_container.find_element(By.TAG_NAME, 'input')\n",
    "            long = float(long_input_element.get_attribute('value'))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"can't find lat/long\")\n",
    "        \n",
    "        print(\"lat : \", lat)\n",
    "        print(\"long : \", long)\n",
    "\n",
    "        # **if can't find lat/long --> don't scrape this attaction\n",
    "        if(lat == 0 and long == 0):\n",
    "            print(\"in scrape_location_latlong_openingHours --> can't find lat/long --> 0, 0\")\n",
    "            return lat, long\n",
    "\n",
    "        adjust_page_driver.quit()\n",
    "        break\n",
    "\n",
    "    return lat, long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_single_accommodation(link_to_accommodation: str, province_th: str) -> Accommodation:\n",
    "    \n",
    "    accommodation = Accommodation()\n",
    "    cnt_retry = 0\n",
    "    \n",
    "    while(True):\n",
    "        # if(cnt_retry == 10):\n",
    "        #     print(\"max retry for scrape single accommodation ...\")\n",
    "        #     break\n",
    "\n",
    "        # formulate the proxy url with authentication\n",
    "        proxy_url = f\"http://{os.environ['proxy_username']}:{os.environ['proxy_password']}@{os.environ['proxy_address']}:{os.environ['proxy_port']}\"\n",
    "        \n",
    "        # set selenium-wire options to use the proxy\n",
    "        seleniumwire_options = {\n",
    "            \"proxy\": {\n",
    "                \"http\": proxy_url,\n",
    "                \"https\": proxy_url\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # set Chrome options to run in headless mode\n",
    "        options = Options()\n",
    "        options.add_argument(\"start-maximized\")\n",
    "        options.add_argument(\"--lang=th-TH\")\n",
    "        # options.add_argument(\"--headless=new\")\n",
    "        options.add_experimental_option(\n",
    "            \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    "        )\n",
    "\n",
    "        # initialize the Chrome driver with service, selenium-wire options, and chrome options\n",
    "        accommodation_page_driver = webdriver.Edge(\n",
    "            service=Service(EdgeChromiumDriverManager().install()),\n",
    "            seleniumwire_options=seleniumwire_options,\n",
    "            options=options\n",
    "        )\n",
    "        \n",
    "        # retry in case of web restrictions and some elements not loaded\n",
    "        try:\n",
    "            print(\"******************************************************\")\n",
    "            print(\"scrape single accommodation...\")\n",
    "            print(\"for accommodation : \", link_to_accommodation)\n",
    "            accommodation_page_driver.get(link_to_accommodation)\n",
    "\n",
    "            print(\"debug scrape_single_accommodation: top info component section\")\n",
    "            WebDriverWait(accommodation_page_driver, 2).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"lithium-root\"]/main/span/div[4]/div/div[1]/div[3]/div')))\n",
    "            top_info_container = accommodation_page_driver.find_element(By.XPATH, '//*[@id=\"lithium-root\"]/main/span/div[4]/div/div[1]/div[3]/div')\n",
    "\n",
    "            print(\"debug scrape_single_accommodation: bottom info component section\")\n",
    "            WebDriverWait(accommodation_page_driver, 2).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"ABOUT_TAB\"]')))\n",
    "            bottom_info_container = accommodation_page_driver.find_element(By.XPATH, '//*[@id=\"ABOUT_TAB\"]')\n",
    "\n",
    "            print(\"debug scrape_single_attraction: common component section\")\n",
    "            WebDriverWait(accommodation_page_driver, 2).until(EC.visibility_of_element_located((By.CLASS_NAME, 'IDaDx')))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"retry single accommodation case 1...\")\n",
    "            cnt_retry += 1\n",
    "            accommodation_page_driver.quit()\n",
    "            continue\n",
    "        \n",
    "        # convert accommodation url to adjust page url\n",
    "        # for example: from 'https://th.tripadvisor.com/Hotel_Review-g10804710-d586602-Reviews-Pacific_Club_Resort-Karon_Beach_Karon_Phuket.html' to 'https://th.tripadvisor.com/ImproveListing-d586602.html'\n",
    "        link_to_adjust_page = 'https://th.tripadvisor.com/ImproveListing-%s.html' % (link_to_accommodation.split('-')[2])\n",
    "\n",
    "        # ** find lat/long, location data and openingHours (there are in another page of current accommodation)\n",
    "        # ** if this accommodation not have lat/long\n",
    "        # ** don't continue to scrape\n",
    "        lat, long = scrape_location_latlong_openingHours(\n",
    "            accommodation_page_driver = accommodation_page_driver,\n",
    "            link_to_adjust_page = link_to_adjust_page\n",
    "        )\n",
    "        \n",
    "        # **if can't find lat/long --> don't scrape this attaction\n",
    "        if(lat == 0 and long == 0):\n",
    "            print(\"in scrape_single_accommodation --> can't find lat/long --> don't scrape this accommodation ...\")\n",
    "            accommodation_page_driver.quit()\n",
    "            return accommodation\n",
    "\n",
    "        # find name\n",
    "        name = \"\"\n",
    "        try:\n",
    "            WebDriverWait(accommodation_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'rRtyp')))\n",
    "            name_element = accommodation_page_driver.find_element(By.CLASS_NAME, 'rRtyp')\n",
    "            name = name_element.text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"can't find name\")\n",
    "\n",
    "        print(\"name -> \", name)\n",
    "\n",
    "        # find description\n",
    "        # description = \"\"\n",
    "        # try:\n",
    "        #     WebDriverWait(accommodation_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"AR_ABOUT\"]/div[1]')))\n",
    "            \n",
    "        #     description_container = accommodation_page_driver.find_element(By.XPATH, '//*[@id=\"AR_ABOUT\"]/div[1]')\n",
    "        #     header_element = description_container.find_element(By.CLASS_NAME, 'biGQs')\n",
    "        #     header_text = header_element.text\n",
    "        #     if(header_text == 'ข้อมูล'):\n",
    "        #         description_element = accommodation_page_driver.find_element(By.CLASS_NAME, 'JguWG')\n",
    "        #         description = description_element.text\n",
    "                \n",
    "\n",
    "        # except Exception as e:\n",
    "        #     print(\"can't find description\")\n",
    "\n",
    "        # print(\"description -> \", description)\n",
    "        \n",
    "        # find\n",
    "        phone = \"\"\n",
    "        try:\n",
    "            WebDriverWait(accommodation_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"lithium-root\"]/main/span/div[4]/div/div[1]/div[3]/div/div[3]/div[1]/div[3]/div[2]/div/a')))\n",
    "            phone_element = accommodation_page_driver.find_element(By.XPATH, '//*[@id=\"lithium-root\"]/main/span/div[4]/div/div[1]/div[3]/div/div[3]/div[1]/div[3]/div[2]/div/a')\n",
    "            phone_element_href = phone_element.get_attribute('href')\n",
    "            if(\"tel\" in phone_element_href):\n",
    "                phone = phone_element.text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"can't find phone\")\n",
    "\n",
    "        print(\"phone --> \", phone)\n",
    "\n",
    "        # find rating\n",
    "        rating = 0\n",
    "        rating_count = 0\n",
    "        try:\n",
    "            WebDriverWait(accommodation_page_driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'dGsKv')))\n",
    "            rating_container = accommodation_page_driver.find_element(By.CLASS_NAME, 'dGsKv')\n",
    "            \n",
    "            rating_element = rating_container.find_element(By.CLASS_NAME, 'kJyXc')\n",
    "            rating = float(rating_element.text)\n",
    "\n",
    "            rating_count_element = rating_container.find_element(By.CLASS_NAME, 'KxBGd')\n",
    "            rating_count = int(rating_count_element.text.replace(',', '').replace('รีวิว ', '').replace(' รายการ', ''))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"can't find rating and rating_count\")\n",
    "\n",
    "        print(\"rating --> \", rating)\n",
    "        print(\"rating_count --> \", rating_count)\n",
    "\n",
    "        # find facilities, tags\n",
    "        facilities = []\n",
    "        tags = []\n",
    "        try:\n",
    "            possible_target_containers = bottom_info_container.find_elements(By.CLASS_NAME, 'Jevoh')\n",
    "            all_topic_elements = bottom_info_container.find_elements(By.CLASS_NAME, 'vqEpQ')\n",
    "\n",
    "            for i in range(len(possible_target_containers)):\n",
    "                cur_topic = all_topic_elements[i].text\n",
    "                print(\"cur_topic --> \", cur_topic)\n",
    "                if(cur_topic == \"สิ่งอำนวยความสะดวกของสถานที่ให้บริการ\" or cur_topic == \"สิ่งอำนวยความสะดวกในห้องพัก\"):\n",
    "                    all_facility_elements = possible_target_containers[i].find_elements(By.CLASS_NAME, 'gFttI')\n",
    "                    for cur_facility_element in all_facility_elements:\n",
    "                        cur_facility_text = cur_facility_element.text\n",
    "                        if(not len(cur_facility_text)):\n",
    "                            continue\n",
    "                        facilities.append(cur_facility_text)\n",
    "\n",
    "                elif(cur_topic ==  \"ประเภทห้องพัก\"):\n",
    "                    all_tag_elements = possible_target_containers[i].find_elements(By.CLASS_NAME, 'gFttI')\n",
    "                    for cur_tag_element in all_tag_elements:\n",
    "                        cur_tag_text = cur_tag_element.text\n",
    "                        if(not len(cur_tag_text )):\n",
    "                            continue                        \n",
    "                        tags.append(cur_tag_text)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"can't find facilities or tags\")\n",
    "\n",
    "        print(\"facilities --> \", facilities)\n",
    "        print(\"tags --> \", tags)\n",
    "\n",
    "        # find star\n",
    "        star = 0\n",
    "        try:\n",
    "            WebDriverWait(accommodation_page_driver, 1).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\":lithium-Riqkhaianknvlq:\"]')))\n",
    "            star_element = accommodation_page_driver.find_element(By.XPATH, '//*[@id=\":lithium-Riqkhaianknvlq:\"]')\n",
    "            star = star_element.text.split(' ')[0]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"can't find star\")\n",
    "\n",
    "        print(\"star --> \", star)\n",
    "\n",
    "        # find img_path\n",
    "        img_path = scrape_img(accommodation_page_driver)\n",
    "        print(\"cur img path -> \", img_path)\n",
    "\n",
    "        # find location\n",
    "        location = scrape_location(\n",
    "            accommodation_page_driver = accommodation_page_driver,\n",
    "            latitude = lat,\n",
    "            longitude = long,\n",
    "            province_th = province_th\n",
    "        )\n",
    "        print(\"province :\", location.get_province_code(), location.get_province())\n",
    "        print(\"District :\", location.get_district_code(), location.get_district())\n",
    "        print(\"Address : \", location.get_address())\n",
    "\n",
    "        # set some of \"accommodation\" object properties\n",
    "        accommodation.set_name(name)\n",
    "        # accommodation.set_description(description)\n",
    "        accommodation.set_phone(phone)\n",
    "        accommodation.set_latitude(lat)\n",
    "        accommodation.set_longitude(long)\n",
    "        accommodation.set_imgPath(img_path)\n",
    "        accommodation.set_website(link_to_accommodation)\n",
    "        accommodation.set_facility(facilities)\n",
    "        accommodation.set_tag(tags)\n",
    "        accommodation.set_star(star)\n",
    "        accommodation.set_location(\n",
    "            address = location.get_address(),\n",
    "            province = location.get_province(),\n",
    "            district = location.get_district(),\n",
    "            sub_district = location.get_sub_district(),\n",
    "            province_code = location.get_province_code(),\n",
    "            district_code = location.get_district_code(),\n",
    "            sub_district_code = location.get_sub_district_code()\n",
    "        )\n",
    "        accommodation.set_rating(\n",
    "            score = rating,\n",
    "            rating_count = rating_count\n",
    "        )\n",
    "\n",
    "\n",
    "        accommodation_page_driver.quit()\n",
    "        break\n",
    "\n",
    "    return accommodation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_url_by_page(query_url: str, page: int) -> list[str]:\n",
    "\n",
    "    res_url_by_page = []\n",
    "\n",
    "    cnt_retry = 0\n",
    "    \n",
    "    while(True):\n",
    "        \n",
    "        if(cnt_retry == 10):\n",
    "            print(\"max retry for scrape data by page ...\")\n",
    "            break\n",
    "\n",
    "        # formulate the proxy url with authentication\n",
    "        # os.environ['proxy_port']\n",
    "        proxy_url = f\"http://{os.environ['proxy_username']}:{os.environ['proxy_password']}@{os.environ['proxy_address']}:{os.environ['proxy_port']}\"\n",
    "        \n",
    "        # set selenium-wire options to use the proxy\n",
    "        seleniumwire_options = {\n",
    "            \"proxy\": {\n",
    "                \"http\": proxy_url,\n",
    "                \"https\": proxy_url\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # set Chrome options to run in headless mode\n",
    "        options = Options()\n",
    "        options.add_argument(\"start-maximized\")\n",
    "        options.add_argument(\"--lang=th-TH\")\n",
    "        # options.add_argument(\"--headless=new\")\n",
    "        options.add_experimental_option(\n",
    "            \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    "        )\n",
    "      \n",
    "        # initialize the Chrome driver with service, selenium-wire options, and chrome options\n",
    "        driver = webdriver.Edge(\n",
    "            service=Service(EdgeChromiumDriverManager().install()),\n",
    "            seleniumwire_options=seleniumwire_options,\n",
    "            options=options\n",
    "        )\n",
    "        \n",
    "        # just check for ip\n",
    "        # print(\"just check for ip :\")\n",
    "        # driver.get(\"https://httpbin.io/ip\")\n",
    "        # print(driver.page_source)\n",
    "\n",
    "        # find group of accommodation on the nth page\n",
    "        all_accommodations_card = []\n",
    "\n",
    "        # retry in case of web restrictions and some elements not loaded\n",
    "        try:\n",
    "            query_url_by_page = convert_url_by_page(\n",
    "                link_to_accommodation = query_url,\n",
    "                page = page\n",
    "            )\n",
    "            driver.get(query_url_by_page)\n",
    "            # scroll and wait for some msec\n",
    "            driver.execute_script('window.scrollBy(0, document.body.scrollHeight)')\n",
    "            \n",
    "            print(\"check current page url --> \", driver.current_url)\n",
    "\n",
    "            # wait for div (each accommodation section) to be present and visible\n",
    "            print(\"b1 part 1\")\n",
    "            print(\"debug get_all_url_by_page: accommodation by one page section\")\n",
    "            WebDriverWait(driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'jhsNf')))\n",
    "            all_accommodations_card = driver.find_elements(By.CLASS_NAME, 'jhsNf')\n",
    "\n",
    "            # if current page is 1, find button \"ดูทั้งหมด\"(if it exist) --> click to load more accommodation card elements\n",
    "            # assume that page 1 of target province (phuket for now) not less than 10\n",
    "            # if(page == 1 and len(all_accommodations_card) <= 10):\n",
    "            #     print(\"b 0.5\")\n",
    "            #     print(\"debug get_all_url_by_page: get click more btn for page 1\")\n",
    "            #     WebDriverWait(driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'sOtnj')))\n",
    "            #     click_more_btn = driver.find_element(By.CLASS_NAME, 'sOtnj')\n",
    "            #     click_more_btn.click()\n",
    "\n",
    "            #     # wait for div (each accommodation section) to be present and visible\n",
    "            #     print(\"b1 part 2\")\n",
    "            #     print(\"debug get_all_url_by_page: accommodation by one page section\")\n",
    "            #     WebDriverWait(driver, 1).until(EC.visibility_of_element_located((By.CLASS_NAME, 'jhsNf')))\n",
    "            #     all_accommodations_card = driver.find_elements(By.CLASS_NAME, 'jhsNf')\n",
    "\n",
    "            # check if all accomodation card can get tag a and its attribute for url\n",
    "            print(\"b2\")\n",
    "            print(\"check in loop ...\")\n",
    "            for cur_accommodation_card in all_accommodations_card:\n",
    "\n",
    "                cur_accommodation_url = cur_accommodation_card.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                print(\"cur_accommodation_url : \", cur_accommodation_url)\n",
    "                res_url_by_page.append(cur_accommodation_url)\n",
    "            \n",
    "            driver.quit()\n",
    "            break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"retry find get_all_url_by_page ...\")\n",
    "            cnt_retry += 1\n",
    "            driver.quit()\n",
    "            continue\n",
    "\n",
    "    return res_url_by_page.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_accommodation_by_province(province_url: str, province: str, page: int) -> pd.DataFrame:\n",
    "    # res_accommodation_df = pd.DataFrame()\n",
    "    res_accommodation_df = create_accommodation_df(Accommodation())\n",
    "    \n",
    "    cnt_for_debug = 0\n",
    "        \n",
    "    print(\"scraping accommodation | province --> %s | page --> %s\" % (province, page))\n",
    "\n",
    "    all_url_by_page = get_all_url_by_page(query_url = province_url, page = page)\n",
    "\n",
    "    # use data from 'res_get_data_by_page' to retrive data of specific accommodation\n",
    "    for cur_accommodation_url in all_url_by_page:\n",
    "        if(cnt_for_debug == 4):\n",
    "            break\n",
    "        # continue scraping data for a specific resgtaurant\n",
    "        cur_accommodation = scrape_single_accommodation(\n",
    "            link_to_accommodation = cur_accommodation_url,\n",
    "            province_th = province\n",
    "        )\n",
    "\n",
    "        cnt_for_debug += 1\n",
    "\n",
    "        # create data frame represent data scrape from current accommodation card\n",
    "        cur_accommodation_df = create_accommodation_df(accommodation=cur_accommodation)\n",
    "\n",
    "        # concat all data frame result\n",
    "        res_accommodation_df = pd.concat([res_accommodation_df, cur_accommodation_df])\n",
    "    \n",
    "    return res_accommodation_df.iloc[1:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory res_accommodation_scraping created successfully\n",
      "scraping accommodation | province --> ภูเก็ต | page --> 1\n",
      "check current page url -->  https://th.tripadvisor.com/Hotels-g293920-Phuket-Hotels.html\n",
      "b1 part 1\n",
      "debug get_all_url_by_page: accommodation by one page section\n",
      "b2\n",
      "check in loop ...\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g7847985-d1739625-Reviews-The_Shore_at_Katathani-Kata_Noi_Beach_Karon_Phuket.html?spAttributionToken=MjcwMTcwNTU\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g297930-d315568-Reviews-Phuket_Marriott_Resort_Spa_Merlin_Beach-Patong_Kathu_Phuket.html\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g297930-d12725009-Reviews-The_Marina_Phuket_Hotel-Patong_Kathu_Phuket.html\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g1210687-d1379794-Reviews-Chanalai_Romantica_Resort-Kata_Beach_Karon_Phuket.html\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g297930-d13140255-Reviews-Hotel_Clover_Patong_Phuket-Patong_Kathu_Phuket.html\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g1210687-d308958-Reviews-Chanalai_Garden_Resort-Kata_Beach_Karon_Phuket.html\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g10804710-d535970-Reviews-Beyond_Karon-Karon_Beach_Karon_Phuket.html?spAttributionToken=Mjc4MDU4MTU\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g1223683-d519702-Reviews-JW_Marriott_Phuket_Resort_Spa-Mai_Khao_Thalang_District_Phuket.html\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g1379324-d305747-Reviews-Thavorn_Beach_Village_Resort_Spa-Kamala_Kathu_Phuket.html\n",
      "cur_accommodation_url :  https://th.tripadvisor.com/Hotel_Review-g297930-d557954-Reviews-Baan_Laimai_Beach_Resort_Spa-Patong_Kathu_Phuket.html\n",
      "******************************************************\n",
      "scrape single accommodation...\n",
      "for accommodation :  https://th.tripadvisor.com/Hotel_Review-g7847985-d1739625-Reviews-The_Shore_at_Katathani-Kata_Noi_Beach_Karon_Phuket.html?spAttributionToken=MjcwMTcwNTU\n",
      "debug scrape_single_accommodation: top info component section\n",
      "debug scrape_single_accommodation: bottom info component section\n",
      "debug scrape_single_attraction: common component section\n",
      "scrape data in adjust accommodation page...\n",
      "for link :  https://th.tripadvisor.com/ImproveListing-d1739625.html\n",
      "debug option of adjust page: \n",
      "found target dropdown btn ...\n",
      "lat :  7.803555\n",
      "long :  98.3\n",
      "name ->  เดอะ ชอร์ แอท กะตะธานี\n",
      "The Shore at Katathani\n",
      "phone -->  +66 76 318 350\n",
      "rating -->  4.5\n",
      "rating_count -->  2025\n",
      "cur_topic -->  สิ่งอำนวยความสะดวกของสถานที่ให้บริการ\n",
      "cur_topic -->  สิ่งอำนวยความสะดวกในห้องพัก\n",
      "cur_topic -->  ประเภทห้องพัก\n",
      "facilities -->  ['ที่จอดรถฟรี', 'อินเตอร์เน็ตความเร็วสูง (WiFi) ฟรี', 'ฟิตเนสเซนเตอร์พร้อมห้องออกกำลังกาย', 'สระว่ายน้ำ', 'อาหารเช้าฟรี', 'ชายหาด', 'บริการรถรับ-ส่งสนามบิน', 'สปา', 'ม่านกันแสง', 'ห้องพักแบบเก็บเสียง', 'เครื่องปรับอากาศ', 'ระเบียงส่วนตัว', 'บริการรูมเซอร์วิส', 'มินิบาร์', 'ทีวีจอแบน', 'โถชำระล้าง']\n",
      "tags -->  ['วิวมหาสมุทร', 'วิวสระว่ายน้ำ', 'ห้องสวีทสำหรับคู่แต่งงาน', 'ห้องพักปลอดบุหรี่', 'ห้องสวีท']\n",
      "star -->  5.0\n",
      "p2\n",
      "p3\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "s1\n",
      "cur img path ->  []\n",
      "scrape location data for,  https://www.google.com/maps/search/?api=1&query=7.803555,98.3\n",
      "found province : 83 ภูเก็ต\n",
      "found District : 8301 เมืองภูเก็ต\n",
      "province : 83 ภูเก็ต\n",
      "District : 8301 เมืองภูเก็ต\n",
      "Address :  18 Kata Noi Rd, Kata Noi Beach, กะรน, จังหวัดภูเก็ต 83100 ไทย\n",
      "******************************************************\n",
      "scrape single accommodation...\n",
      "for accommodation :  https://th.tripadvisor.com/Hotel_Review-g297930-d315568-Reviews-Phuket_Marriott_Resort_Spa_Merlin_Beach-Patong_Kathu_Phuket.html\n",
      "debug scrape_single_accommodation: top info component section\n",
      "debug scrape_single_accommodation: bottom info component section\n",
      "debug scrape_single_attraction: common component section\n",
      "scrape data in adjust accommodation page...\n",
      "for link :  https://th.tripadvisor.com/ImproveListing-d315568.html\n",
      "debug option of adjust page: \n",
      "found target dropdown btn ...\n",
      "lat :  7.884707\n",
      "long :  98.272835\n",
      "name ->  ภูเก็ต แมริออท รีสอร์ท แอนด์ สปา, เมอร์ลิน บีช\n",
      "Phuket Marriott Resort & Spa, Merlin Beach\n",
      "phone -->  00 66 76 335 300\n",
      "rating -->  4.5\n",
      "rating_count -->  5832\n",
      "cur_topic -->  สิ่งอำนวยความสะดวกของสถานที่ให้บริการ\n",
      "cur_topic -->  สิ่งอำนวยความสะดวกในห้องพัก\n",
      "cur_topic -->  ประเภทห้องพัก\n",
      "facilities -->  ['ที่จอดรถฟรี', 'อินเตอร์เน็ตความเร็วสูง (WiFi) ฟรี', 'ฟิตเนสเซนเตอร์พร้อมห้องออกกำลังกาย', 'สระว่ายน้ำ', 'บาร์ / เลานจ์', 'ชายหาด', 'การดำน้ำ', 'เด็กเข้าพักฟรี', 'ห้องพักปลอดสารก่อภูมิแพ้', 'ม่านกันแสง', 'เครื่องปรับอากาศ', 'ชายหาดส่วนตัว', 'ห้องน้ำเพิ่มเติม', 'เครื่องชงกาแฟ / ชา', 'เคเบิลทีวี / ทีวีดาวเทียม', 'โถชำระล้าง']\n",
      "tags -->  ['วิวมหาสมุทร', 'วิวสระว่ายน้ำ', 'ห้องพักปลอดบุหรี่', 'ห้องสวีท', 'ห้องสำหรับครอบครัว']\n",
      "star -->  5.0\n",
      "p2\n",
      "p3\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "s1\n",
      "cur img path ->  []\n",
      "scrape location data for,  https://www.google.com/maps/search/?api=1&query=7.884707,98.272835\n",
      "found province : 83 ภูเก็ต\n",
      "found District : 8302 กะทู้\n",
      "province : 83 ภูเก็ต\n",
      "District : 8302 กะทู้\n",
      "Address :  99 ถนนหมื่นเงิน หาดไตรตรัง, ป่าตอง, กะทู้, จังหวัดภูเก็ต 83150 ไทย\n",
      "******************************************************\n",
      "scrape single accommodation...\n",
      "for accommodation :  https://th.tripadvisor.com/Hotel_Review-g297930-d12725009-Reviews-The_Marina_Phuket_Hotel-Patong_Kathu_Phuket.html\n",
      "debug scrape_single_accommodation: top info component section\n",
      "debug scrape_single_accommodation: bottom info component section\n",
      "debug scrape_single_attraction: common component section\n",
      "scrape data in adjust accommodation page...\n",
      "for link :  https://th.tripadvisor.com/ImproveListing-d12725009.html\n",
      "debug option of adjust page: \n",
      "found target dropdown btn ...\n",
      "lat :  7.899594\n",
      "long :  98.30387\n",
      "name ->  เดอะ มารีน่า ภูเก็ต\n",
      "The Marina Phuket Hotel\n",
      "can't find phone\n",
      "phone -->  \n",
      "rating -->  5.0\n",
      "rating_count -->  4199\n",
      "cur_topic -->  สิ่งอำนวยความสะดวกของสถานที่ให้บริการ\n",
      "cur_topic -->  สิ่งอำนวยความสะดวกในห้องพัก\n",
      "cur_topic -->  ประเภทห้องพัก\n",
      "facilities -->  ['ที่จอดรถฟรี', 'อินเตอร์เน็ตความเร็วสูง (WiFi) ฟรี', 'ฟิตเนสเซนเตอร์พร้อมห้องออกกำลังกาย', 'สระว่ายน้ำ', 'อาหารเช้าฟรี', 'เด็กเข้าพักฟรี', 'สระว่ายน้ำสำหรับเด็ก', 'บริการรถรับ-ส่งสนามบิน', 'ม่านกันแสง', 'ห้องพักแบบเก็บเสียง', 'เครื่องปรับอากาศ', 'โต๊ะทำงาน', 'บริการทำความสะอาด', 'เครื่องชงกาแฟ / ชา', 'เคเบิลทีวี / ทีวีดาวเทียม', 'อ่างอาบน้ำ / ฝักบัวอาบน้ำ']\n",
      "tags -->  ['วิวภูเขา', 'ห้องพักปลอดบุหรี่', 'ห้องสวีท', 'ห้องสำหรับครอบครัว']\n",
      "star -->  4.0\n",
      "p2\n",
      "p3\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "s1\n",
      "cur img path ->  []\n",
      "scrape location data for,  https://www.google.com/maps/search/?api=1&query=7.899594,98.30387\n",
      "found province : 83 ภูเก็ต\n",
      "found District : 8302 กะทู้\n",
      "province : 83 ภูเก็ต\n",
      "District : 8302 กะทู้\n",
      "Address :  240/9 Phang Muang Sai Kor Road, ป่าตอง, กะทู้, จังหวัดภูเก็ต 83150 ไทย\n",
      "******************************************************\n",
      "scrape single accommodation...\n",
      "for accommodation :  https://th.tripadvisor.com/Hotel_Review-g1210687-d1379794-Reviews-Chanalai_Romantica_Resort-Kata_Beach_Karon_Phuket.html\n",
      "debug scrape_single_accommodation: top info component section\n",
      "debug scrape_single_accommodation: bottom info component section\n",
      "debug scrape_single_attraction: common component section\n",
      "scrape data in adjust accommodation page...\n",
      "for link :  https://th.tripadvisor.com/ImproveListing-d1379794.html\n",
      "debug option of adjust page: \n",
      "found target dropdown btn ...\n",
      "lat :  7.819152\n",
      "long :  98.3002\n",
      "name ->  Chanalai Romantica Resort\n",
      "phone -->  00 66 76 333 105\n",
      "rating -->  5.0\n",
      "rating_count -->  1380\n",
      "cur_topic -->  สิ่งอำนวยความสะดวกของสถานที่ให้บริการ\n",
      "cur_topic -->  สิ่งอำนวยความสะดวกในห้องพัก\n",
      "cur_topic -->  ประเภทห้องพัก\n",
      "facilities -->  ['ที่จอดรถฟรี', 'อินเตอร์เน็ตความเร็วสูง (WiFi) ฟรี', 'สระว่ายน้ำ', 'อาหารเช้าฟรี', 'บริการรถรับ-ส่งสนามบิน', 'ศูนย์บริการธุรกิจพร้อมบริการอินเทอร์เน็ต', 'การรักษาความปลอดภัยตลอด 24 ชั่วโมง', 'พื้นที่เก็บกระเป๋า', 'เสื้อคลุมอาบน้ำ', 'เครื่องปรับอากาศ', 'บริการทำความสะอาด', 'ระเบียงส่วนตัว', 'บริการรูมเซอร์วิส', 'เครื่องชงกาแฟ / ชา', 'ทีวีจอแบน', 'อ่างอาบน้ำ / ฝักบัวอาบน้ำ']\n",
      "tags -->  ['วิวมหาสมุทร', 'ห้องพักปลอดบุหรี่']\n",
      "star -->  4.0\n",
      "p2\n",
      "p3\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "m1\n",
      "m2\n",
      "retry load galley ...\n",
      "s1\n",
      "cur img path ->  []\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m cur_province_url \u001b[38;5;241m=\u001b[39m cur_region_data[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# get dataframe result of all accommodation in current province\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m cur_res_allaccommodations_df \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_accommodation_by_province\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovince_url\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_province_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovince\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_province_th\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# don't forget to remove row with lat/long be zero\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# remove duplicate accommodation\u001b[39;00m\n\u001b[0;32m     23\u001b[0m cur_res_allaccommodations_df\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[69], line 16\u001b[0m, in \u001b[0;36mscrape_accommodation_by_province\u001b[1;34m(province_url, province, page)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# continue scraping data for a specific resgtaurant\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m cur_accommodation \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_single_accommodation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlink_to_accommodation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_accommodation_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovince_th\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprovince\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m cnt_for_debug \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# create data frame represent data scrape from current accommodation card\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[67], line 192\u001b[0m, in \u001b[0;36mscrape_single_accommodation\u001b[1;34m(link_to_accommodation, province_th)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcur img path -> \u001b[39m\u001b[38;5;124m\"\u001b[39m, img_path)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# find location\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m location \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_location\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccommodation_page_driver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maccommodation_page_driver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatitude\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlongitude\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlong\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovince_th\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprovince_th\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprovince :\u001b[39m\u001b[38;5;124m\"\u001b[39m, location\u001b[38;5;241m.\u001b[39mget_province_code(), location\u001b[38;5;241m.\u001b[39mget_province())\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistrict :\u001b[39m\u001b[38;5;124m\"\u001b[39m, location\u001b[38;5;241m.\u001b[39mget_district_code(), location\u001b[38;5;241m.\u001b[39mget_district())\n",
      "Cell \u001b[1;32mIn[65], line 45\u001b[0m, in \u001b[0;36mscrape_location\u001b[1;34m(accommodation_page_driver, latitude, longitude, province_th)\u001b[0m\n\u001b[0;32m     42\u001b[0m google_map_driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m     44\u001b[0m google_map_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.google.com/maps/search/?api=1&query=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (latitude, longitude)\n\u001b[1;32m---> 45\u001b[0m \u001b[43mgoogle_map_driver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgoogle_map_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscrape location data for, \u001b[39m\u001b[38;5;124m\"\u001b[39m, google_map_query)\n\u001b[0;32m     48\u001b[0m WebDriverWait(google_map_driver, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(EC\u001b[38;5;241m.\u001b[39mvisibility_of_element_located((By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDkEaL\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:368\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    352\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 354\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;66;03m# remove later prn..\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;66;03m# print(\"prn check name of command --> \", driver_command)\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# print('prn check response in side --> ', response)\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:306\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    304\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    305\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:326\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    323\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 326\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\urllib3\\request.py:81\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m     78\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     79\u001b[0m     )\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\urllib3\\request.py:173\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    170\u001b[0m extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(headers)\n\u001b[0;32m    171\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\urllib3\\poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    374\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    729\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    462\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    464\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    466\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:462\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 462\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\http\\client.py:1423\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1422\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1423\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1425\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create directory 'res_accommodation_scraping'\n",
    "createDirectory(fh.STORE_ACCOMM_SCRAPING, 'res_accommodation_scraping')\n",
    "\n",
    "# *** select one province from 'ALL_PROVINCE_ACCOMM_DATA'\n",
    "# *** so, change \"Idx_of_region\" everytime when scrape another province\n",
    "Idx_of_region = 0\n",
    "cur_region_data = ALL_PROVINCE_ACCOMM_DATA[Idx_of_region]\n",
    "\n",
    "cur_province_en = cur_region_data[0]\n",
    "cur_province_th = cur_region_data[1]\n",
    "cur_province_url = cur_region_data[2]\n",
    "\n",
    "# get dataframe result of all accommodation in current province\n",
    "cur_res_allaccommodations_df = scrape_accommodation_by_province(\n",
    "    province_url = cur_province_url,\n",
    "    province = cur_province_th,\n",
    "    page = 1\n",
    ")\n",
    "\n",
    "# don't forget to remove row with lat/long be zero\n",
    "\n",
    "# remove duplicate accommodation\n",
    "cur_res_allaccommodations_df.drop_duplicates(subset=['name'], inplace=True)\n",
    "# set new index\n",
    "cur_res_allaccommodations_df.set_index(['name'], inplace=True)\n",
    "\n",
    "# save result dataframe to .csv\n",
    "res_file_name = 'res_accommodation_%s.csv' % (cur_province_en)\n",
    "res_path = os.path.join(fh.STORE_ACCOMM_SCRAPING, 'res_accommodation_scraping', res_file_name) \n",
    "cur_res_allaccommodations_df.to_csv(res_path, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
